---
layout: post
title: "Bài 6: Object detect với YOLO - YOLO tutorial P1"
title2: "6. Object detect với YOLO - YOLO tutorial P1"
tag: [yolo, object detect]
img: assets/6-yolo/yologo_2.png
category: [computer vision]
---

Mục lục: 
- [Giới thiệu](#-0)
- [1. Tư tưởng của YOLO](#-1)
- [2. Chi tiết thuật toán YOLO](#-2)
- [3. Loss function của YOLO](#-3)


<!-- ############ -->
<a name="-0"></a>

### Giới thiệu

Trong lĩnh vực computer vision, có rất nhiều chủ để, bài toán mà con người đang cố gắng giải quyết tối ưu: 
* bài toán classify (phân loại)
* bài toán detect (xác định vị trí) ( detect + classify = recognize)
* bài toán semantic segmentation (phân đoạn ngữ nghĩa)
* bài toán style transfer.
* Ngoài các bài toán đó còn nhiều bài toán khác nhưng không phổ biến bằng.

Trong các bài toán đó, bài toán Object Detect là bài toán quan trọng và phổ biến, ứng dụng rộng rãi. Ai làm về computer vision, không sớm thì muộn cũng sẽ động đến nó. Hệ thống định vị khuôn mặt trong ảnh của Facebook, các hệ thống chấm công, giám sát nhân viên... là các hệ thống tiêu biểu. Trong bài viết này, mình sẽ viết về **YOLO** để giải quyết bài toán Detect.

<div class="imgcap">
    <div >
        <img src="/assets/6-yolo/yolo1.jpg" width="500">
    </div>
    <div class="thecap">H1: Object detect với YOLO </div>
</div>

**Required knowledge**: Để đảm bảo có thể hiểu được, bạn cần có chút kiến thức về Deep Learning (neural network, CNN)

<!-- ############ -->
<a name="-1"></a>

## 1. Tư tưởng YOLO
Trước đây, bài toán detect có vài hướng giải quyết, trong đó phổ biến nhất theo pipe line tối thiểu 2 bước: 

+ Từ ảnh đầu vào chọn ra các vùng tiềm năng
+ Với từng vùng tiến hành classify xem object nằm trong đó không. 

Tuy nhiên dạng này không phù hợp cho real-time. Sau này, YOLO giải quyết khá tốt vấn đề này, làm đồng thời các công việc trong 1 lần . Với ảnh đầu vào, YOLO tính toán và trả về đồng thời các thông tin: **vị trí, kích cỡ, loại vật thể**. Đó là lí do cái tên YOLO ra đời: **YOU ONLY LOOK ONE**.


<!-- ############ -->
<a name="-2"></a>

## 2. Chi tiết thuật toán.
<div class="imgcap">
    <div >
        <img src="/assets/6-yolo/yolo.gif" width="500">
    </div>
    <div class="thecap">H1: Tổng quan về YOLO </div>
</div>
<hr>

Mạng gồm 2 thành phần chính là Convolution và các Fully-Connected Layer. Kiến trúc phần Convolution bạn có thể tự code 1 kiến trúc bất kì hoặc transfer learning từ các pretrain model khác.

Ảnh được chia thành các **SxS** phần, thông thường người ta chia ảnh thành 7x7 , 9x9, 13x13, 19x19 grid. Việc chia này là chia trong **tưởng tượng**, không có bất kì phép cắt ảnh nào như một số bạn thắc mắc. Thay vào đó, **output** sẽ có shape là $$(S, S, n)$$, có nghĩa là mỗi vùng ảnh tương ứng với 1 vector độ dài n (n = $$5 * B + Class$$)

Sau khi đi qua lớp Fully-connected layer, data được **reshape** lại thành 1 matrix có shape:

$$(S, S, 5 * B + Class)$$

Trong Đó: 
   *  B là Box_number: tại mỗi grid, bạn dự đoán ra B bounding box.
   *  Với mỗi bounding box, mạng predict ra 5 con số bao gồm: x, y, w, h, và c (confidence). C là xác suất rằng bounding box đó chứa object. x,y,w,h nên được chuẩn hóa theo kích cỡ của grid.
   * Class: là phân bố xác suất, cho biết object đó đang chứa vật thể nào. VD trong hình gồm 20 class p1 -> p20
   
   * Ta cần làm quen với khái niệm IOU: tỉ lệ giao nhau giữa 2 vùng A, B. Được tính bằng theo công thức:
   
$$IOU(A, B) = \frac{A \cap B} {A \cup B }$$ 


<!-- ############ -->
<a name="-3"></a>

## 3. YOLO Loss function

Như vậy bạn đã hiểu điểm làm nên sự khác biệt của YOLO đó chính là ở output của nó. Output của nó đồng thời có đầy đủ thông tin về vị trí, kích thước, xác suất có objec trong grid, xác suất object đó thuộc class nào. 

Thứ khó hiểu và khó code nhất của Yolo nằm ở loss function của nó. Bởi vì output là sự kết hợp nhiều loại thông tin khác nhau, nên loss của nó phải được tạo thành 5 loss thành phần. Chúng ta cần hiểu được loss function.

<div class="imgcap">
    <div >
        <img src="/assets/6-yolo/loss.jpeg" width="800">
    </div>
    <div class="thecap">H2: Yolo loss function</div>
</div>
<hr>

Loss function của YOLO được kết hợp từ 5 phần: 
+ Phần 1: Loss về vị trí toạ độ (x,y) tại những ô có tồn tại object.
+ Phần 2: Loss về kích thước object (w,h) tại những ô có tồn tại object.
+ Phần 3: Loss về confidence_score tại những ô có tồn tại object.
+ Phần 4: Loss về confidence_score tại những ô không tồn tại object.
+ Phần 5: Loss xác suất phân loại Class tại những ô có tồn tại object.

**Chú thích**:
+ $$l_{ij}^{obj} = 1$$  nếu box thứ j trong ô thứ i **CÓ** chứa object, ngược lại = 0
+ $$l_{ij}^{noobj} = 1$$ nếu box thứ j trong ô thứ i **KHÔNG** chứa object, ngược lại = 0
+ $$l_{i}^{obj}$$ = 1  Nếu ô thứ i có chưa object.
+ $$\lambda_{coord}$$ và $$\lambda_{noobj}$$ là trọng số cho từng Loss thành phần. Trong paper gốc, tác giả thử nghiệm nhiều lần và thấy $$\lambda_{coord} = 5$$, $$\lambda_{noobj} = 0.5$$ cho kết quả tốt nhất.

Đoạn công thức Loss cho Yolo hơi khó hiểu, bạn cần đọc đi đọc lại nhiều lần để hiểu tường tận. Như vậy, trong bài này mình đã mô tả qua về thuật toán YOLO. Trong bài tiếp theo, mình sẽ nói thêm về thuật toán YOLO2 - một bản cải thiện đáng kể so với YOLO cả về tốc độ và chất lượng.
 
## Link tham khảo: 
[Medium: Realtime Object Detect](https://medium.com/@jonathan_hui/real-time-object-detection-with-yolo-yolov2-28b1b93e2088)

