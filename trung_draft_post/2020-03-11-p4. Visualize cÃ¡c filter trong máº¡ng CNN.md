---
layout: post
title: "Bài 5. Visualize các filter trong mạng CNN"
title2: "5. Visualize các filter trong mạng CNN"
category: [computer vision]
mathjax: true
img: assets/4-visualize/result.png
summary: Quan sát và hiểu được loại feature mà model trích xuất ở từng layer ... 
---




- [1. Ý tưởng thuật toán](#-algorithm)
- [2. Code thôi](#-code)


<div class="imgcap">
    <div >
        <img src="/assets/4-visualize/result.png" width="300">
    </div>
    <div class="thecap">H1  </div>
</div>
<hr>

Khi làm việc với các deep learning, đặc biệt với các CNN model, ta biết rằng tại mỗi layer với các filter có khả năng nhận dạng từng loại đặc trưng khác nhau trong ảnh input. Càng về các layer cuối, thông tin mà model thu được từ input sẽ được trìu tượng hóa cao hơn (hay trích xuất thông tin ở mức phức tạp hơn). Tuy nhiên làm thế nào để biết được từng filter nhận diện loại feature nào?  Hôm nay, mình sẽ viết về thuật toán Visualize Filter để giải quyết vấn đề đó. Hơn nữa, đây cũng là thuật toán cơ sở, tiền đề cho các thuật toán cao cấp hơn như Style Transfer, Deep Dream ...(các thuật toán liên quan tới biến đổi ảnh đầu vào).

Github: [github: trungthanhnguyen0502](https://github.com/trungthanhnguyen0502/Visualize-filter-deepnet)


<!-- Ý tưởng về thuật toán -->
<a name="#-algorithm"></a>

## 1.Thuật toán:

<div class="imgcap">
    <div >
        <img src="/assets/4-visualize/algorithm.png" width="700">
    </div>
    <div class="thecap">H2: Tổng quan về thuật toán  </div>
</div>
<hr>

Thuật toán:
+ Tạo một ảnh nhiễu input_img bất kì
+ Đưa input_img vào model, tại 1 layer lấy ra feature_map tương ứng với Filter cần quan sát. Mục tiêu sau nhiều step, input_img sẽ được biến đổi sao cho giá trị feature_map đạt giá trị lớn nhất. Khi đó input_img sẽ đại diện các đường nét, màu sắc mà Filter đó đạt tối đa khả năng trích xuất.

+ Tính đạo hàm mean(feature_map) theo biến input_img
+ update input_img theo thuật toán gradient_descent, để maximum giá trị mean(feature_map) thì update giá trị input_img với phép cộng thay vì phép trừ thường thấy ở gradient_descent, công thức:

$$img = img + lr * gradient$$

Ok, tiến hành code thôi

<a name="-code"></a>

## 2. Code 

Mình sẽ dùng 1 phiên bản pretrain VGG16 để minh họa thuật toán. Sau khi hiểu thuật toán, mọi người hoàn toàn có thể dùng 1 pretrain CNN bất kì khác, có thể code bằng tensorflow, keras hoặc pytorch.

Để dùng được phiên bản VGG này, mọi người chỉ cần vào [github](https://github.com/trungthanhnguyen0502/Visualize-filter-deepnet) và download code của mình về,
Project gồm: 
+ vgg16.py:     chứa code và các hàm liên quan tới vgg16
+ download.py:  để auto download vgg16.
+ main.ipynb : Toàn bộ code của thuật toán (thứ cần đọc).

<strong>Load và tạo model</strong>:
~~~
vgg16.maybe_download()
vgg = vgg16.VGG16()
~~~


Các hàm tiền xử lí, hậu xử lí ảnh

~~~ python
def normalize_image(x):
    """
    Chuẩn hoá giá trị các pixel ảnh về [0,1]
    """
    x_min = x.min()
    x_max = x.max()
    x_norm = (x - x_min) / (x_max - x_min)
    return x_norm

def plot_image(image):
    img_norm = normalize_image(image)
    plt.figure(figsize=(4,4))
    plt.axis('off')
    plt.imshow(img_norm, interpolation='nearest')
    plt.show()
    
def plot_images(images):
    (m, n) = (len(images)//3, 3)
    fig, axs = plt.subplots(m, n, figsize=(12,8))
    for i, img in enumerate(images):
        ax = axs[i//3, i% 3]
        img = normalize_image(img)
        ax.imshow(img, interpolation='nearest')
        ax.set_xticks([])
        ax.set_yticks([])
    plt.show() 
~~~


Trích xuất ra feature_map tại với layer_index và filter_index (tại 1 layer có nhiều filter khác nhau). Mean(feature_map) là giá trị chúng ta cần maximum.

~~~python
def cost(model, layer_id, feature_id):
    with model.graph.as_default():
        layer = model.get_layer_tensors([layer_id])[0]
        feature_map = layer[:,:,:,feature_id]
        loss = tf.reduce_mean(feature_map)
        return loss
~~~

<strong>Visualize</strong>: tính đạo hàm và update input:
+ Tensorflow cung cấp tf.gradient(loss, tensor) để tính gradient của loss theo 1 biến tensor (giống như tính đạo hàm F(x) theo biến x)  
+ Để đảm bảo giá trị thay đổi trong mỗi step không quá lớn hoặc quá nhỏ, ta sử dụng thuật toán tính learning rate, với stepsize được coi là giá trị khởi tạo learning rate: 

$$lrate = \frac{stepsize}{(gradient.max() + 1e-8)}$$

+ Ngoài gradient.max(), ta có thể dùng gradient.std()

~~~python
# Hàm chính, nhận model, layer index, filter index, trả về generate_image là kết quả bài toán
def visual(model, layer_id, feature_id, iters,step_size = 0.5):

    # khởi tạo 1 ảnh nhiễu bất kì
    generate_img = np.random.uniform(size=(224,224,3)) + 128.0

    with model.graph.as_default():
        loss = cost(vgg, layer_id, feature_id)
        gradient = tf.gradients(loss, model.input)
        
        # feed_dict là input tensor chứa ảnh input đầu vào
        feed_dict = vgg.create_feed_dict(image=generate_img)
        session = tf.Session(graph=vgg.graph)
        init = tf.global_variables_initializer()
        session.run(init)

        for i in range(iters):
            grad_val, loss_val = session.run([gradient, loss], feed_dict=feed_dict)
            grad_val = np.array(grad_val).squeeze()
            
            # tính learning rate
            lrate = step_size/(grad_val.max() + 1e-8)
            generate_img += lrate * grad_val
        return generate_img
~~~

Run code demo:
~~~python
images = []
feature_ids = [0,1,2,3,4,5]
layer_id = 5
for f_id in feature_ids:
    img = visual(vgg, layer_id, f_id, 150, 2)
    images.append(img)
plot_images(images)
~~~ 

Kết quả thu được như dưới, có thể hiểu rằng tại layer thứ 5, filter đầu tiên có khả năng trích xuất các đường nét tròn tròn, filter thứ 2 trích xuất các đường nét cong cong nhưng theo hướng xếp thẳng đứng .... 

<div class="imgcap">
    <div >
        <img src="/assets/4-visualize/result2.png" width="700">
    </div>
    <div class="thecap">H3: Kết quả thu được  </div>
</div>