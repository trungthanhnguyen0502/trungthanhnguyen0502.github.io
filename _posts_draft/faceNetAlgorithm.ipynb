{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faceNetAlgorithm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii4K2B9bqzrJ",
        "colab_type": "text"
      },
      "source": [
        "# 1. Hệ thống nhận diện khuôn mặt\n",
        "\n",
        "## 1.1. Các ứng dụng phổ biến\n",
        "\n",
        "Vào năm 2012, tôi vẫn còn nhớ facebook bắt dầu có chức năng nhận diện khuôn mặt. Khi đó tôi còn là một sinh viên chưa biết đến khái niệm trí tuệ nhân tạo. Tôi cực kì ấn tượng với khả năng kì diệu này. Tôi nghĩ chắc facebook phải thuê hàng ngàn người ngồi gán nhãn cho từng bức ảnh mỗi khi người dùng update lên. Hơi ngây thơ chút, nhưng đó là tất cả những gì tôi có thể biết cách đây 8 năm.\n",
        "\n",
        "Vào năm 2018, apple bắt đầu tích hợp chức năng nhận diện khuôn mặt trong các dòng sản phẩm iphone X. Sau đó, một xu hướng các smart phone ứng dụng nhận diện khuôn mặt ra đời.\n",
        "\n",
        "Một số ngân hàng ở Autralia bắt đầu ứng dụng xác thực khuôn mặt trong các giao dịch ATM.\n",
        "\n",
        "Tại Trung Quốc, hệ thống nhận diện khuôn mặt được triển khai trên toàn quốc giúp chấm điểm công dân và đồng thời xác minh nhiều tội phạm lẩn trốn.\n",
        "\n",
        "Còn tại cơ quan tôi, hệ thống nhận diện khuôn mặt được nghiên cứu in-house áp dụng để chấm công cho nhân viên.\n",
        "\n",
        "Tôi nghĩ rằng nhận diện khuôn mặt có tính ứng dụng cao. Rất nhiều công ty, doanh nghiệp và quốc gia đang cần. \n",
        "\n",
        "Tuy nhiên khá kì lạ là nhiều nơi chưa áp dụng nhận diện khuôn mặt vào cơ quan của mình. Việc xây dựng một hệ thống nhận diện khuôn mặt là không hề khó. Hãy có niềm tin rằng bạn có thể tự xây dựng một hệ thống nhận diện khuôn mặt cho cơ quan của mình sau bài viết này.\n",
        "\n",
        "Trước tiên tôi sẽ viết về lý thuyết của thuật toán. Phần thực hành tôi sẽ giới thiệu ở một bài khác.\n",
        "\n",
        "Đối với các bạn muốn hiểu sâu về thuật toán có thể bắt đầu đọc bài này.\n",
        "\n",
        "Đối với các bạn muốn thấy trước hiệu quả. Hãy chờ bài thực hành sau bài này.\n",
        "\n",
        "## 1.2. Các loại hệ thống xác thực\n",
        "\n",
        "Hầu hết các hệ thống xác thực sẽ dựa trên thông tin sinh trắc để định danh một người. Các thông tin sinh trắc là những thông tin duy nhất với mỗi người. Đó có thể là vân tay, ADN, vân mắt, khuôn mặt (không phẫu thuật thẩm mỹ, hãy thả lỏng khuôn mặt nhất có thể, không chu môi, nháy mắt, tạo kiểu cute các thứ), hình dạng, dáng đi,....\n",
        "\n",
        "Theo đó, có vô số các phương pháp xác thực khác nhau, tùy vào việc sử dụng thông tin sinh trắc nào. Ở Việt Nam thì chắc phổ biến nhất là xác thực bằng vân tay.\n",
        "\n",
        "Trước đây khi computer vision chưa phát triển thì các hệ thống xác thực bằng vân tay, bằng vân mắt được áp dụng khá phổ biến. Vài năm gần đây, xác thực bằng khuôn mặt mới được áp dụng rộng rãi. Xét về độ chính xác thì các hệ thống xác thực vân tay, vân mắt đáng tin cậy hơn so với nhận diện khuôn mặt vì dữ liệu không thay đổi, trong khi khuôn mặt một người có thể thay đổi qua thời gian và chịu sự co dãn.\n",
        "\n",
        "Tuy nhiên hệ thống nhận diện khuôn mặt được ưa chuộng vì quá trình xác thực nhanh, có thể xác thực từ xa, không cần phải tiếp xúc như vân tay, vân mắt. Bạn được phép nhìn người khác nhưng muốn động chạm thì cần phải được sự xin phép của họ.\n",
        "\n",
        "## 1.3. Các phương pháp xác thực khuôn mặt\n",
        "\n",
        "### 1.3.1. Phương pháp truyền thống\n",
        "\n",
        "Các phương pháp truyền thống: Xác thực khuôn mặt bằng cách trích xuất ra một land mark cho face. Land mark như là một bản đồ xác định các vị trí cố định trên khuôn mặt của một người như mắt, mũi, miệng, lông mày,.... \n",
        "\n",
        "![](https://imgur.com/ua9Bryq.png)\n",
        "\n",
        "Như vậy thay land mark face đã loại bỏ những phần thông tin không cần thiết và giữ lại những thông tin chính. Khi đó mỗi khuôn mặt sẽ được nén thành một véc tơ n chiều. Thông thường là 68 chiều.\n",
        "\n",
        "Sử dụng đầu vào là land mark face, áp dụng các thuật toán cổ điển như SVM, k-NN, Naive Bayes, Random Forest, MLP, ... để phân loại khuôn mặt cho một người.\n",
        "\n",
        "### 1.3.2. nhận diện 3D\n",
        "\n",
        "Kĩ thuật nhận diện 3D sẽ sử dụng không gian 3 chiều để biểu diễn khuôn mặt. Từ thông tin này có thể xác định các đặc trưng khác nhau trên bề mặt khuôn mặt như các đường countour của mắt, mũi, cằm.\n",
        "\n",
        "Một lợi thế của nhận diện khuôn mặt 3D là không bị ảnh hưởng bởi những thay đổi về ánh sáng như các phương pháp 2D. Dữ liệu 3D đã cải thiện đáng kể độ chính xác của nhận dạng khuôn mặt. \n",
        "\n",
        "Để tạo ra một ảnh 3D, một cụm ba camera được áp dụng. Mỗi camera sẽ hướng vào một góc khác nhau. Tất cả các camera này phối hợp cùng nhau trong việc theo dõi khuôn mặt của một người trong thời gian thực và có thể nhận diện chúng.\n",
        "\n",
        "![](https://d3i71xaburhd42.cloudfront.net/7492c611b1df6bce895bee6ba33737e7fc7f60a6/4-Figure2-1.png)\n",
        "\n",
        "Nhận diện khuôn mặt của iphone là nhận diện 3D. Bạn sẽ phải quay tròn khuôn mặt của mình khi xác thực nó để thuật toán học các góc độ khác nhau.\n",
        "\n",
        "### 1.3.3. Các phương pháp nhận diện khác\n",
        "\n",
        "Ngoài ra còn có một số phương pháp nhận diện khuôn mặt như nhận diện cảm biến da và phương pháp kết hợp.\n",
        "\n",
        "Phương pháp kết hợp có thể sử dụng nhiều thông tin từ đồng thời land mark face, nhận diện 3D, nhận diện cảm biến da và mang lại độ chính xác cao hơn vì nó nhận diện tốt được trong các trường hợp khuôn mặt có các biểu cảm như cau mày, chớp mắt, co dãn khi cười, nói và ít nhạy cảm với chiếu sáng.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okox7aneElhW",
        "colab_type": "text"
      },
      "source": [
        "# 2. Các bài toán khác nhau về face\n",
        "\n",
        "Có nhiều lớp bài toán khác nhau liên quan đến dữ liệu face. Một trong số 4 bài toán phổ biến nhất dựa trên nhu cầu thực tế cần áp dụng đó là:\n",
        "\n",
        "* Nhận diện khuôn mặt (face identification): Đây là bài toán match one-many. Bài toán này sẽ trả lời cho câu hỏi người ngày là ai bằng cách nhận input là ảnh khuôn mặt và output là nhãn tên người trong ảnh. Tác vụ này thường được áp dụng trong các hệ thống chấm công, hệ thống giám sát công dân, hệ thống cammera thông minh tại các đô thị.\n",
        "\n",
        "* Xác thực khuôn mặt (face verification): Đây là bài toán match one-one. Bài toán này trả lời cho câu hỏi có phải 2 ảnh đầu vào là cùng một người hay không? Kết quả output sẽ là yes hoặc no. Bài toán thường được dùng trong các hệ thống bảo mật. Xác thực khuôn mặt trên điện thoại của bạn là một bài toán như vậy.\n",
        "\n",
        "Do có mối quan hệ khá gần nên face recognition là tên gọi chung cho cả hai thuật toán face identification và face verification.\n",
        "\n",
        "* Tìm kiếm khuôn mặt đại diện (face clustering): Chắc hẳn bạn đã từng đọc hoặc xem video về người có [khuôn mặt đặc trưng nhất thế giới](https://www.youtube.com/watch?v=xLaDbe7P2RU). Đơn giản là ta chỉ cần tính ra trung bình của các ảnh khuôn mặt để thu được centroid image. Tính similarity giữa centroid với toàn bộ khuôn mặt còn lại để thu được khuôn mặt đặc trưng nhất similarity nhất với centroid. Tương tự như vậy bạn cũng có thể tìm ra khuôn mặt đặc trưng nhất của nam, nữ các quốc gia.\n",
        "\n",
        "![](https://thechive.com/wp-content/uploads/2015/09/heres-what-the-average-person-looks-like-in-each-country-12.jpg)\n",
        "\n",
        "* Tìm kiếm khuôn mặt tương đương (face similarity): Chắc các bạn đã từng nghịch qua một số ứng dụng của facebook như bạn giống diễn viên điện ảnh nào nhất. Thuật toán này khá đơn giản, chỉ cần đo lường ảnh mà bạn upload lên với các ảnh diễn viên sẵn có và chọn ra một cái gần nhất. Nhưng đừng tin là mình là họ nhé. Có thể đây chỉ là 1 hình ảnh hai số phận."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDkyMUL8Dc8G",
        "colab_type": "text"
      },
      "source": [
        "# 3. Các thuật toán nhận diện khuôn mặt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEvxCLuFGt7F",
        "colab_type": "text"
      },
      "source": [
        "## 3.1. One shot learning\n",
        "\n",
        "One shot learning là thuật toán học có giám sát mà mỗi một người chỉ cần 1 vài, rất ít hoặc thậm chí chỉ 1 bức ảnh duy nhất (để khỏi tạo ra nhiều biến thể).\n",
        "\n",
        "Từ đầu vào là bức ảnh của một người, chúng ta sử dụng một kiến trúc thuật toán CNN đơn giản để dự báo người đó là ai.\n",
        "\n",
        "Tuy nhiên nhược điểm của phương pháp này là chúng ta phải huấn luyện lại thuật toán thường xuyên khi xuất hiện thêm một người mới vì shape của output thay đổi tăng lên 1. Rõ ràng là không tốt đối với các hệ thống nhận diện khuôn mặt của một công ty vì số lượng người luôn biến động theo thời gian.\n",
        "\n",
        "Để khắc phục được vấn đề này, chúng ta sử dụng phương pháp learning similarity.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tQV2zCpNDp8",
        "colab_type": "text"
      },
      "source": [
        "## 3.2. Learning similarity\n",
        "\n",
        "Phương pháp này dựa trên một phép đo khoảng cách giữa 2 bức ảnh, thông thường là các norm chuẩn $l_1$ hoặc $l_2$ sao cho nếu 2 bức ảnh thuộc cùng một người thì khoảng cách là nhỏ nhất và nếu không thuộc thì khoảng cách sẽ lớn hơn.\n",
        "\n",
        "$$\\begin{equation}\n",
        "  \\begin{cases} d(\\text{img1}, \\text{img2}) \\leq \\tau & \\rightarrow &\\text{same} \\\\\n",
        "  d(\\text{img1}, \\text{img2}) > \\tau & \\rightarrow & \\text{different}\n",
        "  \\end{cases}\n",
        "\\end{equation}$$\n",
        "\n",
        "![](https://imgur.com/MUOIxfq.png)\n",
        "\n",
        "Với phương pháp learning similarity chúng ta không bị phụ thuộc vào shape của output. Quan trọng là ta xây dựng được một model encoding tốt để embedding mỗi bức ảnh thành một véc tơ.\n",
        "\n",
        "Thuật toán siam network đã kết thừa phương pháp learning similarity và tạo nên một xu hướng mới trong face recognition. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atb6MRmpeV9K",
        "colab_type": "text"
      },
      "source": [
        "## 3.3. Siam network\n",
        "\n",
        "Những kiến trúc mạng mà khi bạn đưa vào 2 bức ảnh và mô hình sẽ trả lời chúng thuộc về cùng 1 người hay không được gọi chung là Siam network. Siam network được giới thiệu đầu tiên bởi [DeepFace: Closing the Gap to Human-Level - Yaniv Taigman. elt](https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf).\n",
        "\n",
        "Kiến trúc của Siam network dựa trên base network là một Convolutional neural network đã được loại bỏ output layer có tác dụng encoding ảnh thành véc tơ embedding. Đầu vào của mạng siam network là 2 bức ảnh bất kì được lựa chọn ngẫu nhiên từ dữ liệu ảnh. Output của Siam network là 2 véc tơ tương ứng với biểu diễn của 2 ảnh input. Sau đó chúng ta đưa 2 véc tơ vào hàm loss function để đo lường sự khác biệt giữa chúng. Thông thường hàm loss function là một hàm norm chuẩn bậc 2.\n",
        "\n",
        "Lý thuyết về norm chuẩn bậc 2 tôi khuyến nghị các bạn xem thêm tại [norms chuẩn - machinelearningcoban](https://machinelearningcoban.com/math/#-norms-chuan). Rất đầy đủ và chi tiết.\n",
        "\n",
        "![](https://imgur.com/VPC7yvy.png)\n",
        "\n",
        "**Hình 2:** Từ mô hình Convolutional neural network, mô hình trả ra 2 véc tơ encoding là $\\mathbf{x_1}$ và $\\mathbf{x_2}$ biểu diễn cho lần lượt ảnh 1 và 2. $\\mathbf{x_1}$ và $\\mathbf{x_2}$ có cùng số chiều. Hàm $f(\\mathbf{x})$ có tác dụng tương tự như một phép biến đổi qua layer fully connected trong mạng neural network để tạo tính phi tuyến và giảm chiều dữ liệu về các kích thước nhỏ. Thông thường là 128 đối đối với các mô hình pretrain.\n",
        "\n",
        "* Khi $\\mathbf{x_1}, \\mathbf{x_2}$ là cùng 1 người, $||f(\\mathbf{x_1}) - f(\\mathbf{x_2})||_2^{2}$ nhỏ.\n",
        "\n",
        "* Khi $\\mathbf{x_1}, \\mathbf{x_2}$ là 2 người khác nhau, $||f(\\mathbf{x_1}) - f(\\mathbf{x_2})||_2^{2}$ lớn.\n",
        "\n",
        "Khi sử dụng siam network chúng ta sẽ không cần phải lo lắng về vấn đề output shape thay đổi vì base network đã được loại bỏ layer cuối.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spQMR44gq5iN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# 4. Thuật toán facenet\n",
        "\n",
        "Facenet chính là một dạng siam network có tác dụng biểu diễn các bức ảnh trong một không gian eucledean $n$ chiều (thường là 128) sao cho khoảng cách giữa các véc tơ embedding càng nhỏ, mức độ tương đồng giữa chúng càng lớn.\n",
        "\n",
        "## 4.1. Khái quát thuật toán\n",
        "\n",
        "Hầu hết các thuật toán nhận diện khuôn mặt trước facenet đều tìm cách biểu diễn khuôn mặt bằng một véc tơ embedding thông qua một layer bottle neck có tác dụng giảm chiều dữ liệu.\n",
        "\n",
        "* Tuy nhiên hạn chế của các thuật toán đó là số lượng chiều embedding tương đối lớn (thường >= 1000) và ảnh hưởng tới performance của thuật toán. Thường chúng ta phải áp dụng thêm thuật toán PCA để giảm chiều dữ liệu.\n",
        "\n",
        "* Hàm loss function chỉ đo lường khoảng cách giữa 2 bức ảnh. Như vậy trong một đầu vào huấn luyện chỉ học được một trong 2 khả năng là sự giống nhau nếu chúng cùng 1 class hoặc sự khác nhau nếu chúng khác class giữa 2 bức ảnh.\n",
        "\n",
        "Facenet đã giải quyết cả 2 vấn đề trên bằng các hiệu chỉnh nhỏ nhưng mang lại hiệu quả rất lớn:\n",
        "\n",
        "* Base network áp dụng một mạng convolutional neural network và giảm chiều dữ liệu xuống chỉ còn 128 chiều. Do đó thuật toán classification ở những layer sau hoạt động nhanh hơn và đồng thời độ chính xác vẫn được đảm bảo.\n",
        "\n",
        "* Sử dụng một hàm loss function đặc biệt có khả năng đánh mức độ khác biệt giữa các bức ảnh sao cho giá trị loss function của chúng càng lớn, sự khác biệt giữa chúng càng cao. Đó chính là triplot loss function.\n",
        "\n",
        "* Hàm triplot loss có khả năng học được đồng thời sự giống nhau giữa 2 bức ảnh cùng nhóm và tìm cách phân biệt các bức ảnh nếu chúng không cùng nhóm. Do đó hiệu quả hơn rất nhiều so với các phương phát trước đây."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB6OBxRaWuj9",
        "colab_type": "text"
      },
      "source": [
        "## 4.1. Triple loss\n",
        "\n",
        "Trong facenet, quá trình encoding của mạng convolutional neural network đã giúp ta mã hóa bức ảnh về 128 chiều. Sau đó những véc tơ này sẽ làm đầu vào cho hàm loss function mà có tác dụng phân biệt tốt các véc tơ giống hoặc khác nhau. Đó chính là hàm loss function.\n",
        "\n",
        "Để áp dụng triple loss, chúng ta cần lấy ra 3 bức ảnh trong đó có một bức ảnh là anchor. Chắc bạn còn nhớ khái niệm về anchor box đã được trình bày tại [Bài 25 - YOLO You Only Look Once](https://phamdinhkhanh.github.io/2020/03/09/DarknetAlgorithm.html#5-anchor-box) chứ. Anchor image cũng có tác dụng gần như vậy. Trong 3 ảnh thì ảnh anchor được cố định trước. Chúng ta sẽ lựa chọn 2 ảnh còn lại sao cho một ảnh là negative (của một người khác với anchor) và một ảnh là positive (cùng một người với anchor).\n",
        "\n",
        "\n",
        "![](https://imgur.com/oF1w7lP.png)\n",
        "\n",
        "\n",
        "Kí hiệu ảnh Anchor, Positive, Negative lần lượt là $\\mathbf{A}, \\mathbf{P}, \\mathbf{N}$.\n",
        "\n",
        "Mục tiêu của hàm loss function là tối thiểu hóa khoảng cách giữa 2 ảnh khi chúng là negative và tối đa hóa khoảng cách khi chúng là positive. Như vậy chúng ta kì vọng rằng:\n",
        "\n",
        "* Ảnh Anchor và Positive giống nhau: khoảng cách $d(\\mathbf{A}, \\mathbf{P})$ sẽ nhỏ.\n",
        "* Ảnh Anchor và Negative khác nhau: khoảng cách $d(\\mathbf{A}, \\mathbf{N})$ sẽ lớn.\n",
        "\n",
        "Triplot loss function luôn lấy 3 bức ảnh làm input và trong mọi trường hợp ta kì vọng:\n",
        "\n",
        "$$d(\\mathbf{A}, \\mathbf{P}) < d(\\mathbf{A}, \\mathbf{N}) \\tag{1}$$\n",
        "\n",
        "Để làm cho khoảng cách giữa vế trái và vế phải lớn hơn, chúng ta sẽ cộng thêm vào vế trái một hệ số $\\alpha$ không âm rất nhỏ. Khi đó $(1)$ trở thành:\n",
        "\n",
        "$$\\begin{eqnarray}d(\\mathbf{A}, \\mathbf{P}) + \\alpha & \\leq & d(\\mathbf{A}, \\mathbf{N}) \\\\\n",
        "\\rightarrow||f(\\mathbf{A})-f(\\mathbf{P})||_2^{2} + \\alpha & \\leq & ||f(\\mathbf{A})-f(\\mathbf{N})||_2^{2}\\end{eqnarray}$$\n",
        "\n",
        "$$\\rightarrow ||f(\\mathbf{A})-f(\\mathbf{P})||_2^{2} - ||f(\\mathbf{A})-f(\\mathbf{N})||_2^{2}+ \\alpha \\leq 0\n",
        "$$\n",
        "\n",
        "Như vậy hàm loss function sẽ là:\n",
        "\n",
        "$$\\mathcal{L}(\\mathbf{A, P, N}) = \\sum_{i=0}^{n}||f(\\mathbf{A}_i)-f(\\mathbf{P}_i)||_2^{2} - ||f(\\mathbf{A}_i)-f(\\mathbf{N_i})||_2^{2}+ \\alpha$$\n",
        "\n",
        "Trong đó $n$ là số lượng các bộ 3 hình ảnh được đưa vào huấn luyện.\n",
        "\n",
        "Mục tiêu của chúng ta là giảm thiểu các trường hợp hợp mô hình nhận diện sai ảnh Negative thành Postive nhất có thể. Do đó để loại bỏ ảnh hưởng của các trường hợp nhận diện đúng Negative và Positive. Ta sẽ điều chỉnh giá trị đóng góp của nó vào hàm loss function về 0. \n",
        "\n",
        "Tức là nếu $||f(\\mathbf{A})-f(\\mathbf{P})||_2^{2} - ||f(\\mathbf{A})-f(\\mathbf{N})||_2^{2}+ \\alpha \\leq 0$ sẽ được điều chỉnh về 0. Khi đó hàm loss function trở thành:\n",
        "\n",
        "\n",
        "$$\\mathcal{L}(\\mathbf{A, P, N}) = \\sum_{i=0}^{n}\\max(||f(\\mathbf{A}_i)-f(\\mathbf{P}_i)||_2^{2} - ||f(\\mathbf{A}_i)-f(\\mathbf{N_i})||_2^{2}+ \\alpha, 0)$$\n",
        "\n",
        "Như vậy chúng ta có thể áp dụng Triple loss vào các mô hình convolutional neural network để tạo ra những thuật toán có tác dụng phát hiện ra những ảnh thuộc về cùng một người trong bộ 3 các ảnh đầu vào trong quá trình huấn luyện mô hình. Khi đó tại layer gần cuối cùng của siam network ta sẽ thu được những véc tơ biểu diễn ảnh tốt nhất cho một hình ảnh.\n",
        "\n",
        "Một chú ý quan trọng khi huấn luyện mô hình siam network với triplot function đó là chúng ta luôn phải xác định trước cặp ảnh $(\\mathbf{A}, \\mathbf{P})$ thuộc về cùng một người. Ảnh $\\mathbf{N}$ sẽ được lựa chọn ngẫu nhiên từ các bức ảnh thuộc các nhãn còn lại.\n",
        "\n",
        "Do đó cần thu thập ít nhất 2 bức ảnh/1 người để có thể chuẩn bị được dữ liệu huấn luyện.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNKBLDjVUpf5",
        "colab_type": "text"
      },
      "source": [
        "## 4.2. Lựa chọn triple images input\n",
        "\n",
        "Nếu lựa chọn triple input một cách ngẫu nhiên có thể ảnh khiến cho bất đẳng thức $(1)$ dễ dàng xảy ra vì trong các ảnh ngẫu nhiên, khả năng giống nhau giữa 2 ảnh là rất khó. Hầu hết các trường hợp đều thỏa mãn bất đẳng thức $(1)$ và không gây ảnh hưởng đến giá trị của loss function do giá trị của chúng được set về 0. Như vật việc học những bức ảnh Negative quá khác biệt với Anchor sẽ không có nhiều ý nghĩa.\n",
        "\n",
        "Để mô hình khó học hơn và đồng thời cũng giúp mô hình phân biệt chuẩn xác hơn mức độ giống và khác nhau giữa các khuôn mặt, chúng ta cần lựa chọn các input theo các bộ 3 khó học (hard triplets).\n",
        "\n",
        "Ý tưởng là chúng ta cần tìm ra bộ ba $(\\mathbf{A}, \\mathbf{N}, \\mathbf{P})$ sao cho $(1)$ là gần đạt được đẳng thức (xảy ra dấu =) nhất. Tức là $d(\\mathbf{A}, \\mathbf{P})$ lớn nhất và $d(\\mathbf{A}, \\mathbf{N})$ nhỏ nhất. Hay nói cách khác với mỗi Anchor $\\mathbf{A}$ cần xác định:\n",
        "* **Hard Positive:** Bức ảnh Positive có khoảng cách xa nhất với Anchor, $\\text{argmax}_{\\mathbf{P}_i}(d(\\mathbf{A}, \\mathbf{P}_i))$ \n",
        "* **Hard Negative:** Bức ảnh Negative có khoảng cách gần nhất với Anchor, $\\text{argmin}_{\\mathbf{N}_j}(d(\\mathbf{A}, \\mathbf{N}_j))$\n",
        "\n",
        "\n",
        "Việc tính toán các giá trị $\\text{argmax}_{\\mathbf{P}_i}(d(\\mathbf{A}, \\mathbf{P}_i))$  và $\\text{argmin}_{\\mathbf{N}_j}(d(\\mathbf{A}, \\mathbf{N}_j))$ có thể được thực hiện offline và lưu vào checkpoint hoặc có thể tính toán online trên mỗi mini-batch.\n",
        "\n",
        "Bạn đọc có thể đọc kĩ hơn tại [mục 3.2 - Triplet selection](https://arxiv.org/pdf/1503.03832.pdf) ở bài báo gốc.\n",
        "\n",
        "Chiến lược lựa chọn Triple images sẽ có ảnh hưởng rất lớn tới chất lượng của mô hình Facenet. Nếu lựa chọn Triplet images tốt, Facenet sẽ hội tụ nhanh hơn và đồng thời kết quả dự báo chuẩn xác hơn. Lựa chọn ngẫu nhiên dễ dẫn tới thuật toán không hội tụ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxnydOK7lvVU",
        "colab_type": "text"
      },
      "source": [
        "# 5. Các pretrain model Facenet\n",
        "\n",
        "Hầu hết chúng ta khi xây dựng một thuật toán nhận diện khuôn mặt sẽ không cần phải train lại mô hình facenet mà tận dụng lại các mô hình pretrain sẵn có. Bạn sẽ không cần phải tốn thời gian và công sức nếu không có đủ tài nguyên và dữ liệu. Đó cũng là lý do tôi cho rằng việc xây dựng mô hình nhận diện khuôn mặt ở thời điểm hiện tại rất dễ dàng.\n",
        "\n",
        "Những mô hình pretrain được huấn luyện trên các dữ liệu lên tới hàng triệu ảnh. Do đó có khả năng mã hóa rất tốt các bức ảnh trên không gian 128 chiều. Việc còn lại của chúng ta là sử dụng lại mô hình, tính toán embedding véc tơ và huấn luyện embedding véc tơ bằng một classifier đơn giản để phân loại classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hJbeafIjXsm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## 5.1. Một số bộ dữ liệu public về face\n",
        "\n",
        "* [CASIA-WebFace](http://www.cbsr.ia.ac.cn/english/CASIA-WebFace-Database.html): Bộ dữ liệu bao gồm gần 500k ảnh được thu thập từ khoảng 10k người.\n",
        "\n",
        "* [VGGFace2](https://www.robots.ox.ac.uk/~vgg/data/vgg_face2/): Bộ dữ liệu gồm khoảng 3 triệu ảnh được thu thập từ gần 9k người.\n",
        "\n",
        "Trên là 2 bộ dữ liệu về face phổ biến nhất, được sử dụng nhiều trong các bài báo và nghiên cứu về face recognition.\n",
        "\n",
        "* Các bộ dữ liệu từ Trung Quốc cũng khá tốt. Những dữ liệu này được Baidu public để hỗ trợ các nhà nghiên cứu: [baidu dataset](https://ai.baidu.com/broad)\n",
        "\n",
        "* Ngoài ra bạn có thể tìm kiếm các bộ dữ liệu từ google, facebook, flickr và các phòng lab đã được liệt kê tại [top 15 free image datasets for facial recognition](https://lionbridge.ai/datasets/5-million-faces-top-15-free-image-datasets-for-facial-recognition/).\n",
        "\n",
        "* Hiện tại dữ liệu face cho người Việt thì tôi mới chỉ thấy trong cuộc thi [nhận diện người nổi tiếng - aivivn](https://www.aivivn.com/contests/2). Bộ dữ liệu này đã được các bạn AI engineer bên Sun* đóng góp cho cuộc thi miễn phí. Tôi rất ghi nhận sự đóng góp của các bạn đối với cộng đồng AI việt. Tôi hi vọng tương lai sẽ có những bộ dữ liệu về face lớn hơn nữa cho người Việt. Tài nguyên ảnh trên mạng khá là nhiều, đặc biệt là dữ liệu về face. Một vài tip web crawler có lẽ sẽ hữu ích."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgNxJcP5jZHj",
        "colab_type": "text"
      },
      "source": [
        "## 5.2. Một số pretrain model phổ biến\n",
        "\n",
        "Các pretrain model cho facenet khá nhiều:\n",
        "\n",
        "* Bạn có thể sử dụng pretrain model từ [facenet repo - davidsandberg](https://github.com/davidsandberg/facenet)\n",
        "![](https://imgur.com/s2kgSEq.png)\n",
        "Kiến trúc mà tác giả sử dụng là Inception ResNetv1 trên 2 bộ dữ liệu là CASIA-WebFace và VGGFace2\n",
        "\n",
        "* Ngoài ra còn rất nhiều các pretrain model khác nằm rải rác trên các nguồn khác nhau. Bạn có thể xem thêm từ chia sẻ [Khai báo pretrained model nhận diện người nổi tiếng - aivivn](https://forum.machinelearningcoban.com/t/khai-bao-pretrained-models-cho-nhan-dien-nguoi-noi-tieng/4566)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQbuOmiBT37z",
        "colab_type": "text"
      },
      "source": [
        "# 6. Tổng kết\n",
        "\n",
        "Như vậy qua bài viết này bạn đã hiểu được phương pháp chính của thuật toán Facenet trong nhận diện khuôn mặt. Thuật toán này đã cải thiện được đồng thời độ chính xác và tốc độ nhờ áp dụng output shape thấp và hàm triple loss function hiệu quả.\n",
        "\n",
        "Mấu chốt để xây dựng một mô hình facenet tốt đó là chiến lược lựa chọn input triple images sao cho chúng là những bộ 3 khó học (hard triplets).\n",
        "\n",
        "Việc huấn luyện mô hình Facenet có thể tốn rất nhiều tài nguyên của bạn. Thế nên, trừ khi bạn là doanh nghiệp, muốn đầu tư vào mô hình này cho mục đích thương mại thì có thể xây dựng lại mô hình trên dữ liệu mới. Nếu bạn là sinh viên nghèo vượt khó hãy sử dụng lại pretrain model. Các model pretrain hiện tại rất tốt và tôi nghĩ hiệu quả chưa chắc đã thua kém.\n",
        "\n",
        "Ở bài sau tôi sẽ hướng dẫn bạn xây dựng một ứng dụng chấm công cho cơ quan của bạn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19XE4cUxT7ZU",
        "colab_type": "text"
      },
      "source": [
        "# 7. Tài liệu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed3STQytcChn",
        "colab_type": "text"
      },
      "source": [
        "1. [DeepFace: Closing the Gap to Human-Level Performance in Face Verification - Yaniv Taigman .etc](https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf)\n",
        "\n",
        "2. [FaceNet: A Unified Embedding for Face Recognition and Clustering - Florian Schroff .etc](https://arxiv.org/pdf/1503.03832.pdf)\n",
        "\n",
        "3. [FaceNet - Florian Schroff, Dmitry Kalenichenko, James Philbin\n",
        "Google Inc.](http://llcao.net/cu-deeplearning17/pp/class10_FaceNet.pdf)\n",
        "\n",
        "4. [Deep Learning Face Representation by Joint Identification-Verification - Yi Sun, Xiaogang Wang, Xiaoou Tang](https://arxiv.org/abs/1406.4773.pdf)\n",
        "\n",
        "5. [Face Recognition Based on Improved FaceNet Model - Qiuyue Wei etc](https://www.researchgate.net/publication/329893282_Face_Recognition_Based_on_Improved_FaceNet_Model)\n",
        "\n",
        "6. [Introduction to FaceNet: A Unified Embedding for Face Recognition and Clustering - Dhairya Kumar](https://medium.com/analytics-vidhya/introduction-to-facenet-a-unified-embedding-for-face-recognition-and-clustering-dbdac8e6f02)"
      ]
    }
  ]
}