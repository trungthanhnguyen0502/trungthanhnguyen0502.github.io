{"cells":[{"metadata":{"_uuid":"7200eb0cdc8afa588ef75a18239c75263e62aedb"},"cell_type":"markdown","source":"# 1. Lý thuyết về mạng tích chập\n\n## 1.1. Giới thiệu tích chập\n\nTích chập là một khái niệm trong xử lý tín hiệu số nhằm biến đổi thông tin đầu vào thông qua một phép tích chập với bộ lọc để trả về đầu ra là một tín hiệu mới. Tín hiệu này sẽ làm giảm những đặc trưng mà bộ lọc không quan tâm và chỉ giữ những đặc trưng chính. \n\nTích chập thông dụng nhất là tích chập 2 chiều được áp dụng trên ma trận đầu vào và ma trận bộ lọc 2 chiều. Phép tích chập của một ma trận $\\mathbf{X} \\in \\mathbb{R}^{W_1 \\times H_1}$ với một *bộ lọc* (receptive field) $\\mathbf{F} \\in \\mathbb{R}^{F \\times F}$ là một ma trận $\\mathbf{Y} \\in \\mathbb{R}^{W_2 \\times H_2}$ sẽ trả qua những bước sau:\n\n* Tính tích chập tại 1 điểm:\nTại vị trí đầu tiên trên cùng của ma trận đầu vào ta sẽ lọc ra một ma trận con $\\mathbf{X}_{sub} \\in \\mathbb{R}^{F \\times F}$ có kích thước bằng với kích thước của bộ lọc. Giá trị $y_{11}$ tương ứng trên $\\mathbf{Y}$ là tích chập của $\\mathbf{X}_{sub}$ với $\\mathbf{F}$ được tính như sau:\n$$y_{11}= \\sum_{i = 1}^{F}  \\sum_{j = 1}^{F} x_{ij} f_{ij}$$ \n* Tiến hành trượt dọc theo ma trận theo chiều từ trái qua phải, từ trên xuống dưới theo *bước nhảy* (stride) $S$ ta sẽ tính được các giá trị $y_{ij}$ tiếp theo. Sau khi quá trình này kết thúc ta thu được trọn vẹn ma trận $\\mathbf{Y}$.\n\nTrong một mạng nơ ron tích chập, các lớp liền sau lấy đầu vào từ lớp liền trước nó. Do đó để hạn chế lỗi trong thiết kế mạng nơ ron chúng ta cần xác định kích thước đầu ra ở mỗi lớp. Điều đó có nghĩa là dựa vào kích thước ma trận đầu vào $(W_1, H_1)$, kích thước bộ lọc $(F, F)$ và bước nhảy $S$ để xác định kích thước ma trận đầu ra $(W_2, H_2)$.\n\nXét quá trình trượt trên chiều $W_1$ của ma trận đầu vào. \n\n![](https://raw.githubusercontent.com/phamdinhkhanh/Tensorflow/master/ConvWidthStep.png)\n$$\\text{Hình 1: Quá trình trượt theo chiều rộng (W1)}$$\n\nGiả sử quá trình này sẽ dừng sau $W_2$ bước. Tại bước đầu tiên quá trình đi được đến vị trí thứ $F$. Sau mỗi bước liền sau sẽ tăng so với vị trí liền trước là $S$. Như vậy đến bước thứ $i$ quá trình trượt sẽ đi đến vị trí $F+(i-1)S$. Suy ra tại bước cuối cùng $W_2$ ma trận sẽ đi đến vị trí $F+(W_2-1)S$. Đây là vị trí lớn nhất gần với vị trí cuối cùng là $W_1$. Trong trường hợp lý tưởng thì $F+(W_2-1)S = W_1$. Từ đó ta suy ra:\n$$W_2 = \\frac{W_1-F}{S}+1 \\tag{1}$$\nKhi vị trí cuối cùng không trùng với $W_1$ thì số bước $W_2$ sẽ được lấy phần nguyên:\n$$W_2 = [\\frac{W_1-F}{S}]+1$$\n\nChúng ta luôn có thể tạo ra đẳng thức (1) nhờ thêm phần *đường viền* (padding) tại các cạnh của ảnh với độ rộng viền là $P$ sao cho phép chia cho $S$ là chia hết. Khi đó: $$W_2 = \\frac{W_1+2P-F}{S}+1$$\n\n![](https://raw.githubusercontent.com/phamdinhkhanh/Tensorflow/master/WidthPadding.png)\n$$\\text{Hình 2: Thêm padding kích thước P vào 2 lề chiều rộng (W1)}$$\n\nHoàn toàn tương tự ta cũng có công thức ứng với chiều cao: $$H_2 = \\frac{H_1+2P-F}{S}+1$$\n\n## 1.2. Thực hành mạng tích chập\n\nTrong ví dụ bên dưới ta sẽ thực hành sử dụng mạng tích chập để chiết xuất các đặc trưng chính của một bức ảnh. Thông qua hai bộ lọc thông dụng nhất là bộ lọc ngang $\\left[\\begin{matrix} -1 & -1 & -1 \\\\ 0\n& 0 & 0 \\\\ 1 & 1 & 1\\end{matrix}\\right]$ được sử dụng để chiết xuất các đường nằm ngang và bộ lọc dọc $\\left[\\begin{matrix} -1 & 0 & 1 \\\\ -1\n& 0 & 1 \\\\ -1 & 0 & 1\\end{matrix}\\right]$ dùng để chiết xuất các đường nét nằm dọc từ 1 bức ảnh."},{"metadata":{"trusted":true,"_uuid":"a86f20625d70112f3babaa50c8de2059fa48ce6c"},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2 \nfrom PIL import Image\nimport urllib.request\nfrom io import BytesIO\n\n%matplotlib inline\n\nurl = str('https://scontent.fhan2-3.fna.fbcdn.net/v/t1.0-9/31131205_1655267761229858_8661840822800482304_n.jpg?_nc_cat=109&_nc_ht=scontent.fhan2-3.fna&oh=a3c56598e53490f95d3648ab894f4ee0&oe=5C476E67')\nwith urllib.request.urlopen(url) as url:\n    f = BytesIO(url.read())\n\nX = np.array(Image.open(f))\nprint('Image shape: %s'%str(X.shape))\n# Convert to grey\nX = X.dot([0.299, 0.5870, 0.114])\nprint('Image shape: %s'%str(X.shape))\nplt.imshow(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6b3263f749ed91c1b8b9ea21a64b4d4c8601ba48"},"cell_type":"code","source":"#Tạo bộ lọc ngang F1\nF1 = np.array([[-1, -1, -1],\n              [0, 0, 0],\n              [1, 1, 1]])\n#Tính tích chập 2 chiều.\ndef conv2d(X, F, s = 1, p = 0):\n    \"\"\"\n    X: Ma trận đầu vào\n    F: Ma trận bộ lọc\n    s: Bước trượt\n    p: Độ rộng lề thêm vào\n    \"\"\"\n    (w1, h1) = X.shape\n    f = F.shape[0]\n    w2 = int((w1 + 2*p - f)/s) + 1\n    h2 = int((h1 + 2*p - f)/s) + 1\n    Y = np.zeros((w2, h2))\n    X_pad = np.pad(X, pad_width = p, mode = 'constant', constant_values = 0)\n    for i in range(w2):\n        for j in range(h2):\n            idw = i*s\n            idh = j*s\n            Y[i, j] = np.abs(np.sum(X_pad[idw:(idw+f), idh:(idh+f)]*F))\n    return Y\n\nY1 = conv2d(X, F1, s = 1, p = 0)\nplt.imshow(Y1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7179c00321542467f76062c63c6faf6a6ecea6c2"},"cell_type":"markdown","source":"Ta nhận thấy bộ lọc trên có tác dụng nhận diện những đường nét theo chiều ngang của bức ảnh như các đường viền của bảng, mép dưới của áo, mép dưới của chân tường,.... Sở dĩ bộ lọc này làm nổi bật các đường nét nằm ngang là bởi vì tích chập của chúng bằng hiệu của tổng giá trị các điểm phía dưới trừ các điểm phía trên. Đối với các đường nét nằm ngang thì cường độ sáng nằm ngang theo đường nét đó không khác biệt lớn nhưng xét theo chiều dọc thì chúng sẽ khác nhau. Do đó hiệu giữa 2 tổng phía trên và dưới càng lớn dẫn tới giá trị của tích chập càng lớn khi trượt theo các đường nét nằm ngang này. Khi hoàn thành thiện ma trận tích chập các đường nét nằm ngang sẽ có cường độ sáng lớn hơn nên nổi bật hơn. Chúng ta sẽ thử nghiệm một bộ lọc khác để nhận diện chiều dọc của bức ảnh."},{"metadata":{"trusted":false,"_uuid":"ed5e92fce182d38ba9400e1e4964952885a5aa0f"},"cell_type":"code","source":"#Tạo bộ lọc dọc F2\nF2 = np.array([[1, 0, -1],\n             [1, 0, -1],\n             [1, 0, -1]])\nY2 = conv2d(X, F2, s = 3, p = 0)\nplt.imshow(Y2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2190fd2d32cd0334a2bfd71df5ded42cfe1099f0"},"cell_type":"markdown","source":"Bộ lọc cho thấy các đường nét dọc theo bức ảnh như dáng người đứng thẳng đã được nhận diện rõ ràng, các đướng nét ngang như viền bảng, chân tường, viền dưới áo,... đã biến mất. Như vậy chúng ta có thể thấy mỗi bộ lọc sẽ có 1 tác dụng chiết xuất đặc trừng khác nhau từ cùng 1 bức ảnh.\n\n## 1.3. Mạng nơ ron tích chập\n\nTích chập được ứng dụng phổ biến trong lĩnh vực thị giác máy tính. Thông qua các phép tích chập, các đặc trưng chính từ ảnh được chiết xuất và truyền vào các lớp *tích chập* (layer convolution). Mỗi một lớp tích chập sẽ bao gồm nhiều đơn vị mà kết quả ở mỗi đơn vị là một phép biến đổi tích chập từ layer trước đó thông qua phép nhân tích chập với bộ lọc. \n\nVề cơ bản thiết kế của một mạng nơ ron tích chập 2 chiều có dạng như sau:\n\nINPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC\n\nTrong đó:\n\nINPUT: Lớp đầu vào\n\nCONV: Lớp tích chập\n\nRELU: Lớp biến đổi thông qua hàm kích hoạt relu để kích hoạt tính phi tuyến\n\nPOOL: Lớp tổng hợp, thông thường là Max pooling hoặc có thể là Average pooling dùng để giảm chiều của ma trận đầu vào.\n\nFC: Lớp kết nối hoàn toàn. Thông thường lớp này nằm ở sau cùng và kết nối với các đơn vị đại diện cho nhóm phân loại.\n\nCác kí hiệu []*N, []*M hoặc []*K ám chỉ cấu trúc bên trong [] có thể lặp lại nhiều lần liên tiếp nhau. M, K là số lần lặp lại. \nKí hiệu -> đại diện cho các lớp liền kề nhau mà lớp đứng trước -> sẽ làm đầu vào cho lớp đứng sau ->.\n\n\nNhư vậy ta có thể thấy một mạng nơ ron tích chập về cơ bản có 3 quá trình khác nhau:\n\n* Quá trình chiết xuất đặc trưng: Thông qua các tích chập giữa ma trận đầu vào với bộ lọc để tạo thành các đơn vị trong một lớp mới. Quá trình này có thể diễn ra liên tục ở phần đầu của mạng và thường sử dụng hàm kích hoạt relu.\n\n* Quá trình tổng hợp: Các lớp ở về sau quá trình chiết xuất đặc trưng sẽ có kích thước lớn do số đơn vị ở các lớp sau thường tăng tiến theo cấp số nhân. Điều đó làm tăng số lượng hệ số và khối lượng tính toán trong mạng nơ ron. Do đó để giảm tải tính toán chúng ta sẽ cần giảm chiều của ma trận hoặc giảm số đơn vị của lớp. Vì mỗi một đơn vị sẽ là kết quả đại diện của việc áp dụng 1 bộ lọc để tìm ra một đặc trưng cụ thể nên việc giảm số đơn vị sẽ không khả thi. Giảm kích thước ma trận thông qua việc tìm ra 1 giá trị đại diện cho mỗi một vùng không gian mà bộ lọc đi qua sẽ không làm thay đổi các đường nét chính của bức ảnh nhưng lại giảm được kích thước của ảnh. Do đó quá trình giảm chiều ma trận được áp dụng. Quá trình này gọi là tổng hợp.\n\n* Quá trình kết nối hoàn toàn: Sau khi đã giảm số lượng tham số đến một mức độ hợp lý, ma trận cần được làm dẹt (flatten) thành một vector và sử dụng các kết nối hoàn toàn giữa các lớp. Quá trình này sẽ diễn ra cuối mạng tích chập và sử dụng hàm kích hoạt là relu. Kết nối cuối cùng sẽ dẫn tới các đơn vị là đại diện cho mỗi lớp với hàm kích hoạt là softmax nhằm mục đích tính xác xuất.\n\n\n![](https://cdn-images-1.medium.com/max/800/1*NQQiyYqJJj4PSYAeWvxutg.png)\n\n$\\text{Hình 3: Cấu trúc đại diện của một mạng nơ ron tích chập, source: }$ [Mathworks.com]( Source: https://www.mathworks.com/videos/introduction-to-deep-learning-what-are-convolutional-neural-networks--1489512765771.html)\n\n\n## 1.4. Tính chất của mạng nơ ron tích chập\n\n**Tính kết nối trượt:** Khác với các mạng nơ ron thông thường, mạng nơ ron tích chập không kết nối tới toàn bộ hình ảnh mà chỉ kết nối tới từng *vùng địa phương* (local region) có kích thước bằng kích thước bộ lọc của hình ảnh đó. Các bộ lọc sẽ trượt theo chiều của ảnh từ trái qua phải và từ trên xuống dưới đồng thời tính toán các giá trị tích chập và điền vào *bản đồ kích hoạt* (activation map).\n\n![](https://developer.apple.com/library/archive/documentation/Performance/Conceptual/vImage/Art/kernel_convolution.jpg)\n\n$\\text{Hình 4: Tính tích chập trên bản đồ kích hoạt,  Source:}$ [developer.apple.com](https://developer.apple.com/library/archive/documentation/Performance/Conceptual/vImage/Art/kernel_convolution.jpg)\n\n![](https://raw.githubusercontent.com/iamaaditya/iamaaditya.github.io/master/images/conv_arithmetic/full_padding_no_strides_transposed.gif)\n\n$\\text{Hình 5: Quá trình trượt và tính tích chập của một bộ lọc kích thước 3x3 trên ảnh và kết nối tới bản đồ kích hoạt,  Source:}$ [github - iamaaditya](https://raw.githubusercontent.com/iamaaditya/iamaaditya.github.io/master/images/conv_arithmetic/full_padding_no_strides_transposed.gif)\n\n**Các khối nơ ron 3D:** Không giống như những mạng nơ ron thông thường khi cấu trúc ở mỗi lớp là một ma trận 2D (số quan sát và số đơn vị ở mỗi lớp). Các kết quả ở mỗi lớp của một mạng nơ ron là một khối 3D được sắp xếp một cách hợp lý theo 3 chiều `width, height, depth`. Trong đó các chiều width và height được tính toán theo công thức tích chập mục 1.1. Giá trị width ( height) của một lớp phụ thuộc vào kích thước của bộ lọc, chiều width (height) của lớp trước, độ rộng viền và bước trượt bộ lọc. Tuy nhiên chiều depth lại hoàn toàn không phụ thuộc vào những tham số này mà nó bằng với số đơn vị trong lớp đó. Quá trình tính bản đồ kích hoạt dựa trên một bộ lọc sẽ tạo ra một ma trận 2D. Như vậy khi áp dụng cho d bộ lọc khác nhau, mỗi bộ lọc ứng với một đơn vị trên mạng nơ ron, ta sẽ thu được d ma trận 2D có cùng kích thước. Khi sắp xếp chồng lấn các ma trận này kết quả đầu ra là một khối nơ ron 3D. Thông thường đối với xử lý ảnh thì lớp đầu vào nếu các bức ảnh đang để ở dạng màu RBG thì depth = 3 (số channels). Bên dưới là một cấu trúc mạng nơ ron điển hình có dạng khối.\n![](https://www.mdpi.com/remotesensing/remotesensing-09-00848/article_deploy/html/images/remotesensing-09-00848-g001.png)\n\n$\\text{Hình 6: Cấu trúc các khối nơ ron 3D mạng Alexnet,  Source:}$ [mdpi.com](https://www.mdpi.com/remotesensing/remotesensing-09-00848/article_deploy/html/images/remotesensing-09-00848-g001.png)\n\n**Tính chia sẻ kết nối và kết nối cục bộ:** Chúng ta đã biết quá trình biến đổi trong mạng tích chập sẽ kết nối các khối nơ ron 3D. Tuy nhiên các đơn vị sẽ không kết nối tới toàn bộ khối 3D trước đó theo chiều width và height mà chúng sẽ chọn ra các *vùng địa phương* có kích thước bằng với bộ lọc giống như quá trình tính tích chập. Các vùng địa phương sẽ được chia sẻ chung một bộ siêu tham số gọi là trường tiếp nhận (receptive field) của bộ lọc. Tuy nhiên các kết nối cục bộ chỉ diễn ra theo chiều width và height. Kết nối sẽ mở rộng hoàn toàn theo chiều depth. Như vậy số tham số trong một lớp sẽ là $F \\times F \\times D$ ($F, D$ lần lượt là kích thước bộ lọc và chiều depth).\n\nMỗi bộ lọc đại diện cho một khả năng chiết xuất một đặc trưng nào đó. Do đó khi đi qua toàn bộ các vùng địa phương của khối nơ ron 3D, các đặc trưng được chiết xuất sẽ hiển thị trên lớp mới.\n\n\n![](http://cs231n.github.io/assets/cnn/depthcol.jpeg)\n\n$\\text{Hình 7: Kết nối cục bộ,  Source:}$ [cs231n - stanford](http://cs231n.github.io/assets/cnn/depthcol.jpeg)\n\n> Giả sử ta có đầu vào là một bức ảnh 3 chiều kích tước 32x32x3. Khi đó mỗi đơn vị sẽ chỉ kết nối tới một vùng địa phương theo chiều width và height nhưng sẽ mở rộng hoàn toàn kết nối theo chiều depth. Chúng ta có tổng cộng 5 đơn vị (nơ ron) trong lớp cùng nhìn vào một vùng địa phương này và sẽ tạo ra cùng 1 vùng địa phương kích thước 1x1x5 trên khối nơ ron 3D mới.\n\n**Tính tổng hợp:** Chúng ta tưởng tượng rằng ở các lớp tích chập gần cuối số tham số sẽ cực kì lớn do sự gia tăng của chiều depth và thông thường sẽ theo cấp số nhân. Như vậy nếu không có một cơ chế kiểm soát sự gia tăng tham số, chi phí tính toán sẽ cực kì lớn và vượt quá khả năng của một số máy tính cấu hình yếu (*Như máy của mình chẳng hạn, hơi đáng buồn*). Một cách tự nhiên là chúng ta sẽ giảm kích thước các chiều width và height (down sampling) mà vẫn giữ nguyên được các đặc trưng của khối. Các thực hiện tương tự như tính tích chập nhưng thay vì tính tích hadamard giữa ma trận bộ lọc và vùng địa phương ta sẽ tính trung bình (average pooling) hoặc giá trị lớn nhất (max pooling) của các phần tử trong vùng địa phương. Trước đây các tính trung bình được áp dụng nhiều nhưng các mô hình hiện đại đã thay thế bằng giá trị lơn nhất do tốc độ tính max nhanh hơn so với trung bình.\n\n![](http://cs231n.github.io/assets/cnn/pool.jpeg)\n$\\text{Hình 7: Quá trình tổng hợp,  Source:}$ [cs231n - stanford](http://cs231n.github.io/assets/cnn/depthcol.jpeg)\n\n> Chẳng hạn chúng ta có một khối nơ ron 3D kích thước 224x224x64. Sẽ cần 224x224x64 = 3211264 tham số để kết nối tới khối này. Chúng ta sẽ giảm kích thước kết nối đến khối 4 lần thông qua giảm chiều width và height mỗi chiều 2 lần. Quá trình giảm chiều dữ liệu sẽ thực hiện lần lượt trên các lát cắt của chiều depth và không làm thay đổi độ lớn depth. Khối mới có đặc trưng không đổi.\n\n**Độ phức tạp phát hiện hình ảnh tăng dần:** Ở lớp đầu tiên hình ảnh mà chúng ta có chỉ là những giá trị pixels. Sau khi đi qua lớp thứ 2 máy tính sẽ nhận diện được các hình dạng cạnh, rìa và các đường nét đơn giản. Càng ở những lớp tích chập về sau càng có khả năng phát hiện các đường nét phức tạp hoặc vật thể. Đầu ra ở lớp cuối cùng là xác xuất thuộc về mỗi lớp. \n\n![](https://i.stack.imgur.com/oGBRR.jpg)\n$\\text{Hình 8: Hình ảnh mô phỏng các phát hiện sau mỗi lớp}$\n\n# 2. Xây dựng mạng nơ ron tích chập\n\nBên dưới ta sẽ tiến hanh xây dựng một mạng nơ ron tích chập phân biệt chữ số viết tay trong bộ số liệu mnist thông qua sử dụng API estimator của tensorflow. Phần source code này được lấy từ trang chủ của tensorflow và được hiệu chỉnh để phù hợp với mục đích của bài viết."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"b316adc0501048ef79e44f08bbb538263c61e9b4"},"cell_type":"code","source":"import tensorflow as tf \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\ndef cnn_model_fn(features, labels, mode):\n    \"\"\"Model function for CNN\"\"\"\n    #Input layer\n    input_layer = tf.reshape(features['x'], shape = [-1, 28, 28, 1])\n    \n    #Convolution layer 1\n    conv1 = tf.layers.conv2d(\n        inputs = input_layer,\n        filters = 32,\n        kernel_size = [5, 5],\n        padding = 'same',\n        activation = tf.nn.relu)\n    #Apply formula:N1 = (N+2P-f)/S + 1\n    #in which: N is input image size, P is padding size, f is filter size and S is step\n    #Output tensor shape: N1 = (28-5)/1+1 = 24 => shape = [-1, 24, 24, 1]\n    #But we at parameter we set padding = 'same' in order to keep output shape unchange to input shape \n    #Thus output shape is [-1, 28, 28, 1]\n    \n    #Max pooling layer 1\n    pool1 = tf.layers.max_pooling2d(\n        inputs = conv1, \n        pool_size = [2, 2],\n        strides = 2)\n    #Output tensor shape: N2 = (28-2)/2+1 = 14 => shape = [-1, 14, 14, 1]\n    \n    #Convolution layer 2\n    conv2 = tf.layers.conv2d(\n        inputs = pool1,\n        filters = 64,\n        kernel_size = [5, 5],\n        padding = 'same',\n        activation = tf.nn.relu)\n    #Output tensor shape: N3 = (14-5)/1+1 = 10 => shape = [-1, 10, 10, 1]\n    #But padding = 'same' so output shape is [-1, 14, 14, 1]\n    \n    #Max pooling layer 2\n    pool2 = tf.layers.max_pooling2d(\n        inputs = conv2,\n        pool_size = [2, 2],\n        strides = 2)\n    #Output tensor shape: N4 = (14-2)/2+1 = 7 => shape = [-1, 7, 7, 1]\n    \n    #Dense layer\n    flat = tf.reshape(pool2, [-1, 7*7*64])\n    dense = tf.layers.dense(\n        inputs = flat, \n        units = 1024,\n        activation = tf.nn.relu)\n    \n    dropout = tf.layers.dropout(\n        inputs = dense,\n        rate = 0.4,\n        training = mode == tf.estimator.ModeKeys.TRAIN)\n    \n    #Logits layer\n    logits = tf.layers.dense(inputs = dropout, units = 10)\n    \n    predictions = {\n        'classes': tf.argmax(input = logits, axis = 1, name = 'class_tensor'),\n        'probabilities': tf.nn.softmax(logits, name = 'softmax_tensor')}\n    \n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode = mode, predictions = predictions)\n\n    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = logits)\n    \n    if mode == tf.estimator.ModeKeys.TRAIN:\n        optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n        train_op = optimizer.minimize(\n            loss = loss, \n            global_step = tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode = mode, loss = loss, train_op = train_op)\n    \n    if mode == tf.estimator.ModeKeys.EVAL:\n        eval_metric_ops = {\n            'accuracy': tf.metrics.accuracy(\n            labels = labels, predictions = predictions['classes'])}\n        return tf.estimator.EstimatorSpec(\n            mode = mode, loss = loss, eval_metric_ops = eval_metric_ops)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26c65b5848e6d5e707e65354064b73d835d0338c"},"cell_type":"markdown","source":"Như vậy mạng nơ ron của chúng ta sẽ có cấu trúc:\n\n* Lớp input: Có kích thước [-1, 28, 28, 1], số -1 biểu thị bất kì số lượng bức ảnh nào có thể truyền vào mô hình. 3 thành phần còn lại là chiều rộng, chiều cao và kênh của bức ảnh.\n\n* Lớp tích chập số 1: Gồm 32 bộ lọc có kích thước [5, 5]. Chúng ta có thể khai báo đơn giản là `kernel_size = 5` trong trường hợp bộ lọc là vuông. Tham số `padding = same` để cố định kích thước của đầu ra so với đầu vào. Khi đó lớp sẽ tự động thêm viền ngoài để kích thước không đổi theo công thức $P = \\frac{W_1(S-1)-1+F}{2}$. Như vậy sau bước này kích thước đầu ra vẫn sẽ là [-1, 28, 28, 1].\n\n* Lớp chồng chất số 1: Có kích thước của bộ lọc là [2, 2] và bước nhảy là 2. Áp dụng công thức tính kích thước đầu ra ta sẽ suy ra w2 = h2 = (28-2)/2+1 = 14. Kích thước đầu ra sau bước này là [-1, 14, 14, 1].\n\n* Lớp tích chập số 2: Gồm 64 bộ lọc có kích thước [5, 5] và thám số `padding = same` sẽ không thay đổi kích thước đầu ra so với lớp trước là [-1, 14, 14, 1].\n\n* Lớp chồng chất số 2: Giống với lớp chồng chất số 1 với bộ lọc kích thước [2, 2] và bước nhảy 2. Do đó chiều dài và rộng của ma trận đầu ra sẽ là w2 = h2 = (14-2)/2+1 = 7. Kích thước đầu ra: [-1, 7, 7, 1].\n\n* Lớp vector dàn phẳng: Ma trận ở lớp trước sẽ được dành phẳng nên có kích thước là 7x7. Kết hợp với chiều sâu = 64 là số lượng đơn vị ở layer trước ta suy ra kích thước của lớp này là 7x7x64 = 3136.\n\n* Lớp dropout: Lớp này không làm thay đổi kích thước của lớp trước mà chỉ tác động vào quá trình training khi sẽ tắt ngẫu nhiên các đơn vị của lớp trước với xác xuất là `rate = 0.4` bằng cách gán cho trọng số ứng với đơn vị bị tắt bằng 0. Đây là một kĩ thuật trong *kiểm soát* (regularization) mô hình nhằm giảm thiểu overfiting và tăng mức độ chính xác của dự báo và tốc độ huấn luyện.\n\n* Lớp output: Là một kết nối hoàn toàn tới 10 đơn vị đại diện cho 10 nhóm chữ số cần phân loại.\n\nBên dưới chúng ta sẽ load dữ liệu đầu vào dưới dạng numpy."},{"metadata":{"trusted":true,"_uuid":"9fa4898d61431e817c3fe97133a0a66e02bd8f34"},"cell_type":"code","source":"import sys\n!{sys.executable} -m pip install python-mnist\n\nfrom mnist import MNIST\nmndata = MNIST('../input')\n\nmndata.load_training()\ntrain_data = np.asarray(mndata.train_images)/255.0\ntrain_labels = np.array(mndata.train_labels.tolist())\n\nmndata.load_testing()\ntest_data = np.asarray(mndata.test_images)/255.0\ntest_labels = np.array(mndata.test_labels.tolist())\n\nprint('Train images shape      : %s'%str(train_data.shape))\nprint('Train labels shape shape: %s'%str(train_labels.shape))\nprint('Test  images shape      : %s'%str(test_data.shape))\nprint('Test  labels shape shape: %s'%str(test_labels.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d380b0dd1879245325390c3579ed6655eceef41"},"cell_type":"markdown","source":"Khởi tạo Estimator"},{"metadata":{"trusted":false,"_uuid":"d59062ac7faa07cbade54caa66c035fd53f438e7"},"cell_type":"code","source":"#Create the Estimator\nmnist_classifier = tf.estimator.Estimator(\n    model_fn = cnn_model_fn, \n    model_dir = './tmp/conv2_checkpoints' #temporary file to save model\n)\n#Create the Logging Hook to tracking processing\n# tensors_to_log = {'probability': 'softmax_tensor',\n#                  'class_values': 'class_tensor'}\n\n# logging_hook = tf.train.LoggingTensorHook(\n#     tensors = tensors_to_log, \n#     every_n_iter = 50\n# )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eee23934b5006a6a0d30f4f7c5603d615d812041"},"cell_type":"markdown","source":"Khởi tạo hàm truyền dữ liệu"},{"metadata":{"trusted":false,"_uuid":"37e0faa1bf3871afdc28fe9483fc7dddfd4da5fa"},"cell_type":"code","source":"#Training model\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x = {'x': train_data},\n    y = train_labels, \n    batch_size = 100,\n    num_epochs = 50,\n    shuffle = True\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47144676e1508a155936f7c8903ff5956fd223b5"},"cell_type":"markdown","source":"Hàm truyền dữ liệu sẽ bao gồm 2 biến chính là biến dự báo $\\mathbf{x}$ và nhãn $\\mathbf{y}$ với kích thước bach_size = 100 và mỗi batch sẽ được cập nhật dữ liệu 1 lần. Khi chuyển qua batch mới sẽ thay đổi vị trí các quan sát.\n\nHuẩn luyện mô hình"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"eaad34b5f2f2f471c401d8fb4442cb91883ea903"},"cell_type":"code","source":"mnist_classifier.train(\n    input_fn = train_input_fn,\n    steps = 10000\n#     hooks = [logging_hook]\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed4066dee521023e16df3ae4e71ea3270e82e5a4"},"cell_type":"markdown","source":"Đánh giá mô hình trên tập test"},{"metadata":{"trusted":false,"_uuid":"37231f0364b4c7623d043c0656636498c7b3fa5f"},"cell_type":"code","source":"#Validation on test\neval_input_fn = tf.estimator.inputs.numpy_input_fn(\n      x = {\"x\": test_data},\n      y = test_labels,\n      num_epochs = 1,\n      shuffle = False)\n\neval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\nprint(eval_results)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1324ca2961f1bcf0418484ea75edf0da86ba0d8c"},"cell_type":"markdown","source":"# 3. Tài liệu \n1. [Tài liệu CS231n - Mạng nơ ron tích chập ứng dụng trong nhận diện hình ảnh - Standford](http://cs231n.github.io/convolutional-networks/)\n2. [Tích chấp 2 chiều - Blog machine learning cơ bản - Vũ Hữu Tiệp](https://machinelearningcoban.com/2018/10/03/conv2d)\n3. [Xây dựng mạng nơ ron tích chập sử dụng estimator - Tensoflow](https://www.tensorflow.org/tutorials/estimators/cnn)\n4. [Image kenel - Victor Powell](http://setosa.io/ev/image-kernels/)\n5. [Image Filtering - Blog Machine Learning Guru](http://machinelearninguru.com/computer_vision/basics/convolution/image_convolution_1.html)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}