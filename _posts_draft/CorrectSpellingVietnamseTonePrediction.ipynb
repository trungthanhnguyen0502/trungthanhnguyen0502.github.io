{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "1nmpcCvLzjgM",
    "outputId": "65a19961-e917-46ba-8ed5-40f748d28bf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n",
      "ADRCorrectSpellingVietnamseTonePrediction.ipynb  vietnamese_tone_prediction.zip\n",
      "data\t\t\t\t\t\t vietnamse_tone_prediction\n",
      "utils.py\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/gdrive')\n",
    "path = os.path.join('gdrive/My Drive/data/ADRCorrectSpelling/vietnamse_tone_prediction/vietnamse_tone_prediction')\n",
    "os.chdir(path)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "XRlXLrhblKkS"
   },
   "source": [
    "# 1. Giới thiệu chung\n",
    "Cùng với sự phát triển của deep learning nói chung. Ngày nay lớp các mô hình seq2seq càng tỏ ra hiệu quả trong nhiều tác vụ khác nhau như dịch máy, sửa lỗi chính tả, image captioning, recommendation, dự báo chuỗi thời gian,.... Nhờ sự phát triển của các kiến trúc mạng RNN hiện đại kèm theo các kĩ thuật learning hiệu quả như sử dụng thêm kiến trúc `attention layer`, các phương pháp cải thiện accuracy như ` teach_forcing, beam search` mà mô hình dịch máy ngày càng đạt độ chính xác cao. Các tài liệu về các phương pháp trên đã có nhiều tuy nhiên đa phần là lý thuyết và khá khó cho người mới bắt đầu tiếp cận. Bài viết này nhằm mục đích tạo ra một bản diễn giải kèm thực hành về các bước xây dựng mô hình seq2seq ứng dụng trong sửa lỗi chính tả. Để hiểu được các nội dung trong bài yêu cầu bạn đọc có kiến thức nền tảng về [pytorch](https://phamdinhkhanh.github.io/2019/08/10/PytorchTurtorial1.html), nắm vững lý thuyết về mạng [LSTM](https://phamdinhkhanh.github.io/2019/04/22/L%C3%BD_thuy%E1%BA%BFt_v%E1%BB%81_m%E1%BA%A1ng_LSTM.html). Ngoài ra bạn đọc cần có sẵn máy tính cài [pytorch](https://pytorch.org/) hoặc các VM hỗ trợ pytorch. Để tiện cho thực hành tôi khuyến nghị bạn đọc sử dụng [google colab](https://colab.research.google.com) miễn phí và cài sẵn các deep learning framework cơ bản như tensorflow, pytorch, keras,.... \n",
    "\n",
    "Ngoài ra bài viết được xây dựng và tổng hợp dựa trên nhiều nguồn tài liệu khác nhau. Đặc biệt là từ trang hướng dẫn thực hành [pytorch](https://pytorch.org/tutorials/beginner/chatbot_tutorial.html), từ ý tưởng được chia sẻ nằm trong top của cuộc thi [thêm dấu cho tiếng việt - aivivn 1st](https://forum.machinelearningcoban.com/t/aivivn-3-vietnamese-tone-prediction-1st-place-solution/5721), [thêm dấu cho tiếng việt - aivivn 2nd](https://forum.machinelearningcoban.com/t/aivivn-3-vietnamese-tone-prediction-2nd-place-solution/5759).\n",
    "\n",
    "Để huấn luyện mô hình trên google colab chúng ta cần mount folder lưu trữ dữ liệu trên google drive để có thể access dữ liệu dễ dàng. Bên dưới là câu lệnh thực hiện mount dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/gdrive')\n",
    "path = os.path.join('gdrive/My Drive/your_data_folder_link')\n",
    "os.chdir(path)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong đó `your_data_folder_link` là đường link tới folder chứa dữ liệu. Lưu ý link `gdrive/My Drive` là đường trỏ mặc định để đi vào thư mục `My Drive` của bạn.\n",
    "\n",
    "\n",
    "# 2. Chuẩn bị dữ liệu\n",
    "\n",
    "## 2.1. Giải nén dữ liệu\n",
    "Ở bước này chúng ta sẽ sử dụng đầu vào là dữ liệu của cuộc thi thêm dấu từ tiếng việt tại [aivivn](https://www.aivivn.com/contests/3). Bạn đọc có thể tải về bộ dữ liệu tại [google drive](https://drive.google.com/file/d/1m_5CDQQSavev5zWb8JUq97_zUTnOcVvS/view) dưới dạng zip file. Để giải nén dữ liệu ta cần extract bằng hàm extract bên dưới. Nhớ cài đặt package zipfile trước khi chạy lệnh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "won6cImdDcpT"
   },
   "outputs": [],
   "source": [
    "# Extract zip file\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def _extract_zip_file(fn_zip, fn):\n",
    "  with zipfile.ZipFile(fn, 'r') as zip_ref:\n",
    "      zip_ref.extractall(fn)\n",
    "\n",
    "_extract_zip_file(fn_zip = 'vietnamese_tone_prediction.zip', fn = 'vietnamse_tone_prediction')\n",
    "\n",
    "print(os.path.exists('vietnamse_tone_prediction'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "cH0Cc5bnmi67"
   },
   "source": [
    "Cùng lấy ra 500000 dòng đầu tiên của file `train.txt` trong folder giải nén làm tập huấn luyện. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "ZqNcpfBaz1lr",
    "outputId": "1f01ff14-fdf5-4549-a7aa-ef02c57c11b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train: 500000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Bộ phim lần đầu được công chiếu tại liên hoan phim Rome 2007 và sau đó được chiếu ở Fairbanks, Alaska ngày 21 tháng 9 năm 2007.',\n",
       " 'Những kiểu áo sơ mi may theo chất liệu cotton, KT, hay có chút co giãn năm nay cũng được các bạn trẻ ưa chuộng.',\n",
       " 'Đương kim tổng thống là Andrés Manuel López Obrador, người nhậm chức vào ngày 1 tháng 12 năm 2018.',\n",
       " 'Centaurea gloriosa là một loài thực vật có hoa trong họ Cúc.',\n",
       " 'Sau này mới thấy người ta nói, đó là con rắn đực đi tìm người ăn thịt để trả thù cho rắn cái, bà T cho biết thêm.']"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _data_train(fn):\n",
    "  with open(fn, 'r') as fn:\n",
    "    train = fn.readlines()\n",
    "  train = [item[:-1] for item in train[:500000]]  \n",
    "  return train\n",
    "\n",
    "train = _data_train(fn = 'vietnamse_tone_prediction/train.txt')\n",
    "print('length of train: {}'.format(len(train)))  \n",
    "train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "OQ-lHjUPm80Q"
   },
   "source": [
    "Bên dưới là một số hàm tiện ích để chuyển các từ có dấu của tiếng việt sang không dấu. Mục đích là để tạo ra các cặp (câu không dấu, câu có dấu) từ câu có dấu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "hDrQ2dvpXiat",
    "outputId": "c44913bb-6694-4b98-a75e-1e84df51a138"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Di mot ngay dang hoc 1 sang khon'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding=utf8\n",
    "import codecs\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "def remove_tone_line(utf8_str):\n",
    "    intab_l = \"ạảãàáâậầấẩẫăắằặẳẵóòọõỏôộổỗồốơờớợởỡéèẻẹẽêếềệểễúùụủũưựữửừứíìịỉĩýỳỷỵỹđ\"\n",
    "    intab_u = \"ẠẢÃÀÁÂẬẦẤẨẪĂẮẰẶẲẴÓÒỌÕỎÔỘỔỖỒỐƠỜỚỢỞỠÉÈẺẸẼÊẾỀỆỂỄÚÙỤỦŨƯỰỮỬỪỨÍÌỊỈĨÝỲỶỴỸĐ\"\n",
    "    intab = list(intab_l+intab_u)\n",
    "\n",
    "    outtab_l = \"a\"*17 + \"o\"*17 + \"e\"*11 + \"u\"*11 + \"i\"*5 + \"y\"*5 + \"d\"\n",
    "    outtab_u = \"A\"*17 + \"O\"*17 + \"E\"*11 + \"U\"*11 + \"I\"*5 + \"Y\"*5 + \"D\"\n",
    "    outtab = outtab_l + outtab_u\n",
    "\n",
    "    r = re.compile(\"|\".join(intab))\n",
    "    replaces_dict = dict(zip(intab, outtab))\n",
    "    return r.sub(lambda m: replaces_dict[m.group(0)], utf8_str)\n",
    "  \n",
    "remove_tone_line('Đi một ngày đàng học 1 sàng khôn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "iUO8G2i5nPFB"
   },
   "source": [
    "Để ý thấy hầu hết các dấu câu sẽ dính liền với câu. Chẳng hạn câu `tại khanh blog, tôi lưu lại các bài viết như một quyển nhật kí`. Thì từ `blog` và dấu phảy bị dính liền. Vì vậy ta cần sử dụng hàm `normalizeString()` để tách các dấu ra khỏi từ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "AaXz8kLfhLSM",
    "outputId": "d2b388f7-8244-4001-8541-579450128dce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vui vẻ , hòa đồng , hoạt bát'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tách dấu ra khỏi từ\n",
    "def normalizeString(s):\n",
    "    # Tách dấu câu nếu kí tự liền nhau\n",
    "    marks = '[.!?,-${}()]'\n",
    "    r = \"([\"+\"\\\\\".join(marks)+\"])\"\n",
    "    s = re.sub(r, r\" \\1 \", s)\n",
    "    # Thay thế nhiều spaces bằng 1 space.\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "normalizeString('vui vẻ, hòa đồng, hoạt bát')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "Q1BfGyX-n_j6"
   },
   "source": [
    "Sử dụng 2 hàm số trên để tạo ra các list `train` gồm các câu có dấu và `train_rev_accent` gồm các câu không dấu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "9f_bJfTk2j13",
    "outputId": "b15faf02-3c47-45ca-878f-7fc52810d345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train top 5: ['Bộ phim lần đầu được công chiếu tại liên hoan phim Rome 2007 và sau đó được chiếu ở Fairbanks , Alaska ngày 21 tháng 9 năm 2007 .', 'Những kiểu áo sơ mi may theo chất liệu cotton , KT , hay có chút co giãn năm nay cũng được các bạn trẻ ưa chuộng .', 'Đương kim tổng thống là Andrés Manuel López Obrador , người nhậm chức vào ngày 1 tháng 12 năm 2018 .', 'Centaurea gloriosa là một loài thực vật có hoa trong họ Cúc .', 'Sau này mới thấy người ta nói , đó là con rắn đực đi tìm người ăn thịt để trả thù cho rắn cái , bà T cho biết thêm .']\n",
      "train_rev_accent top 5: ['Bo phim lan dau duoc cong chieu tai lien hoan phim Rome 2007 va sau do duoc chieu o Fairbanks , Alaska ngay 21 thang 9 nam 2007 .', 'Nhung kieu ao so mi may theo chat lieu cotton , KT , hay co chut co gian nam nay cung duoc cac ban tre ua chuong .', 'Duong kim tong thong la Andres Manuel Lopez Obrador , nguoi nham chuc vao ngay 1 thang 12 nam 2018 .', 'Centaurea gloriosa la mot loai thuc vat co hoa trong ho Cuc .', 'Sau nay moi thay nguoi ta noi , do la con ran duc di tim nguoi an thit de tra thu cho ran cai , ba T cho biet them .']\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "train = [normalizeString(item) for item in train]\n",
    "train_rev_accent = [remove_tone_line(item) for item in train]\n",
    "\n",
    "print('train top 5:', train[:5])\n",
    "print('train_rev_accent top 5:', train_rev_accent[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "nAHV-zK43hF9"
   },
   "source": [
    "##  1.2. Load and Trim data\n",
    "\n",
    "Bên dưới ta sẽ xây dựng class Voc để xây dựng từ điển cho tập dữ liệu. Các hàm trong Voc có tác dụng:\n",
    "\n",
    "*  `addWord()`: Kiểm tra xem từ đã xuất hiện trong từ điển chưa. Nếu chưa sẽ thêm từ mới đó vào từ điển.\n",
    "* `addSentence()`: Truyền vào 1 câu và thêm các từ trong câu vào từ điển.\n",
    "* `trim()`: Loại bỏ các từ hiếm trong từ điển nếu nó có ngưỡng số tần xuất xuất hiện trong toàn bộ tập dữ liệu ít hơn `min_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "wM2EeM2w3Wge"
   },
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "xH280UZJ30CT"
   },
   "source": [
    "## 1.2. Chuẩn hóa dữ liệu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "DRH39PzNfS7x"
   },
   "source": [
    "### 1.2.1 Tạo ngram\n",
    "\n",
    "Trong dữ liệu có những câu rất dài làm giảm hiệu quả dự báo của mô hình. Do đó chúng ta sẽ tìm cách tạo ra các ngram với độ dài đo bằng số lượng từ cố định để dự báo trong một khoảng cách ngắn. Ở bài này ta sẽ lựa chọn ngram = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "bxykBee5gG65",
    "outputId": "70680eaa-aee8-4462-d75a-d0294fe42ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mùa đông năm nay', 'đông năm nay không', 'năm nay không còn', 'nay không còn lạnh', 'không còn lạnh nữa.', 'còn lạnh nữa. Vì', 'lạnh nữa. Vì đã', 'nữa. Vì đã có', 'Vì đã có gấu', 'đã có gấu 37', 'có gấu 37 độ', 'gấu 37 độ ấm']\n",
      "['mùa đông PAD PAD']\n"
     ]
    }
   ],
   "source": [
    "def _ngram(text, length = 4):\n",
    "  words = text.split()\n",
    "  grams = []\n",
    "  if len(words) <= length:\n",
    "    words = words + [\"PAD\"]*(length-len(words))\n",
    "    return [' '.join(words)]\n",
    "  else:\n",
    "    for i in range(len(words)-length+1):\n",
    "      grams.append(' '.join(words[i:(i+length)]))\n",
    "    return grams\n",
    "  \n",
    "print(_ngram('mùa đông năm nay không còn lạnh nữa. Vì đã có gấu 37 độ ấm'))\n",
    "print(_ngram('mùa đông'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "nG5fxFjaen3E"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "train_grams = list(itertools.chain.from_iterable([_ngram(item) for item in train]))\n",
    "train_rev_acc_grams = list(itertools.chain.from_iterable([_ngram(item) for item in train_rev_accent]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "cGJUdILaofXP",
    "outputId": "eed38c43-9fed-4f70-971b-63c2214dcafe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bo phim lan dau', 'Bộ phim lần đầu'),\n",
       " ('phim lan dau duoc', 'phim lần đầu được'),\n",
       " ('lan dau duoc cong', 'lần đầu được công'),\n",
       " ('dau duoc cong chieu', 'đầu được công chiếu'),\n",
       " ('duoc cong chieu tai', 'được công chiếu tại')]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(zip(train_rev_acc_grams, train_grams))\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "0hGs-Uyz3mnA",
    "outputId": "a4ae04a4-4ec1-44b2-fe0e-981dcb9da369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 9771412 sentence pairs\n",
      "Trimmed to 9771412 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 202153\n",
      "\n",
      "pairs:\n",
      "['Bo phim lan dau', 'Bộ phim lần đầu']\n",
      "['phim lan dau duoc', 'phim lần đầu được']\n",
      "['lan dau duoc cong', 'lần đầu được công']\n",
      "['dau duoc cong chieu', 'đầu được công chiếu']\n",
      "['duoc cong chieu tai', 'được công chiếu tại']\n",
      "['cong chieu tai lien', 'công chiếu tại liên']\n",
      "['chieu tai lien hoan', 'chiếu tại liên hoan']\n",
      "['tai lien hoan phim', 'tại liên hoan phim']\n",
      "['lien hoan phim Rome', 'liên hoan phim Rome']\n",
      "['hoan phim Rome 2007', 'hoan phim Rome 2007']\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "MAX_LENGTH = 4  # Maximum sentence length to consider\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    # Tách dấu câu nếu kí tự liền nhau\n",
    "    s = re.sub(r\"([.!?,\\-\\&\\(\\)\\[\\]])\", r\" \\1 \", s)\n",
    "    # Thay thế nhiều spaces bằng 1 space.\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Read query/response pairs and return a voc object\n",
    "def readVocs(lines, corpus_name = 'corpus'):\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(str(s)) for s in l] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "voc, pairs = readVocs(corpus)  \n",
    "  \n",
    "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# # Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(voc, pairs):\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    # pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "  \n",
    "# Load/Assemble voc and pairs\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "voc, pairs = loadPrepareData(voc, pairs)\n",
    "# Print some pairs to validate\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "FdqmczU-4ZKf"
   },
   "source": [
    "Model sẽ huấn luyện nhanh hơn nếu:\n",
    "\n",
    "* Giảm bớt số lượng các token không quá phổ biến.\n",
    "* Loại bỏ bớt các câu không phổ biến.\n",
    "\n",
    "Bên dưới ta sẽ xây dựng hàm số loại bỏ các token có tần suất nhỏ hơn ngưỡng MIN_COUNT và loại bỏ các câu có chứa token vừa bị loại bỏ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "HclqD4g64AYQ",
    "outputId": "4113d692-8f57-48fb-d8f0-9bde2048f88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 171772 / 202150 = 0.8497\n",
      "Trimmed from 9771412 pairs to 9741582, 0.9969 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "cYnklALNuwXe"
   },
   "source": [
    "Như vậy sau khi loại bỏ các từ hiếm với tần xuất xuất hiện <= 3 thì dữ liệu còn lại 87% số lượng các token và 99.81% các câu được dữ lại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "AmUqyASuHCr9"
   },
   "source": [
    "## 1.3. Tạo batch huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "uD5tMCQ3HkX3",
    "outputId": "f3ca0ec0-a3bc-437e-99ed-7fdf23db83a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS_token:  2\n",
      "SOS_token:  1\n",
      "PAD_token:  0\n"
     ]
    }
   ],
   "source": [
    "print('EOS_token: ', EOS_token)\n",
    "print('SOS_token: ', SOS_token)\n",
    "print('PAD_token: ', PAD_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "BwTTU_2B5L70"
   },
   "source": [
    "Bên dưới ta sẽ xây dựng các hàm chức năng, trong đó:\n",
    "\n",
    "* `indexesFromSentence()`: Mã hóa câu văn thành chuỗi index của các token theo giá trị của cặp word2index trong từ điển và đính thêm token EOS ở cuối để đánh dấu kết thúc câu. Chẳng hạn trong từ điển từ các từ tương ứng với index như sau: {'học':5, 'sinh':7, 'đi':9, 'EOS':2}, khi đó giá trị mã hóa index của câu 'học sinh đi học' sẽ là [5, 7, 9, 5,2].\n",
    "\n",
    "* `zeroPadding()`: Nhận đầu vào là 1 list các chuỗi index đại diện cho câu. Hàm này sẽ xác định câu có độ dài lớn nhất trong list. Sau đó padding thêm 0 vào cuối mỗi chuỗi index các giá trị 0 về cuối để các câu có độ dài bằng nhau và bằng độ dài lớn nhất.\n",
    "\n",
    "* `binaryMatrix()`: Một ma trận sẽ biểu diễn một batch của các câu truyền vào. Mỗi dòng của ma trận sẽ đại diện cho 1 câu. Trong ma trận này sẽ tồn tại những index tương ứng với vị trí padding. binaryMatrix sẽ đánh dấu các vị trí mà tương ứng với padding bằng 0 và tương ứng với từ bằng 1.\n",
    "\n",
    "* `inputVar()`: Nhận giá trị truyền vào là 1 list các câu input và từ điển. Hàm sẽ trả về ma trận được padding thêm 0 đại diện cho list các câu input và list độ dài tương ứng thực tế của các câu.\n",
    "\n",
    "* `outputVar()`: Nhận giá trị truyền vào là 1 list các câu output và từ điển. Về cơ bản cũng giống như `inputVar()` nhưng ngoài trả về ma trận padding và độ dài lớn nhất của các câu còn trả về thêm ma trận mask có kích thước bằng ma trận padding đánh dấu các vị trí là padding (=0) và từ (=1).\n",
    "\n",
    "* `batch2TrainData()`: Nhận giá trị truyền vào là các cặp câu (input, output) và từ điển. Hàm số sẽ khởi tạo batch cho huấn luyện mô hình bao gồm: ma trận batch input, ma trận batch output, ma trận mask đánh đấu padding của output. Ngoài ra còn trả thêm list độ dài thực tế các câu trong input và độ dài lớn nhất của các câu trong output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "Q7MiPpiOG1k5"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "# Padding thêm 0 vào list nào có độ dài nhỏ hơn về phía bên phải\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "  \n",
    "# Tạo ma trận binary có kích thước như ma trận truyền vào l nhưng giá trị của mỗi phần tử đánh dấu 1 hoặc 0 tương ứng với padding hoặc không padding\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 4\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "M2vR5fGp-QJy"
   },
   "source": [
    "Cuối cùng ta sẽ thử nghiệm giá trị trả ra của hàm `batch2TrainData()` khi lựa chọn ra 4 cặp câu bất kì trong list các cặp (input, output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "5AzM9h-r-O6C",
    "outputId": "a75620e5-8a26-4817-b0ba-1568408c7b0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: \n",
      " tensor([[  66,  369,   66, 1272],\n",
      "        [ 567,  183,   28,  616],\n",
      "        [ 392, 1558, 1143,  175],\n",
      "        [ 394,   31,   31, 5558],\n",
      "        [   2,    2,    2,    2]])\n",
      "lengths: \n",
      " tensor([5, 5, 5, 5])\n",
      "target_variable: \n",
      " tensor([[  66,  370,  124, 1275],\n",
      "        [ 568,  184,   29,  617],\n",
      "        [ 393, 1560, 1144, 6240],\n",
      "        [ 395,   31,   31, 5559],\n",
      "        [   2,    2,    2,    2]])\n",
      "mask: \n",
      " tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]], dtype=torch.uint8)\n",
      "max_target_len: \n",
      " 5\n"
     ]
    }
   ],
   "source": [
    "print(\"input_variable: \\n\", input_variable)\n",
    "print(\"lengths: \\n\", lengths)\n",
    "print(\"target_variable: \\n\", target_variable)\n",
    "print(\"mask: \\n\", mask)\n",
    "print(\"max_target_len: \\n\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "8XEzsZEnY0bb"
   },
   "source": [
    "# 2. Mô hình seq2seq sửa lỗi chính tả\n",
    "\n",
    "Model seq2seq sẽ nhận đầu vào là 1 chuỗi và trả ra kết quả output cũng là 1 chuỗi. Chính vì thế tên gọi của mô hình là sequence to sequence (từ câu đến câu). \n",
    "\n",
    "Trong kiến trúc của model seq2seq sẽ gồm 2 phrases: Encoder và decoder.\n",
    "\n",
    "* **Encoder**: Nhúng các từ thành những véc tơ embedding với kích thước tùy ý. Encoder sẽ xây dựng một chuỗi các xử lý liên hoàn sao cho output của bước liền trước là input của bước liền sau. Khi đó tại mỗi time step sẽ truyền đầu vào là các véc tơ đã được mã hóa ứng với mỗi từ $\\mathbf{x_i}$. Encoder sẽ  trả ra 2 kết quả ở đầu ra gồm: \n",
    "encoder outputs đại diện cho toàn bộ câu input trong đó mỗi véc tơ của encoder outputs đại diện cho 1 từ trong câu và hidden state của GRU cuối cùng.  hidden state sẽ được sử dụng để làm giá trị hidden khởi tạo cho quá trình Decoder (chi tiết ở hình 1 bên dưới). ma trận encoder outputs được sử dụng để tính attention weight tại mỗi time step trong phrase decoder. Để dễ hình dung output của một mạng RNN chúng ta có thể xem thêm [lý thuyết về mạng LSTM](https://phamdinhkhanh.github.io/2019/04/22/L%C3%BD_thuy%E1%BA%BFt_v%E1%BB%81_m%E1%BA%A1ng_LSTM.html). \n",
    "\n",
    "* Decoder: Sau phrase encoder ta sẽ thu được một hidden state của GRU cuối cùng và ma trận encoder outputs đại điện cho toàn bộ câu input. Phrase decoder có tác dụng giải mã thông tin đầu ra ở encoder thành các từ. Do đó tại mỗi time step đều trả ra các véc tơ phân phối xác xuất của từ tại bước đó. Từ đó ta có thể xác định được từ có khả năng xảy ra nhất tại mỗi time step. Tại time step $t$, mô hình sẽ  kết hợp giữa decoder embedding véc tơ $h_t$ đại diện cho token $word_t$ và ma trận encoder outputs theo cơ chế global attention (được đề xuất bởi anh Lương Mạnh Thắng) để tính ra trọng số attention weight phân bố cho vị trí từ ở câu input lên $word_t$. véc tơ context đại diện cho toàn bộ câu input sẽ được tính bằng tích trọng số của attention weight với từng encoder véc tơ của ma trận encoder outputs (cụ thể hình 3). Tiếp theo để dự báo cho từ kế tiếp $word_{t+1}$ ta cần kết hợp véc tơ decoder hidden state $h_{t+1}$ và véc tơ context như hình 5. Qúa trình này sẽ được lặp lại liên tục cho đến khi gặp token cuối cùng là `<EOS>` đánh dấu vị trí cuối của câu. Như vậy ta sẽ trải qua các bước:\n",
    "\n",
    "  * Tính decoder input chính là embedding véc tơ $h_t$ của từ đã biết $word_t$ dựa vào embedding layer.\n",
    "  \n",
    "  * Tính attention weight đánh giá mức độ tập trung của các từ input vào từ được dự báo dựa vào ma trận encoder outputs và $h_{t}$.\n",
    "  \n",
    "  * Tính context véc tơ $c_t$ chính là tích có trọng số của attention weights với các véc tơ đại diện cho mỗi từ input trong ma trận encoder outputs.\n",
    "  \n",
    "  * Truyền decoder input và last hidden state ở bước $t$ vào mô hình decoder GRU để tính ra được decoder hidden state $h_{t+1}$.\n",
    "  \n",
    "  * Kết hợp decoder hidden state $h_{t+1}$ và context véc tơ $c_t$ để dự báo từ tại time step $t+1$.\n",
    "\n",
    "Quá trình tiếp tục cho đến khi gặp token `<EOS>` đánh dấu kết thúc câu. \n",
    "\n",
    "Kết quả đầu ra là chuỗi các indexes (lấy theo vocabulary) đại diện cho từng từ tại mỗi vị trí của câu.\n",
    "\n",
    "![Seq2seq model](https://pytorch.org/tutorials/_images/seq2seq_ts.png)\n",
    "> **Hình 1:** Sơ đồ Encoder và Decoder sử dụng mạng GRU trong mô hình seq2seq.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "gxbdQejj7DOA"
   },
   "source": [
    "\n",
    "## 2.1. Encoder\n",
    "\n",
    "Tại phrase encoder chúng ta sẽ sử dụng kiến trúc mạng bidirectional GRU (2 chiều) như bên dưới để mã hóa thông tin.\n",
    "\n",
    "![Bidirectional GRU](https://pytorch.org/tutorials/_images/RNN-bidirectional.png)\n",
    "> **Hình 2:** Kiến trúc mạng bidirectional GRU. Khác với mạng unidirectional GRU (1 chiều) chỉ có chiều từ trái qua phải. Mạng GRU 2 chiều sẽ đánh giá thêm chiều từ phải qua trái. Điều này giúp cho việc học được đầy đủ hơn khi sự phụ thuộc của các từ trong câu luôn tuân theo cả 2 chiều.\n",
    "  \n",
    "Lưu ý một embedding layer được áp dụng để mã hóa các từ về một véc tơ với kích thước được khai báo là `hidden_size`. Khi huấn luyện xong model, embedding layer sẽ có kết quả sao cho những từ gần nghĩa sẽ được đại diện bởi những vec tơ sao cho độ tương quan về nghĩa càng lớn. Độ tương quan này được đo bằng cosin similarity của các embedding véc tơ của mỗi từ.\n",
    "\n",
    "Mô hình RNN sẽ nhận đầu vào là một batch. Để padding một batch vào model RNN thì chúng ta phải pack dữ liệu bằng hàm `nn.utils.rnn.pack_padded_sequence` để tự động padding thêm 0 vào các véc tơ từ. Và ở bước decoder chúng ta phải unpack phần zero padding bao quanh đầu ra bằng hàm `nn.utils.rnn.pad_packed_sequence`.\n",
    "\n",
    "Bên dưới ta sẽ xây dựng Module encoder.\n",
    "\n",
    "**Quá trình tính toán của đồ thị:**  \n",
    "1. Mã hóa các từ về index và embedding các index thành các véc tơ.\n",
    "2. Xác định batch cho mô hình. Padding câu về chung 1 độ dài và đóng gói thành batch bằng hàm `nn.utils.rnn.pack_padded_sequence`.\n",
    "3. Thực hiện quá trình feed forward.\n",
    "4. unpack các zero padding bằng hàm `nn.utils.rnn.pad_packed_sequence`\n",
    "5. Tính tổng của bidirectional GRU outputs theo hai chiều trái và phải.\n",
    "6. Trả về encoder output của layer GRU cuối cùng và hidden state tại layer cuối cùng.\n",
    "  \n",
    "Các tham số của model:\n",
    "\n",
    "**Inputs**:\n",
    "\n",
    "* `input_seq`: Batch của các câu đầu vào dưới dạng tensor (như tham số input được trả ra của hàm `batch2trainData()`). `shape = max_length x batch_size`. Trong đó `batch_size` là kích thước batch (tương ứng với số câu được đưa vào batch) và `max_length` là kích thước của câu văn đã được pad hoặc trim về độ dài chuẩn.\n",
    "* `input_lengths`: list của độ dài thực tế (không tính pad hoặc trim) các câu tương ứng trong batch.\n",
    "\n",
    "**Outputs**:\n",
    "\n",
    "* `outputs`: hidden layer cuối cùng của GRU (tổng của bidirectional outputs). Trên hình chính là GRU  tại vị trí $\\mathbf{x_n}$; `shape = (max_length, batch_size, hidden_size)` . Trong đó `max_length` là độ dài của câu. `batch_size` là kích thước batch. `hidden_size` là số chiều mã hóa của embedding layer.\n",
    "\n",
    "* `hidden`: là ma trận concatenate của các hidden state được cập nhật từ mỗi layer của GRU; `shape = (n_layers x num_directions, batch_size, hidden_size)`. Trong đó:\n",
    "\n",
    "  * `n_layers` là số layers GRU được áp dụng. Số lượng layers này sẽ bằng chính số lượng hidden state của mạng GRU.\n",
    "\n",
    "  * `hidden_size` chính là kích thước của embedding véc tơ ứng với mỗi từ. \n",
    "\n",
    "  * `num_bidirections` là số chiều của mạng GRU. Trong trường hợp này là 2 chiều.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "WpuFdLDso0Rv"
   },
   "source": [
    "Trước tiên ta cần khai báo sử dụng pytorch cuda bằng đoạn code bên dưới. hàm `torch.cuda.is_available()` sẽ tự động kiểm tra xem máy có GPU hỗ trợ CUDA hay không. Nếu có sẽ khai báo `device` là `cuda` và trái lại sẽ sử dụng `cpu` để huấn luyện mô hình. Và tất nhiên là tốc độ huấn luyện trên `cuda` nhanh hơn rất nhiều."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "xbigdGgYpACM"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "FPmH2Cm1Ib34"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        # set bidirectional = True for bidirectional\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=gru#torch.nn.GRU to get more information\n",
    "        self.gru = nn.GRU(input_size = hidden_size, # number of expected feature of input x \n",
    "                          hidden_size = hidden_size, # number of expected feature of hidden state \n",
    "                          num_layers = n_layers, # number of GRU layers\n",
    "                          dropout=(0 if n_layers == 1 else dropout), # dropout probability apply in encoder network\n",
    "                          bidirectional=True # one or two directions.\n",
    "                         )\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Step 1: Convert word indexes to embeddings\n",
    "        # shape: (max_length , batch_size , hidden_size)\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module. Padding zero when length less than max_length of input_lengths.\n",
    "        # shape: (max_length , batch_size , hidden_size)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Step 2: Forward packed through GRU\n",
    "        # outputs is output of final GRU layer\n",
    "        # hidden is concatenate of all hidden states corresponding with each time step.\n",
    "        # outputs shape: (max_length , batch_size , hidden_size x num_directions)\n",
    "        # hidden shape: (n_layers x num_directions , batch_size , hidden_size)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding. Revert of pack_padded_sequence\n",
    "        # outputs shape: (max_length , batch_size , hidden_size x num_directions)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs to reshape shape into (max_length , batch_size , hidden_size)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # outputs shape:(max_length , batch_size , hidden_size)\n",
    "        # hidden shape: (n_layers x num_directions , batch_size , hidden_size)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "o5lO97XVKHbU"
   },
   "source": [
    "Để kiểm nghiệm kết quả trả ra của EncoderRNN bên dưới ta sẽ thực hiện 1 ví dụ giả lập encoder với `hidden_size` = 3 và `n_layers = 7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "kbqBK1C0GeBf",
    "outputId": "d1a7faca-11e3-4b50-c0cf-5384c8aece83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_seq: \n",
      " tensor([[  66,  369,   66, 1272],\n",
      "        [ 567,  183,   28,  616],\n",
      "        [ 392, 1558, 1143,  175],\n",
      "        [ 394,   31,   31, 5558],\n",
      "        [   2,    2,    2,    2]])\n",
      "input_lengths: \n",
      " tensor([5, 5, 5, 5])\n",
      "encoder: \n",
      " EncoderRNN(\n",
      "  (embedding): Embedding(171775, 3)\n",
      "  (gru): GRU(3, 3, num_layers=7, bidirectional=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Thử nghiệm phrase Encoder bằng cách giả lập 1 mạng Encoder với:\n",
    "from torch import nn\n",
    "\n",
    "hidden_size = 3\n",
    "n_layers = 7\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "print('input_seq: \\n', input_variable)\n",
    "print('input_lengths: \\n', lengths)\n",
    "encoder = EncoderRNN(hidden_size = hidden_size, embedding = embedding, n_layers = n_layers)\n",
    "\n",
    "print('encoder phrase: \\n', encoder)\n",
    "\n",
    "output, hidden = encoder.forward(input_seq = input_variable, input_lengths = lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "OTbu3O3JH743",
    "outputId": "884bff09-71a5-47e0-87da-46aa041af397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size:  torch.Size([5, 4, 3])\n",
      "hidden size:  torch.Size([14, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "print('output size: ', output.size())\n",
    "print('hidden size: ', hidden.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "Jtb3VEnALxx6"
   },
   "source": [
    "Ta nhận thấy đầu ra của output là `(max_length, batch_size, hidden_size)` và của hidden là `(n_layers x num_directions, batch_size, hidden_size)`. Thông qua ví dụ này bạn đọc đã hình dung được quá trình Encoder rồi chứ.\n",
    "\n",
    "## 2.2. Decoder \n",
    "Như vậy sau bước encoder ta thu được output là layer GRU cuối cùng (gọi là encoder outputs) và các hidden state của layer GRU cuối cùng. Bước tiếp theo chúng ta cần giải mã các kết quả thu được từ encoder thành câu hoàn chỉnh. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "THxHNH22ZSC4"
   },
   "source": [
    "### 2.2.1. Áp dụng Attention layer\n",
    "Ở phrase này chúng ta sẽ sử dụng thêm 1 layer attention để tính phân phối trọng số attention weights cho các véc tơ từ (hidden state) của ma trận encoder outputs. attention weight sẽ có kích thước bằng đúng độ dài của câu. Sau khi tính tổng theo attention weights ta sẽ thu được context véc tơ đại diện cho toàn bộ câu. Quá hình này được thể hiện như hình 5. context véc tơ sẽ kết hợp với các decoder hidden state (các thẻ $h_t$ màu đỏ trong hình 5) tại mỗi time step để dự đoán từ tiếp theo. decoder hidden state chính là outptut trả ra của model Decoder sau mỗi time step. Quá trình này lặp lại truy hồi (output layer trước làm input cho layer sau) cho đến khi kết quả trả về là `<EOS>`  (end of sequence).\n",
    "\n",
    "Hình bên dưới sẽ minh họa cho quá trình tính toán attention weigths dựa trên sự kết hợp của decoder input (véc tơ embedding của từ được dự báo ở bước trước), decoder hidden state (ma trận của các hidden state sau cùng) và encoder outputs.\n",
    "\n",
    "<img src=\"https://pytorch.org/tutorials/_images/attn2.png\" width=\"600px\" style=\"display:block; margin-left:auto; margin-right:auto\"/>\n",
    "\n",
    "\n",
    "> **Hình 3:** Kết hợp giữa decoder input, decoder hidden state và encoder outputs để tạo ra một attended encoder outputs.\n",
    "  \n",
    "Các bạn đã hình dung được quá trình kết hợp attention vào decoder rồi chứ? Điểm mấu chốt là chúng ta phải tính ra được các trọng số attention tại mỗi time step. Việc tính toán attention weight đã được đề xuất theo rất nhiều cách khác nhau bởi anh [Lương Mạnh Thắng](https://arxiv.org/abs/1508.04025). Trong đó điểm cải tiến so với cha đẻ của attention layer Bahdanau chính là một `global attention` được tính toán trên toàn bộ encoder hidden state thay vì `local attention` được tính toán dựa trên chỉ encoder hidden state của time step hiện tại. Điểm khác biệt thứ 2 là global attention tính attention weight chỉ dựa trên decoder hidden state tại time step hiện tại thay vì `local attention` được đề xuất bởi Bahdanau yêu cầu thêm các decoder hidden state trước đó.  Theo đó điểm của các attention ở time step hiện tại được anh Thắng Lương đề xuất dưới nhiều công thức khác nhau như hình bên dưới.\n",
    "\n",
    "<img src=\"https://pytorch.org/tutorials/_images/scores.png\" width=\"400px\" style=\"display:block; margin-left:auto; margin-right:auto\"/>\n",
    "\n",
    "> **Hình 4:** Tính điểm tại time step t dựa trên decoder hidden state ($h_t$) của thời điểm $t$ và toàn bộ các encoder hidden states ($\\bar{h_s}$).\n",
    "  \n",
    "Các bước tiếp theo để tính context véc tơ ta có thể tham khảo ở bài diễn giải về [attention is all you need](https://phamdinhkhanh.github.io/2019/06/18/AttentionLayer.html).\n",
    "\n",
    "Cơ chế tính context véc tơ có thể khái quát hóa như hình bên dưới. Lưu ý chúng ta sẽ triển khai `Attention Layer` như một `nn.Module` tách biệt và được gọi là `Attn`. Kết quả của attention layer là `attention weights` là một phân phối xác xuất hàm softmax dưới dạng tensor có kích thước `(batch_size, 1, max_length)`.\n",
    "\n",
    "<img src=\"https://pytorch.org/tutorials/_images/global_attn.png\" width=\"600px\" style=\"display:block; margin-left:auto; margin-right:auto\"/>\n",
    "> **Hình 5:** Cơ chế global attention. \n",
    "  \n",
    "  \n",
    "  Bên dưới là code của class `Attention`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "mtx3fiFrSD2o"
   },
   "outputs": [],
   "source": [
    "# Luong attention layer\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        # encoder_output shape:(max_length , batch_size , hidden_size)\n",
    "        # hidden shape: (1 , batch_size , hidden_size)\n",
    "        # return shape: (max_length, batch_size)\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        # encoder_output shape:(max_length , batch_size , hidden_size)\n",
    "        # hidden shape: (batch_size , hidden_size)\n",
    "        # energy shape: (max_length , batch_size , hidden_size)\n",
    "        # return shape: (max_length , batch_size)\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        # encoder_output shape:(max_length , batch_size , hidden_size)\n",
    "        # hidden shape: (batch_size , hidden_size)\n",
    "        # energy shape: (max_length , batch_size , 2*hidden_size)\n",
    "        # self.v shape: (hidden_size)\n",
    "        # return shape: (max_length , batch_size)\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        # attn_energies.shape: (max_length , batch_size)\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        # attn_energies.shape: (batch_size , max_length)\n",
    "        attn_energies = attn_energies.t()\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        attn_weights = F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "        # attn_weights shape: (batch_size , 1 , max_length)\n",
    "        return attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "82JPMd8fmzxe"
   },
   "source": [
    "Để hiểu rõ hơn attention hoạt động như thế nào ta sẽ cùng thử nghiệm truyền vào decoder hidden là các hidden state véc tơ của decoder và encoder outputs là ma trận mã hóa đầu ra của toàn bộ các từ trong câu input. Ví dụ bên dưới ta sẽ xét ở time step 0 nên decoder hidden khi đó sẽ là véc tơ hidden state cuối cùng của encoder (tham số last_hidden_encoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "mQSqgugwVcR_",
    "outputId": "9d89d502-2860-45d4-bee2-ee002e6605e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_hidden_encoder.size:  torch.Size([1, 4, 3])\n",
      "encoder_outputs.size:  torch.Size([5, 4, 3])\n",
      "hidden_size:  3\n",
      "decoder_hidden_size:  7\n",
      "attn_weights shape:  torch.Size([4, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "method = 'dot'\n",
    "# Take last hidden encoder vector as a initialize of decoder\n",
    "last_hidden_encoder = hidden[encoder.n_layers, :, :].unsqueeze(0)\n",
    "print('last_hidden_encoder.size: ', last_hidden_encoder.size())\n",
    "print('encoder_outputs.size: ', output.size())\n",
    "print('hidden_size: ', hidden_size)\n",
    "decoder_hidden_size = 7\n",
    "print('decoder_hidden_size: ', decoder_hidden_size)\n",
    "\n",
    "attn = Attn(method = method, hidden_size = decoder_hidden_size)\n",
    "attn_weights = attn.forward(hidden = last_hidden_encoder, encoder_outputs = output)\n",
    "print('attn_weights shape: ', attn_weights.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "52r79O-PZfMM"
   },
   "source": [
    "Như vậy tại mỗi time step để tính attention weights chúng ta sẽ truyền vào một decoder hidden véc tơ (chính là output của GRU tại time step đó) và ma trận encoder outputs. Thông qua các phương pháp dot_score, general_score hoặc concat_score ta sẽ tính được attention weights đại diện cho mức độ attention của từng vị trí của encoder outputs lên từ được dự báo. \n",
    "\n",
    "Qua diễn giải trên chúng ta mới chỉ hiểu cách thức mà attention hoạt động. Vậy thì attention được áp dụng trong toàn bộ quá trình decoder như thế nào tại mỗi time step. Để hiểu rõ chúng ta tìm hiểu qua phrase decoder.\n",
    "\n",
    "### 2.2.2. Quá trình Decoder\n",
    "\n",
    "Trong bước decoder chúng ta sẽ truyền một từ một lần tại mỗi time step. Do đó các véc tơ embedding của từ và GRU output phải có chung shape là `(1, batch_size, hidden_size)`.\n",
    "\n",
    "**Quá trình tính toán đồ thị**\n",
    "1. Lấy embedding của input word hiện tại.\n",
    "2. thực hiện lan truyền thuận (feed forward) qua một GRU 1 chiều (unidirectional GRU) để thu được decoder hidden state.\n",
    "3. Tính attention weights từ decoder hidden state của GRU hiện tại ở bước 2 kết hợp với encoder outputs của encoder.\n",
    "4. Nhân attention weights với encoder outputs để thu được một tổng có trọng số là context véc tơ.\n",
    "5. Concatenate context véc tơ và GRU output.\n",
    "6. Dự báo từ tiếp theo (không sử dụng softmax).\n",
    "7. Trả về output và hidden state cuối cùng.\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "* `input_step`: một bước thời gian tương ứng với 1 từ của input sequence; shape = (1, batch_size).\n",
    "* `last_hidden`: layer GRU cuối cùng; shape=(n_layers x num_directions, batch_size, hidden_size).\n",
    "* `encoder_outputs`: đầu ra của bước encoder; shape = (max_length, batch_size, hidden_size).\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "* `output`: softmax normalized tensor trả về xác xuất tương ứng với mỗi từ là từ tại vị trí tương ứng của câu; shape=(batch_size, voc.num_words)\n",
    "* `hidden`: hidden state cuối cùng của GRU; shape=(n_layers x num_directions, batch_size, hidden_size). Do ở phrase decoder ta chỉ áp dụng unidirectional GRU nên shape = (n_layers , batch_size, hidden_size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "yctYTZn3SPKZ"
   },
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        '''\n",
    "        input_step: list time step index of batch. shape (1 x batch_size)\n",
    "        last_hidden: last hidden output of hidden layer (we can take in right direction or left direction upon us) which have shape = (n_layers x batch_size x hidden_size)\n",
    "        encoder_outputs: output of encoder \n",
    "        '''\n",
    "        #===========================================\n",
    "        # Step 1: Embedding current sequence index\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        # embedded shape: 1 x batch_size x hidden_size\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        \n",
    "        #===========================================\n",
    "        # Step 2: pass embedded and last hidden into decoder\n",
    "        # Forward through unidirectional GRU\n",
    "        # rnn_output shape: 1 x batch_size x hidden_size\n",
    "        # hidden shape: n_layers x batch_size x hidden_size\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        # attn_weights shape: batch_size x 1 x max_length\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        # encoder_outputs shape: max_length x batch_size x hidden_size\n",
    "        # context shape: batch_size x 1 x hidden_size\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        # rnn_output shape: batch_size x hidden_size\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        # context shape: batch_size x hidden_size\n",
    "        context = context.squeeze(1)\n",
    "        \n",
    "        #===========================================\n",
    "        # Step 3: calculate output probability distribution \n",
    "        # concat_input shape: batch_size x (2*hidden_size)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        # concat_output shape: batch_size x hidden_size\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        # output shape: output_size\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "qFKg4r8nf-of"
   },
   "source": [
    "Bên dưới ta sẽ giải thích quá trình dự đoán các từ tiếp theo tại time step đầu tiên. Lưu ý quá trình được thực hiện trên batch nên các đầu vào sẽ có kích thước scale theo batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "l-uraIX6YghI",
    "outputId": "3d907d89-ea9d-4d9a-d164-c22e1ec6d80c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size:  4\n",
      "input_step.size at time_step 0:  torch.Size([1, 4])\n",
      "last_hidden.size:  torch.Size([7, 4, 3])\n",
      "luongAttnDecoderRNN phrase: \n",
      " LuongAttnDecoderRNN(\n",
      "  (embedding): Embedding(171775, 3)\n",
      "  (embedding_dropout): Dropout(p=0.1)\n",
      "  (gru): GRU(3, 3, num_layers=7, dropout=0.1)\n",
      "  (concat): Linear(in_features=6, out_features=3, bias=True)\n",
      "  (out): Linear(in_features=3, out_features=171772, bias=True)\n",
      "  (attn): Attn()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "time_step = 0\n",
    "# Take all index of batch at time step 0. All words are <SOS> mark for start of sentences.\n",
    "input_step = torch.tensor([SOS_token] * small_batch_size).unsqueeze(0)\n",
    "n_layers = 7\n",
    "# take last hidden vector of encoder\n",
    "last_hidden = hidden[:n_layers]\n",
    "print('batch_size: ', small_batch_size)\n",
    "print('input_step.size at time_step 0: ', input_step.size())\n",
    "print('last_hidden.size: ', last_hidden.size())\n",
    "attn_model = 'dot'\n",
    "hidden_size = 3\n",
    "# Output size of decoder model is size of vocabulary\n",
    "output_size = len(voc.word2index)\n",
    "\n",
    "\n",
    "luongAttnDecoderRNN = LuongAttnDecoderRNN(attn_model = attn_model,\n",
    "                                         embedding = embedding,\n",
    "                                         hidden_size = hidden_size,\n",
    "                                         output_size = output_size,\n",
    "                                         n_layers = n_layers)\n",
    "\n",
    "print('luongAttnDecoderRNN phrase: \\n', luongAttnDecoderRNN)\n",
    "dec_output, dec_hidden = luongAttnDecoderRNN.forward(input_step = input_step, \n",
    "                                                     last_hidden = last_hidden, \n",
    "                                                     encoder_outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "o27KsdvXcriL",
    "outputId": "ec2efbef-78a8-40b4-b0d0-9afda47600de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec_output.size:  torch.Size([4, 171772])\n",
      "dec_hidden.size:  torch.Size([7, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "print('dec_output.size: ', dec_output.size())\n",
    "print('dec_hidden.size: ', dec_hidden.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "aIeiV2-RinPR"
   },
   "source": [
    "\n",
    "**Diễn giải hàm forward:**\n",
    "\n",
    "Như vậy sau khi truyền vào decoder embedding véc tơ đại diện cho từ liền trước kết hợp với last hidden output của chính time step trước (có kích thước = `n_layers x hidden_size`) ta sẽ thu được decoder hidden state véc tơ (chính là các rnn_output trong hàm `luongAttnDecoderRNN.forward()`). Đây chính là một quá trình lan truyền thuật thông thường của một mạng RNN.\n",
    "\n",
    "Tiếp theo kết hợp decoder hidden state véc tơ với encoder outputs thu được ở phrase encoding ta sẽ tính được attention weight và từ đó suy ra context véc tơ. concatenate context véc tơ và decoder hidden state véc tơ tạo thành feature learning. Truyền feature learning véc tơ này qua hàm softmax ta sẽ tìm được véc tơ phân phối của từ tại vị trí time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "asB1Ho85ZrVU"
   },
   "source": [
    "# 3. Huấn luyện model.\n",
    "## 3.1 Loss function\n",
    "\n",
    "Bởi vì chúng ta huấn luyện mô hình dựa trên các batch đã được padding nên không đơn thuần là đưa toàn bộ các phần tử của output vào để tính toán giá trị của loss function mà cần có thêm một binary mask tensor để xác định các vị trí padding của target tensor. Khi đó loss function được tính toán dựa trên decoder's output tensor, target tensor và binary mask tensor. Hàm loss function chính là trung bình âm của log likelihood của toàn bộ các phần tử tương ứng với 1 trong 1 trong binary mask tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "MI4zSapvZoKx"
   },
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "MB6G7PALb4oL"
   },
   "source": [
    "## 3.2. Huấn luyện vòng lặp đơn\n",
    "\n",
    "Hàm huấn luyện `train()` bên dưới sẽ được xây dựng để huấn luyện cho 1 batch đơn lẻ.\n",
    "\n",
    "**Các kĩ thuật sử dụng**\n",
    "\n",
    "Chúng ta sẽ sử dụng 2 kĩ thuật để hỗ trợ hội tụ:\n",
    "\n",
    "* **teacher forcing**: Tại một ngưỡng xác xuất nào đó được thiết lập thông qua tham số `teacher_forcing_ratio`, chúng ta sẽ sử dụng luôn current target word như là đầu vào cho decoder tại bước tiếp theo hơn là sử dụng dự báo từ mô hình tại bước hiện tại. Kĩ thuật này hỗ trợ cho quá trình huấn luyện hiệu quả hơn. Tuy nhiên điểm hạn chế là có thể khiến cho mô hình thiếu ổn định trong quá trình suy diễn, khi decoder có thể không có cơ hội học đủ các khả năng để tạo ra output sequence trong quá trình huấn luyện. Do đó phải hết sức cẩn thận khi sử dụng `teacher_forcing_ratio`.\n",
    "\n",
    "* **gradient clipping**: Hay còn gọi là kĩ thuật kẹp gradient để tránh hiện tượng bùng nổ gradient (exploding gradient - gradient lớn quá nhanh) bằng các thiết lập giá trị max cho gradient descent.\n",
    "\n",
    "**Chuỗi các bước triển khai**\n",
    "\n",
    "1. Truyền vào toàn bộ các batch của câu qua encoder.\n",
    "2. Khởi tạo decoder input bằng token `<SOS>` (start of sequence) và encoder's hidden state cuối cùng.\n",
    "3. Truyền input batch sequence vào decoder một lần tại một time step.\n",
    "4. Nếu thực hiện teaching forcing: Thiết lập decoder input tiếp theo chính là giá trị target hiện tại; trái lại: thiết lập decoder input tiếp theo như là đầu ra của decoder hiện tại.\n",
    "5. Tính loss function.\n",
    "6. Thực hiện lan truyền ngược.\n",
    "7. Kẹp gradient tránh hiện tượng bùng nổ tham số.\n",
    "8. Cập nhật các tham số của encoder và decoder cho mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "SI2ktqdxWt7L"
   },
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "aHs0ew-2cB8f"
   },
   "source": [
    "## 3.3. Huấn luyện vòng lặp\n",
    "\n",
    "Cuối cùng đã đến lúc gắn kết toàn bộ quy trình huấn luyện với dữ liệu. Hàm `trainIters` chịu trách nhiệm chạy các `n_interations` quá trình huấn luyện từ các đầu vào gồm các model, hàm tối ưu optimizer, dữ liệu, v.v.\n",
    "\n",
    "Một lưu ý là khi chúng ta lưu mô hình, chúng ta lưu vào một tarball (một dạng folder) chứa encoder và decoder state_dicts (chính là các tham số), optimizers’ state_dicts, the loss, iteration, .... Lưu mô hình theo cách này sẽ mang lại sự linh hoạt cho mô hình nhờ checkpoint. Sau khi load một checkpoint, chúng ta sẽ có thể sử dụng các tham số mô hình để chạy suy diễn hoặc có thể tiếp tục huấn luyện ngay tại trạng thái rời đi trước đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "97RVcycEW9Bk"
   },
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, \n",
    "               encoder_optimizer, decoder_optimizer, \n",
    "               embedding, encoder_n_layers, decoder_n_layers, \n",
    "               save_dir, n_iteration, batch_size, print_every, \n",
    "               save_every, clip, corpus_name, loadFilename):\n",
    "    '''\n",
    "    model_name: Tên model\n",
    "    voc: bộ từ vựng cho mô hình\n",
    "    pairs: list các cặp (input, output)\n",
    "    encoder: phrase encoder\n",
    "    decoder: phrase decoder\n",
    "    encoder_optimizer: phương pháp tối ưu hóa encoder\n",
    "    decoder_optimizer: phương pháp tối ưu hóa decoder\n",
    "    embedding: layer embedding\n",
    "    encoder_n_layers: số lượng layers ở encoder\n",
    "    decoder_n_layers: số lượng layers ở decoder\n",
    "    save_dir: link save model\n",
    "    n_iteration: số iteration tổng cộng được chọn ngẫu nhiên từ pairs. Mỗi iteration = 1 batch\n",
    "    batch_size: kích thước của batch.\n",
    "    print_every: số iteration của batch để in kết quả\n",
    "    save_every: số iteration của batch để save model\n",
    "    clip: trimming giá trị của tensor về 1 range\n",
    "    corpus_name: tên bộ từ vựng\n",
    "    loadFilename: link load file\n",
    "    '''\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "ife5icOCcKSW"
   },
   "source": [
    "# 4. Xác định phương pháp đánh giá\n",
    "\n",
    "Sau khi huấn luyện mô hình, chúng ta đã có khả năng giao tiếp với bot. Muốn như vậy cần phải xác định xem chúng ta muốn mô hình mã hóa đầu vào như thế nào. Chúng ta có những cách giải mã sau:\n",
    "\n",
    "**Mã hóa tham lam (greedy decoding)**\n",
    "Các mã hóa này được sử dụng trong tính huống không sử dụng có teacher forcing. Đầu ra của mô hình tại mỗi time step đơn giản là từ với xác xuất cao nhất. \n",
    "\n",
    "Bên dưới chúng ta tạo ra class `GreedySearchDecoder` nhận đầu vào là một câu input với shape (input_seq length, 1), một scalar độ dài đầu vào (input_length) tensor, và một max_length để giới hạn độ dài lớn nhất của câu trả về. Câu đầu vào sẽ được đánh giá qua các bước như đồ thị bên dưới.\n",
    "\n",
    "**Đồ thị tính toán**:\n",
    "\n",
    "1. Truyền input qua model encoder.\n",
    "2. Chuẩn bị hidden layer cuối cùng của encoder làm hidden input đầu tiên của decoder.\n",
    "3. Khởi tạo input đầu tiên của decoder là `<SOS>`\n",
    "4. Khởi tạo tensor để append vào các từ được giải mã vào.\n",
    "5. Lặp lại quá trình giải mã một word token 1 lần:\n",
    "  1. Truyền vào decoder.\n",
    "  2. Thu được word token dự báo dựa trên xác xuất lớn nhất.\n",
    "  3. Lưu lại token và score.\n",
    "  4. Coi token hiện tại như là đầu vào tiếp theo của decoder.\n",
    "6. Trả về một tợp hợp các từ và điểm số.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "vW2O_eG6WfSB"
   },
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "GdBFKFzVcYHY"
   },
   "source": [
    "**Đánh giá câu dự báo**\n",
    "Qua bước trên chúng ta đã có hàm decoder xác định câu đầu ra dựa trên câu đầu vào. Hàm đánh giá quản lý quá trình xử lý câu đầu vào mức độ thấp. Trước tiên, chúng ta định dạng câu dưới dạng một batch đầu vào của các word index với batch_size = 1. Chúng ta thực hiện điều này bằng cách chuyển đổi các từ của câu thành các indexes tương ứng và transpose để chuẩn bị tensor cho các mô hình. Chúng ta cũng tạo ra một tensor độ dài chứa độ dài của câu đầu vào. Trong trường hợp này, độ dài là scalar vì chúng ta chỉ đánh giá một câu tại một thời điểm (batch_size = 1). Tiếp theo, chúng ta thu được một tensor các câu trả về được giải mã bằng cách sử dụng object `GreedySearchDecoder` (trình tìm kiếm). Cuối cùng, chúng tôi chuyển đổi các indexes trả về thành các từ và trả về danh sách các từ được giải mã.\n",
    "\n",
    "class `evaluateInput` hoạt động như giao diện người dùng cho chatbot. Khi được gọi, một input text field sẽ sinh ra trong đó chúng ta có thể nhập câu hỏi của mình. Sau khi nhập câu đầu vào và nhấn Enter, text sẽ được chuẩn hóa giống như dữ liệu huấn luyện và cuối cùng được đưa vào hàm đánh giá để thu được câu đầu ra được giải mã. Chúng ta lặp lại quy trình này cho liên tục cho đến khi nhấn `q` hoặc `quit` để quit.\n",
    "\n",
    "Cuối cùng, nếu một câu được nhập có chứa một từ không có trong từ vựng, chúng ta sẽ xử lý việc này một cách tinh tế bằng cách in một thông báo lỗi và nhắc người dùng nhập một câu khác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "dcE31cuKcZG-"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "3TnVktO-cctL"
   },
   "source": [
    "# 5. Huấn luyện model\n",
    "\n",
    "Bên dưới ta sẽ thực hiện huấn luyện mô hình bằng cách thiết lập các tham số. Chúng ta có thể thử nghiệm nhiều tham số cấu hình khác nhau để lựa chọn được 1 mô hình tối ưu. Chúng ta cũng có thể xây dựng mô hình từ đầu hoặc load từ checkpoint một mô hình sẵn có.\n",
    "\n",
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "H4Dy7ezecgFv",
    "outputId": "20ded227-f02c-47e6-f184-d1302ee2e48c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'correct_spelling_model'\n",
    "corpus_name = 'corpus_aivivn'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 100\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None\n",
    "checkpoint_iter = 5000\n",
    "    \n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "# if loadFilename:\n",
    "#     embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "kpdzfNDX-wX5"
   },
   "source": [
    "Khi muốn load một model từ check point chúng ta chỉ cần thay đổi loadFilename như bên dưới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "oBHenx_e-4BF"
   },
   "outputs": [],
   "source": [
    "# Khi muốn load model thì enable đoạn dưới để tạo file lưu địa model training.  \n",
    "loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "                           '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "                           '{}_checkpoint.tar'.format(checkpoint_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "3Bmy-v2hcl1U"
   },
   "source": [
    "## 5.1. Huấn luyện model \n",
    "\n",
    "Để huấn luyện mô hình trước tiên ta cần thiết lập các tham số. Gọi vào hàm `trainIters` để huấn luyện qua các vòng lặp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "0RY1uKUtcpW2",
    "outputId": "c3b9facc-9f23-4f57-c50d-d07b61e835c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n",
      "Iteration: 100; Percent complete: 2.0%; Average loss: 6.7370\n",
      "Iteration: 200; Percent complete: 4.0%; Average loss: 5.0068\n",
      "Iteration: 300; Percent complete: 6.0%; Average loss: 3.5866\n",
      "Iteration: 400; Percent complete: 8.0%; Average loss: 2.3804\n",
      "Iteration: 500; Percent complete: 10.0%; Average loss: 1.8249\n",
      "Iteration: 600; Percent complete: 12.0%; Average loss: 1.5482\n",
      "Iteration: 700; Percent complete: 14.0%; Average loss: 1.3622\n",
      "Iteration: 800; Percent complete: 16.0%; Average loss: 1.2253\n",
      "Iteration: 900; Percent complete: 18.0%; Average loss: 1.1341\n",
      "Iteration: 1000; Percent complete: 20.0%; Average loss: 1.0986\n",
      "Iteration: 1100; Percent complete: 22.0%; Average loss: 1.0536\n",
      "Iteration: 1200; Percent complete: 24.0%; Average loss: 1.0119\n",
      "Iteration: 1300; Percent complete: 26.0%; Average loss: 0.9666\n",
      "Iteration: 1400; Percent complete: 28.0%; Average loss: 0.9291\n",
      "Iteration: 1500; Percent complete: 30.0%; Average loss: 0.9200\n"
     ]
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 5000\n",
    "print_every = 100\n",
    "save_every = 1000\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "85qZFwyTcxrL"
   },
   "source": [
    "## 5.2 Đánh giá model\n",
    "\n",
    "Bên dưới chúng ta cùng đánh giá mô hình thông qua việc dự đoán một số từ không dấu. Lưu ý rằng do dữ liệu được huấn luyện chỉ là các ngram có 4 từ nên chúng ta sẽ truyền vào các cụm 4 từ. Để thêm dấu cho 1 câu văn với độ dài tùy ý bạn đọc có thể chia câu thành các ngram với kích thước 4 và ghép các kết quả dự báo trên từng ngram đơn lẻ. Hàm này tôi sẽ không viết ở đây và xin dành cho bạn đọc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "id": "zgPDdm8Tcyj2",
    "outputId": "46226dc7-7f22-4130-9a3f-5b5ef48dfd00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> tai nguyen thien nhien\n",
      "Bot: tài nguyên thiên nhiên\n",
      "> thuong mai dien tu\n",
      "Bot: thương mại điện tử\n",
      "> hoc sinh cap 1\n",
      "Bot: học sinh cấp 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-bc9e9ab9e7f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Begin chatting (uncomment and run the following line to begin)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mevaluateInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-697ba0b24fe3>\u001b[0m in \u001b[0;36mevaluateInput\u001b[0;34m(encoder, decoder, searcher, voc)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Get input sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0minput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'> '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Check if it is quit case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'q'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "evaluateInput(encoder, decoder, searcher, voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "gOx15kTE_KTz"
   },
   "source": [
    "# 6. Hạn chế của mô hình\n",
    "\n",
    "Mô hình seq2seq luôn tồn tại một số hạn chế nhất định mà chúng ta sẽ nhận ra trong quá trình huấn luyện đó là:\n",
    "\n",
    "* Mô hình rất tốn tài nguyên và thời gian huấn luyện lâu. Để huấn luyện mô hình dịch máy, google đã huy động một hệ thống máy chủ mà diện tích có thể trải trên 1 km2.\n",
    "\n",
    "* Mô hình sẽ không thêm dấu chính xác đối với những cụm từ mà chúng chưa từng được học. Do đó để nâng cao mức độ chuẩn xác ngoài cần một kiến trúc mô hình mạnh thì một tập dữ liệu đủ lớn.\n",
    "\n",
    "* Trong bài tôi sử dụng mô hình theo word level. Chính vì thế kích thước của vocabolary là rất lớn và sẽ ảnh hưởng đến số lượng parameter của model.\n",
    "\n",
    "* Huấn luyện mô hình theo character level sẽ có lợi thế hơn khi các từ thay đổi chỉ nằm trong tập các chữ cái `ueoaidy`. Do đó chúng ta sẽ teacher forcing để chỉ thay đổi các từ nằm trong tập `ueoaidy` và không thay đổi các từ còn lại.\n",
    "\n",
    "* Mô hình mới chỉ xây dựng cho các cụm từ ngram với kích thước bằng 4. Để dự báo cho câu với độ dài tùy ý dựa trên ngram = 4 xin dành cho bạn đọc.\n",
    "\n",
    "* Lớp model transformer cũng là một trong những mô hình cân nhắc thay thế cho seq2seq trong bài toán này vì tốc độ tính toán nhanh, có thể xử lý trên nhiều GPU. Bạn đọc có thể tham khảo ý tưởng của đội xếp 2nd của cuộc thi thêm dấu tiếng việt.\n",
    "\n",
    "# 7. Tài liệu tham khảo\n",
    "\n",
    "1. [hướng dẫn pytorch](https://phamdinhkhanh.github.io/2019/08/10/PytorchTurtorial1.html)\n",
    "2. [lý thuyết về mạng LSTM](https://phamdinhkhanh.github.io/2019/04/22/L%C3%BD_thuy%E1%BA%BFt_v%E1%BB%81_m%E1%BA%A1ng_LSTM.html)\n",
    "3. [seq2seq pytorch](https://pytorch.org/tutorials/beginner/chatbot_tutorial.html)\n",
    "4. [tensor2tensor project](https://github.com/tensorflow/tensor2tensor)\n",
    "5. [attention là tất cả bạn cần](https://phamdinhkhanh.github.io/2019/06/18/AttentionLayer.html)\n",
    "6. [thêm dấu cho tiếng việt - aivivn 1st](https://forum.machinelearningcoban.com/t/aivivn-3-vietnamese-tone-prediction-1st-place-solution/5721)\n",
    "7. [thêm dấu cho tiếng việt - aivivn 2nd](https://forum.machinelearningcoban.com/t/aivivn-3-vietnamese-tone-prediction-2nd-place-solution/5759)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ADRCorrectSpellingVietnamseTonePrediction.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
