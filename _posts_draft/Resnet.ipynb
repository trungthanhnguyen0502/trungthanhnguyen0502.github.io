{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBjcKwLWQFPY"
      },
      "source": [
        "# 1. ResNet history\n",
        "\n",
        "ResNet is outstanding CNN network that have both model size and accuracy is bigger than MobileNet. It was firstly launched in 2015 in a paper [Deep Resual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf) and very soon to gain the first rank on ILSVLC 2015. It allow you to tunning the model's deepth according to your requirement as flexiable as possible. Thus, i guess that you have ever meet several kinds of ResNet deepth version such as ResNet18, ResNet34, ResNet50, ResNet101, ResNet152. They keep the same block architecture that we throughly make it clear in this paper. Such blocks are stacked in side by side from the start to the end that are enable to us adjust the output shape being graduatelly smaller.\n",
        "\n",
        "The most particular characteristic in ResNet is that skip connection is applied inside each block. Such to help model keep residual from the past to future. Hence, the ResNet is abreviation for `Residual Learning Network`.\n",
        "\n",
        "So, what is architecture of Residual block in ResNet? how to implement ResNet from scratch. I am going to help you deeply dive into.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZnO9VdBWMAL"
      },
      "source": [
        "# 2. General Architecture\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dPQpdSI-Jz-"
      },
      "source": [
        "\n",
        "## 2.1. Batch Normalization\n",
        "\n",
        "ResNet is very first architecture applied Batch Normalization inside each Residual block on the basis of exploration is that model can be easily to meet the vanishing gradient descent when it is deeper. Batch Normalization help to keep stable on gradient descent and support the training process convergence quickly to optimal point.\n",
        "\n",
        "Batch normalization is applied on each mini-batch by standard normalization $\\mathbf{N}(0, 1)$. For example, we have $\\mathcal{B} =\\{ x_1, x_2, \\dots , x_m \\}$, $m$ foot index indicates your mini-batch size. All input samples are re-scaling as bellow:\n",
        "\n",
        "\n",
        "$$\\begin{eqnarray}\\mu & = & \\frac{1}{m} \\sum_{i=1}^{m} x_i \\\\\n",
        "\\sigma^2 & = & \\frac{1}{m}\\sum_{i=1}^{m}(x_i-\\mu)^2\n",
        "\\end{eqnarray}$$\n",
        "\n",
        "the new normalized-sample:\n",
        "\n",
        "$$\\hat{x}_i = \\frac{x_i-\\mu}{\\sigma}$$\n",
        "\n",
        "To normalization being more generalization, we usually set mini-batch size higher such as 128 or 256."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IDfzbbhcuFs"
      },
      "source": [
        "\n",
        "\n",
        "## 2.2. Skip Connection\n",
        "\n",
        "The authors also thoroughly scout the efficiency of the deepth changing to model accuracy. Actually, when model deepth increases and approaches the given length we meet the accuracy saturation, further increasing in the deepth may lead to degration. It is the evidence state that to improve model accuracy is not just simply make it deeper.\n",
        "\n",
        "![](https://imgur.com/IGNcHHc.png)\n",
        "\n",
        "Source [Figure 1 - Deep Resual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)\n",
        "\n",
        "> Training error (left) and test error (right) on CIFAR-10\n",
        "with 20-layer and 56-layer `plain` networks. The deeper network\n",
        "has higher training error, and thus test error.\n",
        "\n",
        "So one solution the authors applied is to add identify mapping layer to copy the shallow learned layer into deeper layer. identify mapping layer is directly plus previous input block into output block with the same shape.\n",
        "\n",
        "![](https://imgur.com/hQCHTUR.png)\n",
        "\n",
        "Source [Figure 2 - Deep Resual Learning for Image Recognition] Skip Connection (or shortcut connection) on ResNet block.\n",
        "\n",
        "We assume that output of shallow learned layer is $\\mathbf{x}$, the feed forward non-linear transform it into $\\mathcal{F}(\\mathbf{x})$. We hypothesize reality output of the whole process is $\\mathcal{H}(\\mathbf{x})$. So the residual between deeper layer compared with shallower layer is:\n",
        "\n",
        "$$\\mathcal{F}(\\mathbf{x}; \\{{W_i}\\}) := \\mathcal{H}(\\mathbf{x}) - \\mathbf{x}$$\n",
        "\n",
        "\n",
        "$\\{{W_i}\\}$ are the model parameters in many convolutional layers of $\\mathcal{F}$ transformation and also being to learn in backpropagation.\n",
        " \n",
        "The learning process actually study non-linear transform $\\mathcal{F}(\\mathbf{x}; \\{{W_i}\\})$ of residual after each block between input and output. It is going to be easier than learning non-linear transform input to output in directly way.\n",
        "\n",
        "the skip connections simply perform identity mapping, and their outputs are added to the outputs of the stacked layers. So, we simply name it as `indentity` block.\n",
        "\n",
        "The other block we applied convolutional transformation before skip connection from input layers to output layers in order to study feature learning.\n",
        "\n",
        "$$\\mathbf{y} = \\mathcal{F}(\\mathbf{x}; \\{{W_i}\\}) + \\text{Conv}(\\mathbf{x})$$\n",
        "\n",
        "To keep output's shape unchange and reduce the total parameters, $\\text{Conv}$ layers normally have kernel size `1 x 1`.\n",
        "\n",
        "![](https://imgur.com/rzRehsD.png)\n",
        "\n",
        "Source [ResNet block with and without  1Ã—1  convolution](https://d2l.ai/chapter_convolutional-modern/resnet.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVee4uTHx3S2"
      },
      "source": [
        "# 3. How to build up Residual Block\n",
        "\n",
        "After you firmly understand general architecture of Residual Block, i introduce you how can build up this fantastic block from scratch on three common deep learning frameworks. Beside, i facilitate to you practice on the [colab notebook](https://colab.research.google.com/drive/1Ni4JsbZRN6Q8sMkz2Y2c9NAEn3hgeD01?usp=sharing).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xcNk8zOyJ_k"
      },
      "source": [
        "**tensorflow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zugu8RQyyHrf",
        "outputId": "1558896f-de47-4806-80ae-73940dbacbe7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class ResidualBlockTF(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_channels, output_channels, strides=1, is_used_conv11=False, **kwargs):\n",
        "    super(ResidualBlockTF, self).__init__(**kwargs)\n",
        "    self.is_used_conv11 = is_used_conv11\n",
        "    self.conv1 = tf.keras.layers.Conv2D(num_channels, padding='same', \n",
        "                                        kernel_size=3, strides=1)\n",
        "    self.batch_norm = tf.keras.layers.BatchNormalization()\n",
        "    self.conv2 = tf.keras.layers.Conv2D(num_channels, padding='same', \n",
        "                                        kernel_size=3, strides=1)\n",
        "    if self.is_used_conv11:\n",
        "      self.conv3 = tf.keras.layers.Conv2D(num_channels, padding='same', \n",
        "                                          kernel_size=1, strides=1)\n",
        "    # Last convolutional layer to reduce output block shape.\n",
        "    self.conv4 = tf.keras.layers.Conv2D(output_channels, padding='same',\n",
        "                                        kernel_size=1, strides=strides)\n",
        "    self.relu = tf.keras.layers.ReLU()\n",
        "\n",
        "  def call(self, X):\n",
        "    if self.is_used_conv11:\n",
        "      Y = self.conv3(X)\n",
        "    else:\n",
        "      Y = X\n",
        "    X = self.conv1(X)\n",
        "    X = self.relu(X)\n",
        "    X = self.batch_norm(X)\n",
        "    X = self.relu(X)\n",
        "    X = self.conv2(X)\n",
        "    X = self.batch_norm(X)\n",
        "    X = self.relu(X+Y)\n",
        "    X = self.conv4(X)\n",
        "    return X\n",
        "\n",
        "X = tf.random.uniform((4, 28, 28, 1)) # shape=(batch_size, width, height, channels)\n",
        "X = ResidualBlockTF(num_channels=1, output_channels=64, strides=2, is_used_conv11=True)(X)\n",
        "print(X.shape)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 14, 14, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJP4u9hGyNii"
      },
      "source": [
        "**pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diaG-TMEySz9",
        "outputId": "01cfde29-b8ba-41f7-8479-50e8fdb13dd0"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class ResidualBlockPytorch(nn.Module):\n",
        "  def __init__(self, num_channels, output_channels, strides=1, is_used_conv11=False, **kwargs):\n",
        "    super(ResidualBlockPytorch, self).__init__(**kwargs)\n",
        "    self.is_used_conv11 = is_used_conv11\n",
        "    self.conv1 = nn.Conv2d(num_channels, num_channels, padding=1, \n",
        "                           kernel_size=3, stride=1)\n",
        "    self.batch_norm = nn.BatchNorm2d(num_channels)\n",
        "    self.conv2 = nn.Conv2d(num_channels, num_channels, padding=1, \n",
        "                           kernel_size=3, stride=1)\n",
        "    if self.is_used_conv11:\n",
        "      self.conv3 = nn.Conv2d(num_channels, num_channels, padding=0, \n",
        "                           kernel_size=1, stride=1)\n",
        "    # Last convolutional layer to reduce output block shape.\n",
        "    self.conv4 = nn.Conv2d(num_channels, output_channels, padding=0, \n",
        "                           kernel_size=1, stride=strides)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    \n",
        "  def forward(self, X):\n",
        "    if self.is_used_conv11:\n",
        "      Y = self.conv3(X)\n",
        "    else:\n",
        "      Y = X\n",
        "    X = self.conv1(X)\n",
        "    X = self.relu(X)\n",
        "    X = self.batch_norm(X)\n",
        "    X = self.relu(X)\n",
        "    X = self.conv2(X)\n",
        "    X = self.batch_norm(X)\n",
        "    X = self.relu(X+Y)\n",
        "    X = self.conv4(X)\n",
        "    return X\n",
        "\n",
        "X = torch.rand((4, 1, 28, 28)) # shape=(batch_size, channels, width, height)\n",
        "X = ResidualBlockPytorch(num_channels=1, output_channels=64, strides=2, is_used_conv11=True)(X)\n",
        "print(X.shape)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 64, 14, 14])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI501Oy5yP_r"
      },
      "source": [
        "**mxnet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CStmtA5N768z"
      },
      "source": [
        "Google colab docker may be unavailable mxnet pakcage. In case of missing, you install very simple as bellow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaWtOY4y59Rd",
        "outputId": "00a3d478-84ba-4836-c93f-3b869ba7f8a8"
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.6/dist-packages (1.7.0.post1)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.19.4)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPLJxtOEySXV",
        "outputId": "65dae09d-d860-4925-e848-f0005e99b2da"
      },
      "source": [
        "import mxnet as mx\n",
        "from mxnet.gluon import nn as mxnn\n",
        "\n",
        "class ResidualBlockMxnet(mxnn.Block):\n",
        "  def __init__(self, num_channels, output_channels, strides=1, is_used_conv11=False, **kwargs):\n",
        "    super(ResidualBlockMxnet, self).__init__(**kwargs)\n",
        "    self.is_used_conv11 = is_used_conv11\n",
        "    self.conv1 = mxnn.Conv2D(num_channels, padding=1, \n",
        "                           kernel_size=3, strides=1)\n",
        "    self.batch_norm = mxnn.BatchNorm()\n",
        "    self.conv2 = mxnn.Conv2D(num_channels, padding=1, \n",
        "                           kernel_size=3, strides=1)\n",
        "    if self.is_used_conv11:\n",
        "      self.conv3 = mxnn.Conv2D(num_channels, padding=0, \n",
        "                           kernel_size=1, strides=1)\n",
        "    self.conv4 = mxnn.Conv2D(output_channels, padding=0, \n",
        "                           kernel_size=1, strides=strides)\n",
        "    self.relu = mxnn.Activation('relu')\n",
        "    \n",
        "  def forward(self, X):\n",
        "    if self.is_used_conv11:\n",
        "      Y = self.conv3(X)\n",
        "    else:\n",
        "      Y = X\n",
        "    X = self.conv1(X)\n",
        "    X = self.relu(X)\n",
        "    X = self.batch_norm(X)\n",
        "    X = self.relu(X)\n",
        "    X = self.conv2(X)\n",
        "    X = self.batch_norm(X)\n",
        "    X = self.relu(X+Y)\n",
        "    X = self.conv4(X)\n",
        "    return X\n",
        "\n",
        "X = mx.nd.random.uniform(shape=(4, 1, 28, 28)) # shape=(batch_size, channels, width, height)\n",
        "res_block = ResidualBlockMxnet(num_channels=1, output_channels=64, strides=2, is_used_conv11=True)\n",
        "# you must initialize parameters for mxnet block.\n",
        "res_block.initialize()\n",
        "X = res_block(X)\n",
        "print(X.shape)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 64, 14, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dzOUBTX8WiJ"
      },
      "source": [
        "As you can see, building the Residual Block is not quite hard with support of high level API on all frameworks: tensorflow keras, pytorch and mxnet gluon. They are all the same arrange of layers on the feed-forward process. Next step we shall deeply analyze of how to build up ResNet architectures under variate of model's deepth options. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPN4owLz97Ee"
      },
      "source": [
        "# 4. ResNet model\n",
        "\n",
        "There are many kind of ResNet version changing by deepth. If you want to applied them on edge devices, you may concern to light weight ResNet18, ResNet34, ResNet50 models. In opposite aspect, you consider more about accuracy, computation resource is not a such big problem, i suggest you choose deeper models such as ResNet101, ResNet152.\n",
        "\n",
        "Actually, in my current task related to label generation, i define to need one model that are good enough to make quality labels. Thus training another bigger model version that are separeted from my original model. Absolutely, bigger model is high computational cost and inappropriate to deploy on edge device.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD0O-W3BDho0"
      },
      "source": [
        "## 4.1. Architecture of ResNet model\n",
        "\n",
        "In generally, the common architecture of those different deepth ResNet models have the same rule. So, i introduce to you the analysis and the implementation of ResNet-18 architecture as such bellow description:\n",
        "\n",
        "![](https://imgur.com/TBnUbVO.png)\n",
        "\n",
        "ResNet-18 architecture.\n",
        "\n",
        "The starting layer is Convol2D `7 x 7`, we choose bigger kernel size because of input shape is largest to capture features in the wider context. The coherent idea applied during the whole models that is the one batch normalization layer follow right behind each convolutional layer.\n",
        "\n",
        "Residual block is enveloped by dash rectangle with 5 stacked layers in figure 3. The two starting residual blocks are identify blocks. After that, we repeat three times `[convolutional mapping + identity mapping]`. Finally, global average pooling applied to capture general features according to the deepth dimension and forward the final fully connected output.\n",
        "\n",
        "Because of the repetation of residual blocks, we are going to neatly design the code to serve the general architecture in which only need to define each kind of block (indentity or convolution mapping) in each position. The sequential model module is the most prudent choice with such kind of stacked architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7eKmjQvLNjT"
      },
      "source": [
        "## 4.2. Practice coding\n",
        "\n",
        "I introduce to you three coding styles on tensorflow, pytorch, mxnet in order. They are share the same procedure. Through this practice, you facilitate to apply the given CNN architecture on any deep learning framework.\n",
        "\n",
        "**tensorflow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ7nW7woNH7p",
        "outputId": "13ca05bc-92ed-464f-f934-fca17dde5d4e"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class ResNet18TF(tf.keras.Model):\n",
        "  def __init__(self, residual_blocks, output_shape):\n",
        "    super(ResNet18TF, self).__init__()\n",
        "    self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=7, strides=2, padding='same')\n",
        "    self.batch_norm = tf.keras.layers.BatchNormalization()\n",
        "    self.max_pool = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=2, padding='same')\n",
        "    self.relu = tf.keras.layers.ReLU()\n",
        "    self.residual_blocks = residual_blocks\n",
        "    self.global_avg_pool = tf.keras.layers.GlobalAvgPool2D()\n",
        "    self.dense = tf.keras.layers.Dense(units=output_shape)\n",
        "\n",
        "  def call(self, X):\n",
        "    X = self.conv1(X)\n",
        "    X = self.batch_norm(X)\n",
        "    X = self.relu(X)\n",
        "    X = self.max_pool(X)\n",
        "    for residual_block in residual_blocks:\n",
        "      X = residual_block(X)\n",
        "    X = self.global_avg_pool(X)\n",
        "    X = self.dense(X)\n",
        "    return X\n",
        "\n",
        "residual_blocks = [\n",
        "    # Two start conv mapping\n",
        "    ResidualBlockTF(num_channels=64, output_channels=64, strides=2, is_used_conv11=False),\n",
        "    ResidualBlockTF(num_channels=64, output_channels=64, strides=2, is_used_conv11=False),\n",
        "    # Next three [conv mapping + identity mapping]\n",
        "    ResidualBlockTF(num_channels=64, output_channels=128, strides=2, is_used_conv11=True),\n",
        "    ResidualBlockTF(num_channels=128, output_channels=128, strides=2, is_used_conv11=False),\n",
        "    ResidualBlockTF(num_channels=128, output_channels=256, strides=2, is_used_conv11=True),\n",
        "    ResidualBlockTF(num_channels=256, output_channels=256, strides=2, is_used_conv11=False),\n",
        "    ResidualBlockTF(num_channels=256, output_channels=512, strides=2, is_used_conv11=True),\n",
        "    ResidualBlockTF(num_channels=512, output_channels=512, strides=2, is_used_conv11=False)\n",
        "]\n",
        "\n",
        "tfmodel = ResNet18TF(residual_blocks, output_shape=10)\n",
        "tfmodel.build(input_shape=(None, 28, 28, 1))\n",
        "tfmodel.summary()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"res_net18tf_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_71 (Conv2D)           multiple                  3200      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc multiple                  256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "re_lu_21 (ReLU)              multiple                  0         \n",
            "_________________________________________________________________\n",
            "residual_block_tf_12 (Residu multiple                  78272     \n",
            "_________________________________________________________________\n",
            "residual_block_tf_13 (Residu multiple                  78272     \n",
            "_________________________________________________________________\n",
            "residual_block_tf_14 (Residu multiple                  86592     \n",
            "_________________________________________________________________\n",
            "residual_block_tf_15 (Residu multiple                  312192    \n",
            "_________________________________________________________________\n",
            "residual_block_tf_16 (Residu multiple                  345216    \n",
            "_________________________________________________________________\n",
            "residual_block_tf_17 (Residu multiple                  1246976   \n",
            "_________________________________________________________________\n",
            "residual_block_tf_18 (Residu multiple                  1378560   \n",
            "_________________________________________________________________\n",
            "residual_block_tf_19 (Residu multiple                  4984320   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  5130      \n",
            "=================================================================\n",
            "Total params: 8,518,986\n",
            "Trainable params: 8,515,914\n",
            "Non-trainable params: 3,072\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHBV58O0M9Jx"
      },
      "source": [
        "**pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHrwPb9ufOJD",
        "outputId": "5fae8365-f5ee-4868-ce15-889c2cdee788"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "\n",
        "class ResNet18PyTorch(nn.Module):\n",
        "  def __init__(self, residual_blocks, output_shape):\n",
        "    super(ResNet18PyTorch, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
        "    self.batch_norm = nn.BatchNorm2d(64)\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.residual_blocks = nn.Sequential(*residual_blocks)\n",
        "    self.global_avg_pool = nn.Flatten()\n",
        "    self.dense = nn.Linear(in_features=512, out_features=output_shape)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.conv1(X)\n",
        "    X = self.batch_norm(X)\n",
        "    X = self.relu(X)\n",
        "    X = self.max_pool(X)\n",
        "    X = self.residual_blocks(X)\n",
        "    X = self.global_avg_pool(X)\n",
        "    X = self.dense(X)\n",
        "    return X\n",
        "\n",
        "residual_blocks = [\n",
        "    # Two start conv mapping\n",
        "    ResidualBlockPytorch(num_channels=64, output_channels=64, strides=2, is_used_conv11=False),\n",
        "    ResidualBlockPytorch(num_channels=64, output_channels=64, strides=2, is_used_conv11=False),\n",
        "    # Next three [conv mapping + identity mapping]\n",
        "    ResidualBlockPytorch(num_channels=64, output_channels=128, strides=2, is_used_conv11=True),\n",
        "    ResidualBlockPytorch(num_channels=128, output_channels=128, strides=2, is_used_conv11=False),\n",
        "    ResidualBlockPytorch(num_channels=128, output_channels=256, strides=2, is_used_conv11=True),\n",
        "    ResidualBlockPytorch(num_channels=256, output_channels=256, strides=2, is_used_conv11=False),\n",
        "    ResidualBlockPytorch(num_channels=256, output_channels=512, strides=2, is_used_conv11=True),\n",
        "    ResidualBlockPytorch(num_channels=512, output_channels=512, strides=2, is_used_conv11=False)\n",
        "]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "ptmodel = ResNet18PyTorch(residual_blocks, output_shape=10)\n",
        "ptmodel.to(device)\n",
        "summary(ptmodel, (1, 28, 28))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 14, 14]           3,200\n",
            "       BatchNorm2d-2           [-1, 64, 14, 14]             128\n",
            "              ReLU-3           [-1, 64, 14, 14]               0\n",
            "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
            "            Conv2d-5             [-1, 64, 7, 7]          36,928\n",
            "              ReLU-6             [-1, 64, 7, 7]               0\n",
            "       BatchNorm2d-7             [-1, 64, 7, 7]             128\n",
            "              ReLU-8             [-1, 64, 7, 7]               0\n",
            "            Conv2d-9             [-1, 64, 7, 7]          36,928\n",
            "      BatchNorm2d-10             [-1, 64, 7, 7]             128\n",
            "             ReLU-11             [-1, 64, 7, 7]               0\n",
            "           Conv2d-12             [-1, 64, 4, 4]           4,160\n",
            "ResidualBlockPytorch-13             [-1, 64, 4, 4]               0\n",
            "           Conv2d-14             [-1, 64, 4, 4]          36,928\n",
            "             ReLU-15             [-1, 64, 4, 4]               0\n",
            "      BatchNorm2d-16             [-1, 64, 4, 4]             128\n",
            "             ReLU-17             [-1, 64, 4, 4]               0\n",
            "           Conv2d-18             [-1, 64, 4, 4]          36,928\n",
            "      BatchNorm2d-19             [-1, 64, 4, 4]             128\n",
            "             ReLU-20             [-1, 64, 4, 4]               0\n",
            "           Conv2d-21             [-1, 64, 2, 2]           4,160\n",
            "ResidualBlockPytorch-22             [-1, 64, 2, 2]               0\n",
            "           Conv2d-23             [-1, 64, 2, 2]           4,160\n",
            "           Conv2d-24             [-1, 64, 2, 2]          36,928\n",
            "             ReLU-25             [-1, 64, 2, 2]               0\n",
            "      BatchNorm2d-26             [-1, 64, 2, 2]             128\n",
            "             ReLU-27             [-1, 64, 2, 2]               0\n",
            "           Conv2d-28             [-1, 64, 2, 2]          36,928\n",
            "      BatchNorm2d-29             [-1, 64, 2, 2]             128\n",
            "             ReLU-30             [-1, 64, 2, 2]               0\n",
            "           Conv2d-31            [-1, 128, 1, 1]           8,320\n",
            "ResidualBlockPytorch-32            [-1, 128, 1, 1]               0\n",
            "           Conv2d-33            [-1, 128, 1, 1]         147,584\n",
            "             ReLU-34            [-1, 128, 1, 1]               0\n",
            "      BatchNorm2d-35            [-1, 128, 1, 1]             256\n",
            "             ReLU-36            [-1, 128, 1, 1]               0\n",
            "           Conv2d-37            [-1, 128, 1, 1]         147,584\n",
            "      BatchNorm2d-38            [-1, 128, 1, 1]             256\n",
            "             ReLU-39            [-1, 128, 1, 1]               0\n",
            "           Conv2d-40            [-1, 128, 1, 1]          16,512\n",
            "ResidualBlockPytorch-41            [-1, 128, 1, 1]               0\n",
            "           Conv2d-42            [-1, 128, 1, 1]          16,512\n",
            "           Conv2d-43            [-1, 128, 1, 1]         147,584\n",
            "             ReLU-44            [-1, 128, 1, 1]               0\n",
            "      BatchNorm2d-45            [-1, 128, 1, 1]             256\n",
            "             ReLU-46            [-1, 128, 1, 1]               0\n",
            "           Conv2d-47            [-1, 128, 1, 1]         147,584\n",
            "      BatchNorm2d-48            [-1, 128, 1, 1]             256\n",
            "             ReLU-49            [-1, 128, 1, 1]               0\n",
            "           Conv2d-50            [-1, 256, 1, 1]          33,024\n",
            "ResidualBlockPytorch-51            [-1, 256, 1, 1]               0\n",
            "           Conv2d-52            [-1, 256, 1, 1]         590,080\n",
            "             ReLU-53            [-1, 256, 1, 1]               0\n",
            "      BatchNorm2d-54            [-1, 256, 1, 1]             512\n",
            "             ReLU-55            [-1, 256, 1, 1]               0\n",
            "           Conv2d-56            [-1, 256, 1, 1]         590,080\n",
            "      BatchNorm2d-57            [-1, 256, 1, 1]             512\n",
            "             ReLU-58            [-1, 256, 1, 1]               0\n",
            "           Conv2d-59            [-1, 256, 1, 1]          65,792\n",
            "ResidualBlockPytorch-60            [-1, 256, 1, 1]               0\n",
            "           Conv2d-61            [-1, 256, 1, 1]          65,792\n",
            "           Conv2d-62            [-1, 256, 1, 1]         590,080\n",
            "             ReLU-63            [-1, 256, 1, 1]               0\n",
            "      BatchNorm2d-64            [-1, 256, 1, 1]             512\n",
            "             ReLU-65            [-1, 256, 1, 1]               0\n",
            "           Conv2d-66            [-1, 256, 1, 1]         590,080\n",
            "      BatchNorm2d-67            [-1, 256, 1, 1]             512\n",
            "             ReLU-68            [-1, 256, 1, 1]               0\n",
            "           Conv2d-69            [-1, 512, 1, 1]         131,584\n",
            "ResidualBlockPytorch-70            [-1, 512, 1, 1]               0\n",
            "           Conv2d-71            [-1, 512, 1, 1]       2,359,808\n",
            "             ReLU-72            [-1, 512, 1, 1]               0\n",
            "      BatchNorm2d-73            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-74            [-1, 512, 1, 1]               0\n",
            "           Conv2d-75            [-1, 512, 1, 1]       2,359,808\n",
            "      BatchNorm2d-76            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-77            [-1, 512, 1, 1]               0\n",
            "           Conv2d-78            [-1, 512, 1, 1]         262,656\n",
            "ResidualBlockPytorch-79            [-1, 512, 1, 1]               0\n",
            "          Flatten-80                  [-1, 512]               0\n",
            "           Linear-81                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 8,518,858\n",
            "Trainable params: 8,518,858\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.67\n",
            "Params size (MB): 32.50\n",
            "Estimated Total Size (MB): 33.17\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NnvGfpTM-4r"
      },
      "source": [
        "**mxnet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3OXzJturjR9",
        "outputId": "ceab0e33-e576-470a-b96e-2e3170e7a312"
      },
      "source": [
        "import mxnet as mx\n",
        "from mxnet.gluon import nn as mxnn\n",
        "\n",
        "class ResNet18Mxnet(mxnn.Block):\n",
        "  def __init__(self, residual_blocks, output_shape, **kwargs):\n",
        "    super(ResNet18Mxnet, self).__init__(**kwargs)\n",
        "    self.conv1 = mxnn.Conv2D(channels=64, padding=3, \n",
        "                           kernel_size=7, strides=2)\n",
        "    self.batch_norm = mxnn.BatchNorm()\n",
        "    self.max_pool = mxnn.MaxPool2D(pool_size=3)\n",
        "    self.relu = mxnn.Activation('relu')\n",
        "    self.residual_blocks = residual_blocks\n",
        "    self.global_avg_pool = mxnn.GlobalAvgPool2D()\n",
        "    self.dense = mxnn.Dense(units=output_shape)\n",
        "    self.blk = mxnn.Sequential()\n",
        "    for residual_block in self.residual_blocks:\n",
        "      self.blk.add(residual_block)\n",
        "  \n",
        "  def forward(self, X):\n",
        "    X = self.conv1(X)\n",
        "    X = self.batch_norm(X)\n",
        "    X = self.relu(X)\n",
        "    X = self.max_pool(X)\n",
        "    X = self.blk(X)\n",
        "    X = self.global_avg_pool(X)\n",
        "    X = self.dense(X)\n",
        "    return X\n",
        "\n",
        "residual_blocks = [\n",
        "    # Two start conv mapping\n",
        "    ResidualBlockMxnet(num_channels=64, output_channels=64, strides=2, is_used_conv11=False),\n",
        "    ResidualBlockMxnet(num_channels=64, output_channels=64, strides=2, is_used_conv11=False),\n",
        "    # Next three [conv mapping + identity mapping]\n",
        "    ResidualBlockMxnet(num_channels=64, output_channels=128, strides=2, is_used_conv11=True),\n",
        "    ResidualBlockMxnet(num_channels=128, output_channels=128, strides=2, is_used_conv11=False),\n",
        "    ResidualBlockMxnet(num_channels=128, output_channels=256, strides=2, is_used_conv11=True),\n",
        "    ResidualBlockMxnet(num_channels=256, output_channels=256, strides=2, is_used_conv11=False),\n",
        "    ResidualBlockMxnet(num_channels=256, output_channels=512, strides=2, is_used_conv11=True),\n",
        "    ResidualBlockMxnet(num_channels=512, output_channels=512, strides=2, is_used_conv11=False)\n",
        "]\n",
        "\n",
        "mxmodel = ResNet18Mxnet(residual_blocks, output_shape=10)\n",
        "mxmodel.hybridize()\n",
        "\n",
        "mx.viz.print_summary(\n",
        "    mxmodel(mx.sym.var('data')), \n",
        "    shape={'data':(4, 1, 28, 28)}, #set your shape here\n",
        ")"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "________________________________________________________________________________________________________________________\n",
            "Layer (type)                                        Output Shape            Param #     Previous Layer                  \n",
            "========================================================================================================================\n",
            "data(null)                                          1x28x28                 0                                           \n",
            "________________________________________________________________________________________________________________________\n",
            "conv83_fwd(Convolution)                             64x14x14                3200        data                            \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm39_fwd(BatchNorm)                          64x14x14                128         conv83_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu39_fwd(Activation)                              64x14x14                0           batchnorm39_fwd                 \n",
            "________________________________________________________________________________________________________________________\n",
            "pool42_fwd(Pooling)                                 64x4x4                  0           relu39_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "conv56_fwd(Convolution)                             64x4x4                  36928       pool42_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu31_fwd(Activation)                              64x4x4                  0           conv56_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm31_fwd(BatchNorm)                          64x4x4                  128         relu31_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu31_fwd(Activation)                              64x4x4                  0           batchnorm31_fwd                 \n",
            "________________________________________________________________________________________________________________________\n",
            "conv57_fwd(Convolution)                             64x4x4                  36928       relu31_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm31_fwd(BatchNorm)                          64x4x4                  128         conv57_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "_plus8(elemwise_add)                                64x4x4                  0           batchnorm31_fwd                 \n",
            "                                                                                        pool42_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu31_fwd(Activation)                              64x4x4                  0           _plus8                          \n",
            "________________________________________________________________________________________________________________________\n",
            "conv58_fwd(Convolution)                             64x2x2                  4160        relu31_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "conv59_fwd(Convolution)                             64x2x2                  36928       conv58_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu32_fwd(Activation)                              64x2x2                  0           conv59_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm32_fwd(BatchNorm)                          64x2x2                  128         relu32_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu32_fwd(Activation)                              64x2x2                  0           batchnorm32_fwd                 \n",
            "________________________________________________________________________________________________________________________\n",
            "conv60_fwd(Convolution)                             64x2x2                  36928       relu32_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm32_fwd(BatchNorm)                          64x2x2                  128         conv60_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "_plus9(elemwise_add)                                64x2x2                  0           batchnorm32_fwd                 \n",
            "                                                                                        conv58_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu32_fwd(Activation)                              64x2x2                  0           _plus9                          \n",
            "________________________________________________________________________________________________________________________\n",
            "conv61_fwd(Convolution)                             64x1x1                  4160        relu32_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "conv62_fwd(Convolution)                             64x1x1                  36928       conv61_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu33_fwd(Activation)                              64x1x1                  0           conv62_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm33_fwd(BatchNorm)                          64x1x1                  128         relu33_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu33_fwd(Activation)                              64x1x1                  0           batchnorm33_fwd                 \n",
            "________________________________________________________________________________________________________________________\n",
            "conv63_fwd(Convolution)                             64x1x1                  36928       relu33_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm33_fwd(BatchNorm)                          64x1x1                  128         conv63_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "conv64_fwd(Convolution)                             64x1x1                  4160        conv61_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "_plus10(elemwise_add)                               64x1x1                  0           batchnorm33_fwd                 \n",
            "                                                                                        conv64_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu33_fwd(Activation)                              64x1x1                  0           _plus10                         \n",
            "________________________________________________________________________________________________________________________\n",
            "conv65_fwd(Convolution)                             128x1x1                 8320        relu33_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "conv66_fwd(Convolution)                             128x1x1                 147584      conv65_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu34_fwd(Activation)                              128x1x1                 0           conv66_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm34_fwd(BatchNorm)                          128x1x1                 256         relu34_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu34_fwd(Activation)                              128x1x1                 0           batchnorm34_fwd                 \n",
            "________________________________________________________________________________________________________________________\n",
            "conv67_fwd(Convolution)                             128x1x1                 147584      relu34_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm34_fwd(BatchNorm)                          128x1x1                 256         conv67_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "_plus11(elemwise_add)                               128x1x1                 0           batchnorm34_fwd                 \n",
            "                                                                                        conv65_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu34_fwd(Activation)                              128x1x1                 0           _plus11                         \n",
            "________________________________________________________________________________________________________________________\n",
            "conv68_fwd(Convolution)                             128x1x1                 16512       relu34_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "conv69_fwd(Convolution)                             128x1x1                 147584      conv68_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu35_fwd(Activation)                              128x1x1                 0           conv69_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm35_fwd(BatchNorm)                          128x1x1                 256         relu35_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu35_fwd(Activation)                              128x1x1                 0           batchnorm35_fwd                 \n",
            "________________________________________________________________________________________________________________________\n",
            "conv70_fwd(Convolution)                             128x1x1                 147584      relu35_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm35_fwd(BatchNorm)                          128x1x1                 256         conv70_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "conv71_fwd(Convolution)                             128x1x1                 16512       conv68_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "_plus12(elemwise_add)                               128x1x1                 0           batchnorm35_fwd                 \n",
            "                                                                                        conv71_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu35_fwd(Activation)                              128x1x1                 0           _plus12                         \n",
            "________________________________________________________________________________________________________________________\n",
            "conv72_fwd(Convolution)                             256x1x1                 33024       relu35_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "conv73_fwd(Convolution)                             256x1x1                 590080      conv72_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu36_fwd(Activation)                              256x1x1                 0           conv73_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm36_fwd(BatchNorm)                          256x1x1                 512         relu36_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu36_fwd(Activation)                              256x1x1                 0           batchnorm36_fwd                 \n",
            "________________________________________________________________________________________________________________________\n",
            "conv74_fwd(Convolution)                             256x1x1                 590080      relu36_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm36_fwd(BatchNorm)                          256x1x1                 512         conv74_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "_plus13(elemwise_add)                               256x1x1                 0           batchnorm36_fwd                 \n",
            "                                                                                        conv72_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu36_fwd(Activation)                              256x1x1                 0           _plus13                         \n",
            "________________________________________________________________________________________________________________________\n",
            "conv75_fwd(Convolution)                             256x1x1                 65792       relu36_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "conv76_fwd(Convolution)                             256x1x1                 590080      conv75_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu37_fwd(Activation)                              256x1x1                 0           conv76_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm37_fwd(BatchNorm)                          256x1x1                 512         relu37_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu37_fwd(Activation)                              256x1x1                 0           batchnorm37_fwd                 \n",
            "________________________________________________________________________________________________________________________\n",
            "conv77_fwd(Convolution)                             256x1x1                 590080      relu37_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm37_fwd(BatchNorm)                          256x1x1                 512         conv77_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "conv78_fwd(Convolution)                             256x1x1                 65792       conv75_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "_plus14(elemwise_add)                               256x1x1                 0           batchnorm37_fwd                 \n",
            "                                                                                        conv78_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu37_fwd(Activation)                              256x1x1                 0           _plus14                         \n",
            "________________________________________________________________________________________________________________________\n",
            "conv79_fwd(Convolution)                             512x1x1                 131584      relu37_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "conv80_fwd(Convolution)                             512x1x1                 2359808     conv79_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu38_fwd(Activation)                              512x1x1                 0           conv80_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm38_fwd(BatchNorm)                          512x1x1                 1024        relu38_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu38_fwd(Activation)                              512x1x1                 0           batchnorm38_fwd                 \n",
            "________________________________________________________________________________________________________________________\n",
            "conv81_fwd(Convolution)                             512x1x1                 2359808     relu38_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "batchnorm38_fwd(BatchNorm)                          512x1x1                 1024        conv81_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "_plus15(elemwise_add)                               512x1x1                 0           batchnorm38_fwd                 \n",
            "                                                                                        conv79_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "relu38_fwd(Activation)                              512x1x1                 0           _plus15                         \n",
            "________________________________________________________________________________________________________________________\n",
            "conv82_fwd(Convolution)                             512x1x1                 262656      relu38_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "pool43_fwd(Pooling)                                 512x1x1                 0           conv82_fwd                      \n",
            "________________________________________________________________________________________________________________________\n",
            "dense21_fwd(FullyConnected)                         10                      5130        pool43_fwd                      \n",
            "========================================================================================================================\n",
            "Total params: 8518858\n",
            "________________________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9MFS7Lwyb7d"
      },
      "source": [
        "# 5. Train model\n",
        "\n",
        "After build up the model, train model is the simple step. In this step i take an example how to train classify digits on mnist dataset. There are total 10 different classes corresponding with digits from 0 to 9. The input is picture with shape `28 x 28 x 1`. Dataset is splitted into `train:test` with proportion `10000:60000` and distribution of data is equal between all classes at both train and test.\n",
        "\n",
        "**tensorflow**\n",
        "\n",
        "Training model on tensorflow keras is wrapped in `fit()` function. Thus, it seem to be simpliest in 3 deep learning frameworks. You can see as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1Au2hBBzyx_",
        "outputId": "9b73a69f-edf7-4490-f2b0-e68aaac402e6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0\n",
        "X_train = np.reshape(X_train, (-1, 28, 28, 1))\n",
        "X_test = np.reshape(X_test, (-1, 28, 28, 1))\n",
        "# Convert data type bo be adaptable to tensorflow computation engine\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "print(X_test.shape, X_train.shape)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28, 1) (60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmrK4P9cpqDG"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT_b_Z7-0p97",
        "outputId": "011422e1-280c-45c4-ac01-2eaa8548e69f"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.99)\n",
        "tfmodel.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "tfmodel.fit(X_train, y_train,\n",
        "            validation_data = (X_test, y_test), \n",
        "            batch_size=32,\n",
        "            epochs=10)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 31s 15ms/step - loss: 1.3851 - accuracy: 0.7868 - val_loss: 1.0273 - val_accuracy: 0.7817\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.1497 - accuracy: 0.9679 - val_loss: 0.9367 - val_accuracy: 0.7883\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.1057 - accuracy: 0.9769 - val_loss: 0.7307 - val_accuracy: 0.8755\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0887 - accuracy: 0.9825 - val_loss: 0.6207 - val_accuracy: 0.8955\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0787 - accuracy: 0.9844 - val_loss: 0.7749 - val_accuracy: 0.7688\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0721 - accuracy: 0.9859 - val_loss: 0.4967 - val_accuracy: 0.8750\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0637 - accuracy: 0.9876 - val_loss: 1.0397 - val_accuracy: 0.7416\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0611 - accuracy: 0.9869 - val_loss: 0.6328 - val_accuracy: 0.8244\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0545 - accuracy: 0.9887 - val_loss: 0.5762 - val_accuracy: 0.8722\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0512 - accuracy: 0.9907 - val_loss: 0.5077 - val_accuracy: 0.8997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7feb56a397b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iJTY6EWyofQ"
      },
      "source": [
        "**pytorch**\n",
        "\n",
        "On the pytorch you are going to see there are a little bit change compare to tensorflow keras training. You normally use DataLoader to forward training. It is very through bellow practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "fytkKmqD6RO6",
        "outputId": "725f3967-1f9d-48f1-b115-76d92dbda91b"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.05), (0.05))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=8)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                         shuffle=False, num_workers=8)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(ptmodel.parameters(), lr=0.001, betas=(0.9, 0.99))\n",
        "\n",
        "                        \n",
        "def acc(output, label):\n",
        "    # output: (batch, num_output) float32 ndarray\n",
        "    # label: (batch, ) int32 ndarray\n",
        "    return (torch.argmax(output, axis=1)==label).float().mean()\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "    total_loss = 0.0\n",
        "    tic = time.time()\n",
        "    tic_step = time.time()\n",
        "    train_acc = 0.0\n",
        "    valid_acc = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = ptmodel(inputs)\n",
        "        train_acc += acc(outputs, labels)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        total_loss += loss.item()\n",
        "        if i % 500 == 499:\n",
        "          print(\"iter %d: loss %.3f, train acc %.3f in %.1f sec\" % (\n",
        "            i+1, total_loss/i, train_acc/i, time.time()-tic_step))\n",
        "          tic_step = time.time()\n",
        "\n",
        "    # calculate validation accuracy\n",
        "    for i, data in enumerate(testloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        valid_acc += acc(ptmodel(inputs), labels)\n",
        "\n",
        "    print(\"Epoch %d: loss %.3f, train acc %.3f, test acc %.3f, in %.1f sec\" % (\n",
        "            epoch, total_loss/len(trainloader), train_acc/len(trainloader),\n",
        "            valid_acc/len(testloader), time.time()-tic))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 500: loss 0.066, train acc 0.989 in 14.8 sec\n",
            "iter 1000: loss 0.065, train acc 0.988 in 13.9 sec\n",
            "iter 1500: loss 0.067, train acc 0.987 in 13.7 sec\n",
            "Epoch 0: loss 0.067, train acc 0.986, test acc 0.986, in 57.6 sec\n",
            "iter 500: loss 0.067, train acc 0.988 in 14.7 sec\n",
            "iter 1000: loss 0.063, train acc 0.989 in 13.9 sec\n",
            "iter 1500: loss 0.063, train acc 0.988 in 13.8 sec\n",
            "Epoch 1: loss 0.062, train acc 0.988, test acc 0.990, in 57.8 sec\n",
            "iter 500: loss 0.049, train acc 0.991 in 15.2 sec\n",
            "iter 1000: loss 0.054, train acc 0.990 in 14.2 sec\n",
            "iter 1500: loss 0.053, train acc 0.990 in 14.1 sec\n",
            "Epoch 2: loss 0.056, train acc 0.989, test acc 0.985, in 59.4 sec\n",
            "iter 500: loss 0.049, train acc 0.992 in 14.7 sec\n",
            "iter 1000: loss 0.051, train acc 0.991 in 14.2 sec\n",
            "iter 1500: loss 0.055, train acc 0.990 in 14.4 sec\n",
            "Epoch 3: loss 0.055, train acc 0.989, test acc 0.989, in 58.3 sec\n",
            "iter 500: loss 0.048, train acc 0.992 in 14.3 sec\n",
            "iter 1000: loss 0.048, train acc 0.991 in 14.1 sec\n",
            "iter 1500: loss 0.052, train acc 0.991 in 13.7 sec\n",
            "Epoch 4: loss 0.050, train acc 0.990, test acc 0.990, in 57.2 sec\n",
            "iter 500: loss 0.051, train acc 0.992 in 14.9 sec\n",
            "iter 1000: loss 0.050, train acc 0.992 in 14.1 sec\n",
            "iter 1500: loss 0.048, train acc 0.991 in 13.9 sec\n",
            "Epoch 5: loss 0.049, train acc 0.990, test acc 0.987, in 57.8 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-26b87e833ff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVUjskNdyp-p"
      },
      "source": [
        "**mxnet**\n",
        "\n",
        "To train model on mxnet also the same as pytorch, we also loop through DataLoader to forward and backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LeiOjPsZxi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4cb0e6-b2ca-46e5-ebc2-4df5f1b8f547"
      },
      "source": [
        "from mxnet import nd, gluon, init, autograd, gpu, cpu\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon.data.vision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "mnist_train = datasets.MNIST(train=True)\n",
        "mnist_val = datasets.MNIST(train=False)\n",
        "\n",
        "transformer = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.05, 0.05)])\n",
        "\n",
        "mnist_train = mnist_train.transform_first(transformer)\n",
        "mnist_val = mnist_val.transform_first(transformer)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/datasets/mnist/t10k-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-images-idx3-ubyte.gz...\n",
            "Downloading /root/.mxnet/datasets/mnist/t10k-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-labels-idx1-ubyte.gz...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gntKf-xaQQh"
      },
      "source": [
        "batch_size = 32\n",
        "train_data = gluon.data.DataLoader(\n",
        "    mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "valid_data = gluon.data.DataLoader(\n",
        "    mnist_val, batch_size=batch_size, shuffle=True, num_workers=4)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdrDz-6dVx9O"
      },
      "source": [
        "To train model of mxnet on GPU, you should install mxnet-cuda version aligning with your computer cuda version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "30C8SI5pWGDy",
        "outputId": "311ace31-db64-400d-883a-470b3573416a"
      },
      "source": [
        "# check cuda version\n",
        "!nvcc --version\n",
        "# install mxnet-cuda version\n",
        "!pip install mxnet-cu101"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "Collecting mxnet-cu101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/26/9655677b901537f367c3c473376e4106abc72e01a8fc25b1cb6ed9c37e8c/mxnet_cu101-1.7.0-py2.py3-none-manylinux2014_x86_64.whl (846.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 834.1MB 1.3MB/s eta 0:00:09tcmalloc: large alloc 1147494400 bytes == 0x39e0c000 @  0x7fc22dc21615 0x591e47 0x4cc179 0x4cc2db 0x50a1cc 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x58e683 0x50c127 0x58e683 0x50c127 0x58e683 0x50c127 0x58e683 0x50c127 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 846.0MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (0.8.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (1.19.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.10)\n",
            "Installing collected packages: mxnet-cu101\n",
            "Successfully installed mxnet-cu101-1.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "mxnet"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92OkquHsYfSW",
        "outputId": "08439a01-a209-42a8-8a58-5780db0cdab7"
      },
      "source": [
        "use_gpu = True\n",
        "if use_gpu:\n",
        "  # incase you have more than one GPU, you can add gpu(1), gpu(2),...\n",
        "  devices = [gpu(0)]\n",
        "else:\n",
        "  devices = [cpu()]\n",
        "print('devices: ', devices)\n",
        "mxmodel = ResNet18Mxnet(residual_blocks, output_shape=10)\n",
        "mxmodel.hybridize()\n",
        "mxmodel.collect_params()\n",
        "mxmodel.initialize(init=init.Xavier(), ctx=devices, force_reinit=True)\n",
        "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "trainer = gluon.Trainer(mxmodel.collect_params(), 'adam', {'learning_rate': 0.001})\n",
        "                        \n",
        "def acc(output, label):\n",
        "    # output: (batch, num_output) float32 ndarray\n",
        "    # label: (batch, ) int32 ndarray\n",
        "    return (output.argmax(axis=1) ==\n",
        "            label.astype('float32')).mean().asscalar()\n",
        "\n",
        "for epoch in range(10):\n",
        "    train_loss, train_acc, valid_acc = 0., 0., 0.\n",
        "    tic = time.time()\n",
        "    for i, (inputs, labels) in enumerate(train_data):\n",
        "        actual_batch_size = inputs.shape[0]\n",
        "        # Split data among GPUs. Since split_and_load is a deterministic function\n",
        "        # inputs and labels are going to be split in the same way between GPUs.\n",
        "        inputs = mx.gluon.utils.split_and_load(inputs, ctx_list=devices, even_split=False)\n",
        "        labels = mx.gluon.utils.split_and_load(labels, ctx_list=devices, even_split=False)\n",
        "        with mx.autograd.record():\n",
        "          for input, label in zip(inputs, labels):\n",
        "            output = mxmodel(input)\n",
        "            loss = softmax_cross_entropy(output, label)\n",
        "\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        trainer.step(batch_size)\n",
        "        # calculate training metrics\n",
        "        train_loss += loss.mean().asscalar()\n",
        "        train_acc += acc(output, label)\n",
        "        if i % 500 == 499:\n",
        "          print(\"Epoch %d: Step %d: loss %.3f, train acc %.3f\" % (\n",
        "              epoch, i+1, train_loss/i, train_acc/i))\n",
        "    # calculate validation accuracy\n",
        "    for inputs, labels in valid_data:\n",
        "        actual_batch_size = inputs.shape[0]\n",
        "        # Split data among GPUs. Since split_and_load is a deterministic function\n",
        "        # inputs and labels are going to be split in the same way between GPUs.\n",
        "        inputs = mx.gluon.utils.split_and_load(inputs, ctx_list=devices, even_split=False)\n",
        "        labels = mx.gluon.utils.split_and_load(labels, ctx_list=devices, even_split=False)\n",
        "        for input, label in zip(inputs, labels):\n",
        "          output = mxmodel(input)\n",
        "          valid_acc += acc(output, label)\n",
        "\n",
        "    print(\"Epoch %d: loss %.3f, train acc %.3f, test acc %.3f, in %.1f sec\" % (\n",
        "            epoch, train_loss/len(train_data), train_acc/len(train_data),\n",
        "            valid_acc/len(valid_data), time.time()-tic))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "devices:  [gpu(0)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: \"ResNet18Mxnet.residual_blocks\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/mxnet/gluon/block.py:656: UserWarning: \"ResNet18Mxnet.residual_blocks\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
            "  self.collect_params().initialize(init, ctx, verbose, force_reinit)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: \"ResNet18Mxnet.residual_blocks\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Step 500: loss 1.041, train acc 0.683\n",
            "Epoch 0: Step 1000: loss 0.705, train acc 0.791\n",
            "Epoch 0: Step 1500: loss 0.561, train acc 0.837\n",
            "Epoch 0: loss 0.495, train acc 0.857, test acc 0.294, in 64.5 sec\n",
            "Epoch 1: Step 500: loss 0.199, train acc 0.952\n",
            "Epoch 1: Step 1000: loss 0.191, train acc 0.953\n",
            "Epoch 1: Step 1500: loss 0.190, train acc 0.954\n",
            "Epoch 1: loss 0.184, train acc 0.955, test acc 0.409, in 64.4 sec\n",
            "Epoch 2: Step 500: loss 0.151, train acc 0.967\n",
            "Epoch 2: Step 1000: loss 0.159, train acc 0.964\n",
            "Epoch 2: Step 1500: loss 0.160, train acc 0.963\n",
            "Epoch 2: loss 0.159, train acc 0.963, test acc 0.779, in 65.4 sec\n",
            "Epoch 3: Step 500: loss 0.199, train acc 0.952\n",
            "Epoch 3: Step 1000: loss 0.186, train acc 0.955\n",
            "Epoch 3: Step 1500: loss 0.168, train acc 0.960\n",
            "Epoch 3: loss 0.160, train acc 0.962, test acc 0.920, in 65.6 sec\n",
            "Epoch 4: Step 500: loss 0.114, train acc 0.975\n",
            "Epoch 4: Step 1000: loss 0.110, train acc 0.975\n",
            "Epoch 4: Step 1500: loss 0.109, train acc 0.975\n",
            "Epoch 4: loss 0.110, train acc 0.975, test acc 0.949, in 67.1 sec\n",
            "Epoch 5: Step 500: loss 0.102, train acc 0.979\n",
            "Epoch 5: Step 1000: loss 0.108, train acc 0.977\n",
            "Epoch 5: Step 1500: loss 0.108, train acc 0.977\n",
            "Epoch 5: loss 0.106, train acc 0.977, test acc 0.957, in 67.5 sec\n",
            "Epoch 6: Step 500: loss 0.098, train acc 0.981\n",
            "Epoch 6: Step 1000: loss 0.092, train acc 0.981\n",
            "Epoch 6: Step 1500: loss 0.090, train acc 0.981\n",
            "Epoch 6: loss 0.091, train acc 0.980, test acc 0.946, in 66.0 sec\n",
            "Epoch 7: Step 500: loss 0.095, train acc 0.982\n",
            "Epoch 7: Step 1000: loss 0.085, train acc 0.983\n",
            "Epoch 7: Step 1500: loss 0.082, train acc 0.982\n",
            "Epoch 7: loss 0.085, train acc 0.981, test acc 0.939, in 65.1 sec\n",
            "Epoch 8: Step 500: loss 0.088, train acc 0.981\n",
            "Epoch 8: Step 1000: loss 0.085, train acc 0.982\n",
            "Epoch 8: Step 1500: loss 0.081, train acc 0.983\n",
            "Epoch 8: loss 0.078, train acc 0.983, test acc 0.947, in 64.3 sec\n",
            "Epoch 9: Step 500: loss 0.063, train acc 0.988\n",
            "Epoch 9: Step 1000: loss 0.065, train acc 0.987\n",
            "Epoch 9: Step 1500: loss 0.063, train acc 0.986\n",
            "Epoch 9: loss 0.064, train acc 0.986, test acc 0.952, in 64.0 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4grMZQcxinz"
      },
      "source": [
        "Through this blog, i introduce to you how to initialize ResNet model from scratch on the whole 3 most common deep learning frameworks. You can realize that when you understand about model architecture, you can easily build up model and customize it according to your new ideas to improve it better and better.\n",
        "\n",
        "If you see this blog is useful, kindly subcribe my channels via [phamdinhkhanh](https://phamdinhkhanh.github.io/home),  [Khanh Blog](https://www.facebook.com/TowardDataScience) and [AICode](https://www.facebook.com/groups/3235479620010379).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSm5k-oDzJ1-"
      },
      "source": [
        "# 6. Referrence\n",
        "\n",
        "1. [ResNet Paper](https://arxiv.org/abs/1512.03385)\n",
        "2. [Residual Networks (ResNet) - dive into deep learning](https://d2l.ai/chapter_convolutional-modern/resnet.html)\n",
        "3. [Understanding and Building Resnet from scratch using Pytorch](https://jarvislabs.ai/blogs/resnet)\n",
        "4. [ResNet build from scratch github - alinarw](https://github.com/alinarw/ResNet)\n",
        "5. [ResNet introduction](https://viblo.asia/p/gioi-thieu-mang-resnet-vyDZOa7R5wj)"
      ]
    }
  ]
}