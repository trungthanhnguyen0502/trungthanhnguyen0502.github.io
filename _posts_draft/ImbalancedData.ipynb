{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImbalancedData.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOd026hAByRO",
        "colab_type": "text"
      },
      "source": [
        "# Mất cân bằng dữ liệu (imbalanced dataset)\n",
        "\n",
        "Mất cân bằng dữ liệu là một trong những hiện tượng phổ biến của bài toán phân loại nhị phân (binary classification). Trong trường hợp tỷ lệ dữ liệu giữa 2 class là 50%:50% thì được coi là cân bằng. Khi có sự khác biệt trong phân phối giữa 2 classes, chẳng hạn 60%:40% thì dữ liệu có hiện tượng mất cân bằng. \n",
        "\n",
        "Hầu hết các bộ dữ liệu đều khó đạt được trạng thái cân bằng mà luôn có sự khác biệt về tỷ lệ giữa 2 classes. Đối với những trường hợp dữ liệu mất cân bằng nhẹ như tỷ lệ 60:40 thì sẽ không ảnh hưởng đáng kể tới khả năng dự báo của mô hình.\n",
        "\n",
        "Tuy nhiên nếu hiện tượng mất cân bằng nghiêm trọng xảy ra, chẳng hạn như tỷ lệ 90:10 sẽ thường dẫn tới dự báo kém chính xác. Khi đó thước đo độ chính xác (accuracy) của mô hình cũng không có nhiều ý nghĩa trong việc đánh giá kết quả vì tỷ lệ này có thể đạt được rất cao mà không cần tới mô hình hồi qui. Trong mẫu ví dụ trên, một dự báo ngẫu nhiên đưa ra tất cả đều là nhóm đa số thì độ chính xác đã đạt được tới 90%. Do đó nếu lựa chọn độ chính xác làm thước đo thì chỉ số này thường rất cao và dễ khiến chúng ta ngộ nhận.\n",
        "\n",
        "Trong trường hợp mẫu mất cân bằng ta cần phải điều chỉnh lại chỉ số đánh giá mô hình để đưa ra kết quả hợp lý hơn. Tôi sẽ trình bày các chỉ số thay thế cho độ chính xác qua bài viết này.\n",
        "\n",
        "Mất cân bằng dữ liệu thường xảy ra đối với rất nhiều các bài toán như phân loại khác nhau trong thực tiễn như spam email, phát hiện gian lận, dự báo vỡ nợ, chuẩn đoán bệnh lý,....\n",
        "\n",
        "Mất cân bằng dữ liệu thường dẫn tới dự báo kém chính xác trên nhóm thiểu số. Bởi đa phần kết quả dự báo ra thường thuộc về nhóm đa số. Trong khi tầm quan trọng của việc dự báo được chính xác một mẫu thuộc nhóm thiểu số lớn hơn nhiều so với dự báo mẫu thuộc nhóm đa số. Do đó sẽ cần những sự điều chỉnh thích hợp để mô hình đạt được một độ chính xác cao trên nhóm thiểu số.\n",
        "\n",
        "Vậy trong tình huống xảy ra mất cân bằng nghiêm trọng ta nên đánh giá mô hình như thế nào? Có những phương pháp nào để đối phó với hiện tượng mất cân bằng mẫu nghiêm trọng? Mời các bạn tham khảo các giải pháp qua bài viết này."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6NIfU-IByn5",
        "colab_type": "text"
      },
      "source": [
        "# Tập dữ liệu\n",
        "\n",
        "Để thuận lợi cho việc minh họa giải pháp, tôi sẽ xây dựng một mô hình trên bộ dữ liệu [gian lận thẻ tín dụng](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients) và thực hiện các đánh giá đo lường mức độ cải thiện mô hình trước và sau khi áp dụng các điều chỉnh.\n",
        "\n",
        "**Thông tin về bộ dữ liệu:**\n",
        "\n",
        "Đây là bộ dữ liệu về thẻ hành vi gian lận trong 6 tháng đầu năm 2005 tại một ngân hàng thuộc Đài Loan. Bộ dữ liệu bao gồm 30000 các hợp đồng thuộc cả 2 nhóm là vỡ nợ và không vỡ nợ. Mẫu xảy ra hiện tượng mất cân bằng trầm trọng vì tỷ lệ `bình thường:vỡ nợ` là `23364:6636`. Chúng ta sẽ cùng xem những giải pháp đưa ra sẽ cải thiện kết quả của mô hình như thế nào.\n",
        "\n",
        "\n",
        "**Thông tin trường:**\n",
        "\n",
        "Trong bộ dữ liệu này chúng ta sẽ dự báo hành vi vỡ nợ của khách hàng trong tháng tới. Biến mục tiêu là default_payment_next_month (Yes = 1, No = 0).\n",
        "\n",
        "Đầu vào của mô hình là 23 biến còn lại có ý nghĩa như bên dưới:\n",
        "* ID: Mã số xác định hồ sơ vay. Mỗi một ID ứng với một quan sát duy nhất.\n",
        "* LIMIT_BAL: Số dư tín dụng bao gồm cả cá nhân người vay và những người phụ thuộc trong gia đình. Đơn vị NT dolar.\n",
        "* SEX: Giới tính (1 = Nam, 2 = Nữ).\n",
        "* EDUCATION: Trình độ giáo dục (1 = tốt nghiệp trung học, 2 = đại học, 3 = trung học thông, 4 = khác).\n",
        "* MARRIAGE: Trạng thái hôn nhân (1 = đã kết hôn, 2 = độc thân, 3 = khác)\n",
        "* AGE: Độ tuổi.\n",
        "* PAY_0 - PAY_6: Lịch sử trả nợ trong quá khứ theo tuần tự của tháng. PAY_6 là tháng xa nhất và PAY_0 là tháng gần nhất. Chỉ số lường cho repayment status được chia thành các hạng: -1 = Trả nợ đúng hạn; 1 = trả nợ chậm 1 tháng; 2= trả nợ chậm 2 tháng; ...; 9 = trả nợ chậm 9 tháng.\n",
        "* BILL_AMT1 - BILL_AMT6: Tổng giá trị của bill. BILL_AMT1 là giá trị bill trong tháng gần nhất, tuần tự như thế cho đến giá trị bill trong tháng sau cùng là BILL_AMT6.\n",
        "* PAY_AMT1 - PAY_AMT6: Số tiền của tháng trước đã thanh toán. PAY_AMT1 là tháng gần nhất cho đến PAY_AMT6 là tháng xa nhất."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXgmzMxdNsti",
        "colab_type": "text"
      },
      "source": [
        "# Phân chia tập train/val/dev/test\n",
        "\n",
        "Tiếp theo để huấn luyện, lựa chọn và kiểm tra kết quả của mô hình chúng ta sẽ phân chia một cách ngẫu nhiên, không trùng lặp bộ dữ liệu thành các tập train/val/dev/test. Các bộ dữ liệu này có ý nghĩa và vai trò như sau:\n",
        "\n",
        "* tập train: Dựa trên các biến input và target của tập train, ta sẽ huấn luyện mô hình phân loại vỡ nợ. Mô hình thu được sẽ được đánh giá ở những tập dữ liệu độc lập khác.\n",
        "* tập val: Đây là tập dữ liệu có các trường tương tự như tập train nhưng không được đưa vào huấn luyện mô hình mà chỉ được sử dụng để đánh giá kết quả dự báo từ mô hình được huấn luyện từ tập train. Nếu mô hình có hiện tượng overfitting hoặc underfitting sẽ được phát hiện và tiến hành hiệu chỉnh.\n",
        "* tập dev: Đây là tập dữ liệu có các trường cũng tương tự như tập train và val nhưng được dùng để đánh giá việc lựa chọn các siêu tham số (hyper parameters) cho các mô hình huấn luyện.\n",
        "* tập test: Đây cũng là tập dữ liệu có các trường giống train, val, dev và được coi như những quan sát mới. Do đó được sử dụng để kiếm tra độ chính xác của mô hình khi áp dụng vào thực tiễn.\n",
        "\n",
        "Các tập dữ liệu sẽ được lựa chọn ngẫu nhiên và không trùng lặp. Trong đó bộ dữ liệu train có tỷ lệ kích thước giữa `bình thường: vỡ nợ` là 10000:500, và val/dev/test đều là là 2000:100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ugYz5Sujen",
        "colab_type": "code",
        "outputId": "1b895c2a-82e4-473f-ae78-df7f20d3acaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "path = '/content/gdrive/My Drive/Colab Notebooks/ImbalanceDataset'\n",
        "os.chdir(path)\n",
        "dataset = pd.read_csv('default_of_credit_card_clients.csv', header = 0, \n",
        "                      encoding='utf-8', engine='python')\n",
        "print(dataset.shape)\n",
        "dataset.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "(30000, 25)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30000 entries, 0 to 29999\n",
            "Data columns (total 25 columns):\n",
            "ID                            30000 non-null int64\n",
            "LIMIT_BAL                     30000 non-null int64\n",
            "SEX                           30000 non-null int64\n",
            "EDUCATION                     30000 non-null int64\n",
            "MARRIAGE                      30000 non-null int64\n",
            "AGE                           30000 non-null int64\n",
            "PAY_0                         30000 non-null int64\n",
            "PAY_2                         30000 non-null int64\n",
            "PAY_3                         30000 non-null int64\n",
            "PAY_4                         30000 non-null int64\n",
            "PAY_5                         30000 non-null int64\n",
            "PAY_6                         30000 non-null int64\n",
            "BILL_AMT1                     30000 non-null int64\n",
            "BILL_AMT2                     30000 non-null int64\n",
            "BILL_AMT3                     30000 non-null int64\n",
            "BILL_AMT4                     30000 non-null int64\n",
            "BILL_AMT5                     30000 non-null int64\n",
            "BILL_AMT6                     30000 non-null int64\n",
            "PAY_AMT1                      30000 non-null int64\n",
            "PAY_AMT2                      30000 non-null int64\n",
            "PAY_AMT3                      30000 non-null int64\n",
            "PAY_AMT4                      30000 non-null int64\n",
            "PAY_AMT5                      30000 non-null int64\n",
            "PAY_AMT6                      30000 non-null int64\n",
            "default_payment_next_month    30000 non-null int64\n",
            "dtypes: int64(25)\n",
            "memory usage: 5.7 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPRxCUVAwqBf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Phân chia train/val/dev/test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhWXoNmsRMyv",
        "colab_type": "code",
        "outputId": "1c5ce289-dc7f-4dee-bdf9-0cadaaa3d18d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "model_features = list(set(dataset.columns).difference({\"ID\", \"default_payment_next_month\"}))\n",
        "target = [\"default_payment_next_month\"]\n",
        "X = dataset[model_features]\n",
        "y = dataset[target]\n",
        "\n",
        "id_pos = np.where(y.values.reshape(-1) == 1)[0]\n",
        "id_neg = np.where(y.values.reshape(-1) == 0)[0]\n",
        "\n",
        "np.random.shuffle(id_pos)\n",
        "np.random.shuffle(id_neg)\n",
        "\n",
        "# Tập train:\n",
        "id_train_neg = id_neg[:10000] \n",
        "id_train_pos = id_pos[:500]\n",
        "id_train = np.concatenate((id_train_neg, id_train_pos), axis = 0)\n",
        "\n",
        "# Tập val:\n",
        "id_val_neg = id_neg[10000:12000]\n",
        "id_val_pos = id_pos[500:600]\n",
        "id_val = np.concatenate((id_val_neg, id_val_pos), axis = 0)\n",
        "\n",
        "# Tập dev:\n",
        "id_dev_neg = id_neg[12000:14000]\n",
        "id_dev_pos = id_pos[600:700]\n",
        "id_dev = np.concatenate((id_dev_neg, id_dev_pos), axis = 0)\n",
        "\n",
        "# Tập test:\n",
        "id_test_neg = id_neg[14000:16000]\n",
        "id_test_pos = id_pos[700:800]\n",
        "id_test = np.concatenate((id_test_neg, id_test_pos), axis = 0)\n",
        "\n",
        "# khởi tạo dataset\n",
        "data_train = dataset.iloc[id_train]\n",
        "data_val = dataset.iloc[id_val]\n",
        "data_dev = dataset.iloc[id_dev]\n",
        "data_test = dataset.iloc[id_test] \n",
        "\n",
        "print('data train shape: ', data_train.shape)\n",
        "print('data val shape: ', data_val.shape)\n",
        "print('data dev shape: ', data_dev.shape)\n",
        "print('data test shape: ', data_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data train shape:  (10500, 25)\n",
            "data val shape:  (2100, 25)\n",
            "data dev shape:  (2100, 25)\n",
            "data test shape:  (2100, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T494-uiN-LZ_",
        "colab_type": "text"
      },
      "source": [
        "## Thay đổi metric:\n",
        "\n",
        "Như đã giải thích ở mục đầu tiên, khi hiện tượng mất cân bằng dữ liệu nghiêm trọng xảy ra thì việc sử dụng độ chính xác làm thước đo đánh giá hiệu quả mô hình thường không chuẩn chuẩn xác bởi hầu hết các mô hình đều đạt độ chính xác rất cao. Một mô hình ngẫu nhiên dự báo toàn bộ là nhãn đa số cũng sẽ mang lại kết quả gần bằng 100%. Khi đó ta có thể cân nhắc tới một số metrics thay thế, có khả năng tập trung đánh giá độ chính xác trên nhóm thiểu số, sẽ có ý nghĩa hơn đối với việc lựa chọn mô hình.\n",
        "\n",
        "![](https://imgur.com/mqcSGn6.png)\n",
        "\n",
        "**Hình 1:** Bảng cross table mô tả kết quả thống kê chéo giữa nhãn dự báo và ground truth. Ở đây Positive tương ứng với nhãn `1` và Negative tương ứng với nhãn `0`.\n",
        "\n",
        "Từ bảng cross table ta dễ dàng hình dung được ý nghĩa của các chỉ số đó là:\n",
        "\n",
        "* Precision: Mức độ dự báo chính xác trong những trường hợp được dự báo là nhãn Positive.\n",
        "\n",
        "$$precision = \\frac{TP}{TP+FP}$$\n",
        "\n",
        "* Recall: Mức độ dự báo chuẩn xác những trường hợp là Positive trong những trường hợp thực tế là Positive.\n",
        "\n",
        "$$Recall = \\frac{TP}{TP+FN}$$\n",
        "\n",
        "* F1-Score: Trung bình điều hòa giữa Precision và Recall. Đây là chỉ số thay thế lý tưởng cho accuracy khi mô hình có tỷ lệ mất cân bằng mẫu cao.\n",
        "\n",
        "$$F1 = \\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}}$$\n",
        "\n",
        "* Kappa-Score: Là chỉ số đo lường mức độ liên kết tin cậy (inter-rater reliability) cho các categories.\n",
        "\n",
        "* Gini: Đo lường sự bất bình đẳng trong phân phối giữa Positive và Negative được dự báo từ mô hình.\n",
        "\n",
        "* AUC: Biểu diễn mối quan hệ giữa độ nhạy (sensitivity) và độ đặc hiệu (specificity). Đánh giá khả năng phân loại good và bad được dự báo từ mô hình.\n",
        "\n",
        "Trong bài này tôi sẽ sử dụng chỉ số `auc` và `f1 score` là 2 thước đo chính đánh giá mô hình."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-fb28hXUBG8",
        "colab_type": "text"
      },
      "source": [
        "# Xây dựng mô hình\n",
        "## Thuật toán Random forest:\n",
        "Bên dưới chúng ta sẽ sử dụng thuật toán random forest để huấn luyện mô hình. \n",
        "\n",
        "**Decision Tree**\n",
        "\n",
        "Trước tiên để hiểu về thuật toán Random Forest ta cần hiểu khái niệm về cây quyết định (decision tree). \n",
        "\n",
        "![](https://imgur.com/IrNJg5x.png)\n",
        "\n",
        "**Hình 2:** Sơ đồ cây quyết đinh. Các node là những hình tròn trắng. Các mũi tên liên kết các node với nhau được gọi là nhánh. Một cây quyết định sẽ xuất phát bắt đầu từ root node, sau đó rẽ nhánh tới các split node và trả ra kết quả phân phối xác suất cho quan sát tại leaf node. Rotine là đường đi liên kết các node với nhau bằng các nhánh.\n",
        "\n",
        "Decision tree sẽ xây dựng một cây quyết định ngẫu nhiên dựa trên các node (các hình tròn trắng trên hình) và nhánh (các mũi tên trên hình). Đại diện cho mỗi node là một câu hỏi mà giá trị trả về là YES hoặc NO. Các nhánh sẽ có tác dụng kết nối các nodes để tạo ra một kịch bản đường đi (routine).\n",
        "\n",
        "Node bắt đầu của cây quyết định là root node. Từ root node, mô hình sẽ xây dựng một câu hỏi lựa chọn. Tập các phương án có thể là toàn bộ các nhóm của biến category hoặc phương án YES/NO được tạo ra từ biến liên tục. Chẳng hạn trong hình vẽ các phương án của câu hỏi từ root node đó là `sunny` (nắng), `rainy` (mưa), `overcast` (u ám). Dựa trên lựa chọn của chúng ta mà từ root node sẽ rẽ nhánh đến các node mới được gọi là split node hoặc internal node. Chẳng hạn nếu lựa chọn nhánh kịch bản `sunny` thì sẽ rẽ tới internal node tiếp theo là `humidity`.\n",
        "\n",
        "Tại các internal node, mô hình tiếp tục rẽ nhánh tới những internal node ở tầng thấp hơn tương ứng với các biến khác. Thứ tự các biến được lựa chọn là ngẫu nhiên. Quá trình rẽ nhánh được thực hiện liên tục cho đến khi mô hình đi đến node cuối cùng là leaf node. Tại node này không có nhánh nào được rẽ thêm và trả ra kết quả dự báo của cây quyết định. \n",
        "\n",
        "Tợp hợp các liên kết giữa các node được gọi là đường đi (routine). Nhãn của kết quả dự báo phụ thuộc vào phân phối xác suất các classes được tính toán theo đường đi từ root node đến leaf node.\n",
        "\n",
        "**Random Forest**\n",
        "\n",
        "![](https://imgur.com/7BEBZgi.png)\n",
        "\n",
        "**Hình 3:** Kiến trúc mô hình random forest. Mô hình là một tập hợp của nhiều cây quyết định. Mỗi một cây quyết định sẽ trả ra một kết quả dự báo. Quyết định cuối cùng về nhãn của quan sát sẽ dựa trên nguyên tắc bầu cử đa số (Majority-Voting) trên toàn bộ các cây quyết định con. Ngoài ra mô hình cũng được chạy trên rất nhiều các sub-sample. Nếu một quan sát xuất hiện tại nhiều sub-sample thì sẽ thực hiện bầu cử đa số trên cả các cây quyết định của toàn bộ các sub-sample.\n",
        "\n",
        "Random Forest là thuật toán thuộc lớp mô hình kết hợp (ensemble model). Kết quả của thuật toán dựa trên không chỉ từ một cây quyết định mà từ nhiều cây quyết định. Thuật toán sẽ xây dựng nhiều kịch bản cây quyết định khác nhau và mỗi một cây được sẽ được áp dụng trên nhiều mẫu dữ liệu con được lựa chọn ngẫu nhiên. Kết quả nhãn dự báo cho một quan sát được tổng hợp từ rất nhiều mô hình cây quyết định khác nhau và ta sẽ voting trên tập hợp các kết quả đó để quyết định nhãn cuối cùng.\n",
        "\n",
        "Kết quả từ mô hình Random Forest được kết hợp từ nhiều mô hình con nên có độ tin cậy cao hơn. Do đó thường có kết quả dự báo chính xác hơn so với những mô hình phân loại tuyến tính như logistic hoặc linear regression.\n",
        "\n",
        "Bên cạnh Random Forest thì Gradient Boosting và AdaBoost cũng là các mô hình thuộc lớp mô hình kết hợp thường được áp dụng và mang lại hiệu quả cao tại nhiều cuộc thi.\n",
        "\n",
        "**Tham số của Random Forest:**\n",
        "\n",
        "Sẽ có một vài kịch bản tham số được lựa chọn và dựa trên kiểm nghiệm từ tập dev, chúng ta quyết định lựa chọn bộ siêu tham số phù hợp nhất.\n",
        "\n",
        "Có rất nhiều tham số trong một mô hình Random Forest, trong đó một số tham số chính được sử dụng để tunning mô hình là:\n",
        "\n",
        "* **n_estimators**: Số lượng các trees trên một cây quyết định.\n",
        "* **max_depth**: Độ sâu lớn nhất của một cây quyết định.\n",
        "* **min_samples_split**: Số lượng mẫu tối thiểu cần thiết để phân chia một internal node. Nếu kích thước mẫu ở một internal node nhỏ hơn ngưỡng thì ta sẽ không rẽ nhánh internal node.\n",
        "* **max_features**: Số lượng các features được xem xét khi tìm kiếm phương án phân chia tốt nhất. Mặc định là toàn bộ các features đầu vào.\n",
        "* **class_weight**: Trọng số tương ứng với mỗi class. Mặc định là None, khi đó các class sẽ có mức độ quan trọng như nhau. Nếu lựa chọn `balance` các class sẽ được đánh trọng số tỷ lệ nghịch với tỷ trọng mẫu của chúng.\n",
        "* **min_impurity_split**: Ngưỡng để dừng sớm (early stopping) quá trình phát triển của cây quyết định. Nó sẽ tiếp tục phân chia nếu độ vẩn đục (impurity) lớn hơn ngưỡng threshold, trái lại thì nó là node leaf.\n",
        "\n",
        "Chúng ta sẽ có một số kịch bản mô hình như sau:\n",
        "\n",
        "* Mô hình 1:\n",
        "\n",
        "n_estimators=100, \n",
        "\n",
        "max_depth=5, \n",
        "\n",
        "min_samples_split=200, \n",
        "\n",
        "class_weight=None,\n",
        "\n",
        "max_features=10\n",
        "\n",
        "* Mô hình 2: \n",
        "\n",
        "n_estimators=500, \n",
        "\n",
        "max_depth=10, \n",
        "\n",
        "min_samples_split=400,\n",
        "\n",
        "max_features=\"auto\" \n",
        "\n",
        "class_weight=\"balanced\"\n",
        "\n",
        "max_features = 20\n",
        "\n",
        "* Mô hình 3: \n",
        "\n",
        "n_estimators=800, \n",
        "\n",
        "max_depth=10, \n",
        "\n",
        "min_samples_split=200,\n",
        "\n",
        "max_features=\"sqrt\" \n",
        "\n",
        "class_weight=\"balanced\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxXZuHxt7Mel",
        "colab_type": "code",
        "outputId": "df143a35-8dbe-4f71-e99f-0f93c0c1fee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model1 = RandomForestClassifier(n_estimators=100,\n",
        "                                max_depth=5,\n",
        "                                min_samples_split=200,\n",
        "                                class_weight=None,\n",
        "                                max_features=10)\n",
        "\n",
        "model2 = RandomForestClassifier(n_estimators=500, \n",
        "                                max_depth=10, \n",
        "                                min_samples_split=400, \n",
        "                                random_state=12, \n",
        "                                class_weight=\"balanced\",\n",
        "                                max_features=\"auto\")\n",
        "\n",
        "model3 = RandomForestClassifier(n_estimators=800, \n",
        "                                max_depth=10, \n",
        "                                min_samples_split=200, \n",
        "                                random_state=12, \n",
        "                                class_weight=\"balanced\",\n",
        "                                max_features=\"sqrt\")\n",
        "\n",
        "def _tunning_model(model , X_train, y_train, X_dev, y_dev):\n",
        "  model.fit(X_train, y_train)\n",
        "  model_predictions = model.predict_proba(X_dev)\n",
        "  model_roc_score = roc_auc_score(y_dev, \n",
        "                                  model_predictions[:,1])\n",
        "  return model, model_roc_score\n",
        "\n",
        "model1, model1_roc_score = _tunning_model(model1, \n",
        "                                          data_train[model_features], data_train['default_payment_next_month'],\n",
        "                                          data_dev[model_features], data_dev['default_payment_next_month'])\n",
        "print('model 1 ROC score on dev dataset: ', model1_roc_score)\n",
        "\n",
        "\n",
        "model2, model2_roc_score = _tunning_model(model2, \n",
        "                                          data_train[model_features], data_train['default_payment_next_month'],\n",
        "                                          data_dev[model_features], data_dev['default_payment_next_month'])\n",
        "print('model 2 ROC score on dev dataset: ', model2_roc_score)\n",
        "\n",
        "model3, model3_roc_score = _tunning_model(model3, \n",
        "                                          data_train[model_features], data_train['default_payment_next_month'],\n",
        "                                          data_dev[model_features], data_dev['default_payment_next_month'])\n",
        "print('model 3 ROC score on dev dataset: ', model3_roc_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model 1 ROC score on dev dataset:  0.7648699999999999\n",
            "model 2 ROC score on dev dataset:  0.7681\n",
            "model 3 ROC score on dev dataset:  0.768555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWDoQinTtDO9",
        "colab_type": "text"
      },
      "source": [
        "Như vậy bằng kiểm tra trên tập dev set cho thấy mô hình 2 sẽ có kết quả tốt nhất. Do đó ta sẽ coi mô hình 2 như một model baseline và các siêu tham số của nó sẽ được giữ để khởi tạo các mô hình về sau."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7DWeLyF_E8e",
        "colab_type": "text"
      },
      "source": [
        "## Under sampling\n",
        "\n",
        "Under sampling là việc ta giảm số lượng các quan sát của nhóm đa số để nó trở nên cân bằng với số quan sát của nhóm thiểu số. Ưu điểm của under sampling là làm cân bằng mẫu một cách nhanh chóng, dễ dàng tiến hành thực hiện mà không cần đến thuật toán giả lập mẫu. \n",
        "\n",
        "Tuy nhiên nhược điểm của nó là kích thước mẫu sẽ bị giảm một cách trầm trọng. Gỉa sử nhóm thiểu số của chúng ta có kích thước là 500, như vậy để tạo ra sự cân bằng mẫu giữa nhóm đa số và thiểu số sẽ cần giảm kích thước mẫu của nhóm đa số từ 10000 về 500. Tổng kích thước tập huấn luyện sau khi under sampling là 1000 và chiếm khoảng 1/10 so với kích thước tập huấn luyện ban đầu. Đây là tập huấn luyện rất nhỏ, không đại diện cho phân phối của toàn bộ tập dữ liệu và thường dễ dẫn tới hiện tượng overfitting.\n",
        "\n",
        "Do đó trong một số phương án, chúng ta có thể không nhất thiết lựa chọn sao cho tỷ lệ mẫu giữa `nhóm đa số: nhóm thiểu số` là `50%:50%` mà có thể giảm dần xuống về `80%:20%`, `70%:30%` hoặc `60%:40%` và tìm ra phương án nào mang lại hiệu quả dự báo tốt nhất trên tập kiểm tra.\n",
        "\n",
        "Bên dưới ta sẽ xây dựng mô hình trên 2 tỷ lệ mẫu `80%:20%` và `70%:30%` và đánh giá mô hình trên tập test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcvkpj9ZCstK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Phân chia mẫu ngẫu nhiên theo tỷ lệ 80%:20% bằng cách giữ lại 2000 mẫu ngẫu nhiên từ tập train\n",
        "np.random.shuffle(id_train_neg)\n",
        "id_train_neg_80_20 = id_train_neg[:2000]\n",
        "id_train_80_20 = np.concatenate((id_train_neg_80_20, id_train_pos), axis = 0)\n",
        "\n",
        "# Phân chia mẫu ngẫu nhiên theo tỷ lệ 70%:30% bằng cách giữ lại 1166 mẫu ngẫu nhiên từ tập train\n",
        "np.random.shuffle(id_train_neg)\n",
        "id_train_neg_70_30 = id_train_neg[:1166]\n",
        "\n",
        "id_train_70_30 = np.concatenate((id_train_neg_70_30, id_train_pos), axis = 0) \n",
        "\n",
        "# khởi tạo dataset\n",
        "data_train_80_20 = dataset.iloc[id_train_80_20]\n",
        "data_train_70_30 = dataset.iloc[id_train_70_30]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7SKpZ-dCfwW",
        "colab_type": "code",
        "outputId": "8cba8b2d-e09f-4b96-898f-1075835c8cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Huấn luyện mô hình trên mẫu tỷ lệ 80%:20%\n",
        "model2_unsam_80_20 = RandomForestClassifier(n_estimators=500, \n",
        "                                            max_depth=10, \n",
        "                                            min_samples_split=400, \n",
        "                                            random_state=12, \n",
        "                                            class_weight=\"balanced\",\n",
        "                                            max_features=\"auto\")\n",
        "\n",
        "model2_unsam_80_20.fit(data_train_80_20[model_features], data_train_80_20['default_payment_next_month'])\n",
        "model_predictions = model2_unsam_80_20.predict_proba(data_test[model_features])\n",
        "model_pred_label = model2_unsam_80_20.predict(data_test[model_features]) \n",
        "model_roc_score = roc_auc_score(data_test['default_payment_next_month'], model_predictions[:,1])\n",
        "model_f1_score = f1_score(data_test['default_payment_next_month'], model_pred_label)\n",
        "print('model2_unsam_80_20 roc score on test: ', model_roc_score)\n",
        "print('model2_unsam_80_20 f1 score on test: ', model_f1_score)\n",
        "\n",
        "# Huấn luyện mô hình trên mẫu tỷ lệ 70%:30%\n",
        "model2_unsam_70_30 = RandomForestClassifier(n_estimators=500, \n",
        "                                            max_depth=10, \n",
        "                                            min_samples_split=400, \n",
        "                                            random_state=12, \n",
        "                                            class_weight=\"balanced\",\n",
        "                                            max_features=\"auto\")\n",
        "\n",
        "model2_unsam_70_30.fit(data_train_70_30[model_features], data_train_70_30['default_payment_next_month'])\n",
        "model_predictions = model2_unsam_70_30.predict_proba(data_test[model_features])\n",
        "model_pred_label = model2_unsam_70_30.predict(data_test[model_features]) \n",
        "model_roc_score = roc_auc_score(data_test['default_payment_next_month'], model_predictions[:,1])\n",
        "model_f1_score = f1_score(data_test['default_payment_next_month'], model_pred_label)\n",
        "print('model2_unsam_70_30 roc score on test: ', model_roc_score)\n",
        "print('model2_unsam_70_30 f1 score on test: ', model_f1_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model2_unsam_80_20 roc score on test:  0.7702749999999998\n",
            "model2_unsam_80_20 f1 score on test:  0.19999999999999998\n",
            "model2_unsam_70_30 roc score on test:  0.7649575000000001\n",
            "model2_unsam_70_30 f1 score on test:  0.1949778434268833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4jjOe1fHNcu",
        "colab_type": "text"
      },
      "source": [
        "Dự báo mô hình trên tập test và tính toán các chỉ số `auc` và `f1 score`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiCZwdgoHE9M",
        "colab_type": "code",
        "outputId": "d4aa3487-e224-40a9-d1f7-4cafa9cfde6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model_predictions = model2.predict_proba(data_test[model_features])\n",
        "model_pred_label = model2.predict(data_test[model_features]) \n",
        "model_roc_score = roc_auc_score(data_test['default_payment_next_month'], model_predictions[:,1])\n",
        "model_f1_score = f1_score(data_test['default_payment_next_month'], model_pred_label)\n",
        "print('random forest roc score on test: ', model_roc_score)\n",
        "print('random forest f1 score on test: ', model_f1_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random forest roc score on test:  0.77301\n",
            "random forest f1 score on test:  0.21946902654867256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tAPTCPEHwMU",
        "colab_type": "text"
      },
      "source": [
        "So sanh kết quả cho ta thấy khi thực hiện under sampling đã không giúp cải thiện được nhiều kết quả dự báo trên tập test ở cả 2 chỉ số `auc` và `f1 score`. Nguyên nhân có thể là do việc thực hiện over sampling đã dẫn tới overfitting. Chúng ta cần thử nghiệm với nhiều tỷ lệ mẫu khác nhau hơn để tìm ra tỷ lệ phù hợp. Phần này xin dành cho bạn đọc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvFQ4733mHNI",
        "colab_type": "text"
      },
      "source": [
        "## Over sampling\n",
        "\n",
        "Over sampling là các phương pháp giúp giải quyết hiện tượng mất cân bằng mẫu bằng cách gia tăng kích thước mẫu thuộc nhóm thiểu số bằng các kĩ thuật khác nhau. Có 2 phương pháp chính để thực hiện over sampling đó là:\n",
        "\n",
        "* Lựa chọn mẫu có tái lập.\n",
        "* Mô phỏng mẫu mới dựa trên tổng hợp của các mẫu cũ.\n",
        "\n",
        "Chúng ta cùng tìm hiểu cụ thể các phương pháp này ở phần bên dưới.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otLnSLIGg5kL",
        "colab_type": "text"
      },
      "source": [
        "### Naive random over-sampling\n",
        "\n",
        "Naive random Over sampling là phương pháp tái chọn mẫu dựa trên giả thuyết ngây ngô là dữ liệu của mẫu mới sẽ hoàn toàn giống dữ liệu sẵn có. Do đó ta sẽ chọn mẫu bằng cách lựa chọn ngẫu nhiên có lặp lại các quan sát thuộc nhóm thiểu số. \n",
        "\n",
        "Do lựa chọn dữ liệu có lặp lại nên các quan sát thu được sau naive random over-sampling chính là những quan sát thực tế và đánh giá dược đúng bản chất dữ liệu.\n",
        "\n",
        "Bên dưới ta sẽ lựa chọn Naive random over-sampling sao cho tỷ lệ mẫu thuộc nhóm thiểu số và nhóm đa số là bằng 1. Sau đó huấn luyện model trên tập mẫu đã được over sampling và kiểm tra kết quả trên tập test. So sánh với kết quả từ mô hình baseline để đánh giá phương pháp over sampling có giúp cải thiện hiệu năng dự báo hay không?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFP_h-I69Xh",
        "colab_type": "code",
        "outputId": "c9e119fb-db73-48a6-fd68-dc4b077691f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.base import BaseSampler"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXtfJX197P7n",
        "colab_type": "code",
        "outputId": "4cc6b6e2-9425-454d-8d56-1421148c3762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "model_smote = RandomForestClassifier(n_estimators=500, \n",
        "                                max_depth=10, \n",
        "                                min_samples_split=400, \n",
        "                                random_state=12, \n",
        "                                class_weight=\"balanced\",\n",
        "                                max_features=\"auto\")\n",
        "\n",
        "pipe = make_pipeline(RandomOverSampler(sampling_strategy=1, random_state=0), model_smote)\n",
        "pipe.fit(data_train[model_features], data_train['default_payment_next_month'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('randomoversampler',\n",
              "                 RandomOverSampler(random_state=0, ratio=None,\n",
              "                                   return_indices=False, sampling_strategy=1)),\n",
              "                ('randomforestclassifier',\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight='balanced',\n",
              "                                        criterion='gini', max_depth=10,\n",
              "                                        max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1,\n",
              "                                        min_samples_split=400,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=500, n_jobs=None,\n",
              "                                        oob_score=False, random_state=12,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXi7C_Gk7eoY",
        "colab_type": "text"
      },
      "source": [
        "Dự báo và kiểm định trên test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2Fo5ACcTshf",
        "colab_type": "code",
        "outputId": "40301cae-e9ae-443b-98a3-bf7dc34518a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model_smote_predictions = pipe.predict_proba(data_test[model_features])\n",
        "model_smote_pred_label = pipe.predict(data_test[model_features]) \n",
        "model_smote_roc_score = roc_auc_score(data_test['default_payment_next_month'], model_smote_predictions[:,1])\n",
        "model_smote_f1_score = f1_score(data_test['default_payment_next_month'], model_smote_pred_label)\n",
        "print('random forest roc score on test: ', model_smote_roc_score)\n",
        "print('random forest f1 score on test: ', model_smote_f1_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random forest roc score on test:  0.7825150000000001\n",
            "random forest f1 score on test:  0.2565217391304348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjaqJHt53S-Q",
        "colab_type": "code",
        "outputId": "50cf7a98-c10e-4a5e-9009-7b5688899269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model_predictions = model2.predict_proba(data_test[model_features])\n",
        "model_pred_label = model2.predict(data_test[model_features]) \n",
        "model_roc_score = roc_auc_score(data_test['default_payment_next_month'], model_predictions[:,1])\n",
        "model_f1_score = f1_score(data_test['default_payment_next_month'], model_pred_label)\n",
        "print('random forest roc score on test: ', model_roc_score)\n",
        "print('random forest f1 score on test: ', model_f1_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random forest roc score on test:  0.782075\n",
            "random forest f1 score on test:  0.245398773006135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyuu76PzTxV9",
        "colab_type": "text"
      },
      "source": [
        "Như vậy ta thấy rằng khi sử dụng phương pháp random over sampling mẫu sẽ giúp cải thiện được đáng kể kết quả dự báo. Chỉ số `auc` tăng lên từ:\n",
        "`0.7820` trên tập test lên `0.7825` và chỉ số `f1 score` tăng từ `0.2454` lên `0.2565`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLfpXfPUWqgt",
        "colab_type": "text"
      },
      "source": [
        "### SMOTE & ADASYN\n",
        "\n",
        "SMOTE (Synthetic Minority Over-sampling) và ADASYN (Adaptive synthetic sampling) là các phương pháp sinh mẫu nhằm gia tăng kích thước mẫu của nhóm thiểu số trong trường hợp xảy ra mất cân bằng mẫu. Quá trình gia tăng kích thước mẫu sẽ dựa trên một tổ hợp tuyến tính của các mẫu láng giềng gần nhất với các quan sát thuộc mẫu thiểu số để tạo ra kết quả khái quát nhất. Phương pháp để lựa chọn ra các láng giềng của một quan sát có thể dựa trên thuật toán `kNN` hoặc `SVM`.\n",
        "\n",
        "Chi tiết các thuật toán này tôi sẽ không trình bày tại đây. Các bạn có thể tham khảo tại [Synthetic Minority Over-sampling](https://arxiv.org/pdf/1106.1813.pdf) và [Adasyn adaptive synthetic](https://towardsdatascience.com/adasyn-adaptive-synthetic-sampling-method-for-imbalanced-data-602a3673ba16).\n",
        "\n",
        "Bên dưới ta sẽ cùng áp dụng phương pháp over-sampling từ SMOTE và ADASYN và kiểm tra kết quả dự báo của mô hình được huấn luyện trên mẫu over-sampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guwabniSgpLQ",
        "colab_type": "code",
        "outputId": "ce791bce-9cfe-4734-991d-9e1103576303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "from imblearn.pipeline import make_pipeline\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.over_sampling import (SMOTE, BorderlineSMOTE, SVMSMOTE, SMOTENC)\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.base import BaseSampler\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=500, \n",
        "                                max_depth=10, \n",
        "                                min_samples_split=400, \n",
        "                                random_state=12, \n",
        "                                class_weight=\"balanced\",\n",
        "                                max_features=\"auto\")\n",
        "\n",
        "smotes = {0 : 'SMOTE',\n",
        "          1 : 'BorderlineSMOTE',\n",
        "          2 : 'SVMSMOTE',\n",
        "          3 : 'ADASYN'}\n",
        "\n",
        "\n",
        "for i, sampler in enumerate((SMOTE(sampling_strategy = 1, random_state=0),\n",
        "                BorderlineSMOTE(sampling_strategy = 1, random_state=0, kind='borderline-1'),\n",
        "                SVMSMOTE(sampling_strategy = 1, random_state=0),\n",
        "                ADASYN(sampling_strategy = 1, random_state=0))):\n",
        "    pipe_line = make_pipeline(sampler, rf_clf)\n",
        "    pipe_line.fit(data_train[model_features], data_train['default_payment_next_month'])\n",
        "    rf_predictions = pipe_line.predict_proba(data_test[model_features])\n",
        "    rf_pred_label = pipe_line.predict(data_test[model_features]) \n",
        "    rf_roc_score = roc_auc_score(data_test['default_payment_next_month'], rf_predictions[:,1])\n",
        "    rf_f1_score = f1_score(data_test['default_payment_next_month'], rf_pred_label)\n",
        "    print('------------------------------------------------')\n",
        "    print('SMOTE method: ', smotes[i])\n",
        "    print('random forest roc score on test: ', rf_roc_score)\n",
        "    print('random forest f1 score on test: ', rf_f1_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------\n",
            "SMOTE method:  SMOTE\n",
            "random forest roc score on test:  0.71945\n",
            "random forest f1 score on test:  0.2255965292841649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------\n",
            "SMOTE method:  BorderlineSMOTE\n",
            "random forest roc score on test:  0.767965\n",
            "random forest f1 score on test:  0.2519280205655527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------\n",
            "SMOTE method:  SVMSMOTE\n",
            "random forest roc score on test:  0.776185\n",
            "random forest f1 score on test:  0.28387096774193554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------\n",
            "SMOTE method:  ADASYN\n",
            "random forest roc score on test:  0.71786\n",
            "random forest f1 score on test:  0.21940928270042193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMC8EqdVhuaz",
        "colab_type": "text"
      },
      "source": [
        "Như vậy ta thấy có 2 phương pháp SMOTE là `SVMSMOTE` và `BorderlineSMOTE` đã giúp tăng chỉ số `f1` score so với mô hình baseline. Trong đó phương pháp `SVMSMOTE` có mức độ cải thiện f1 score là gần 4% từ `0.2454` lên `0.2839`. Trong khi f1 score thay đổi không đáng kể. Đây là cải thiện rất tốt đối với một mô hình mà hầu hết kết quả của `f1` chỉ xoay quanh khoảng từ `0.24-0.25`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubQPCRyu6RNa",
        "colab_type": "text"
      },
      "source": [
        "## Thu thập thêm dữ liệu\n",
        "\n",
        "Thông thường với các mô hình mà số lượng quan sát trong mẫu thiểu quá nhỏ sẽ không đại diện cho toàn bộ các trường hợp của `vỡ nợ`. Để mô hình học được bao quát hơn các khả năng, chúng ta cần gia tăng kích thước mẫu thiểu bằng cách thu thập thêm các quan sát trên thực tế thuộc nhóm thiểu. \n",
        "\n",
        "Ví dụ, giả sử ta lấy thêm 500 quan sát thuộc nhóm thiểu số vào tập train. Các quan sát này phải thỏa mãn điều kiện chưa từng xuất hiện ở các mẫu của tập test. Bởi vì về nguyên tắc, khi đánh giá mô hình, chúng ta không được lấy mẫu đã được huấn luyến để kiểm tra mô hình.\n",
        "\n",
        "Như vậy ta sẽ có một tập dữ liệu mới gọi là `data_train_add` có 10000 mẫu thông thường và 1000 mẫu vỡ nợ. Cùng xây dựng mô hình và kiểm tra trên tập test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYnmUEYG6wvE",
        "colab_type": "code",
        "outputId": "ecfdd504-7789-4af1-89a6-398d69f95d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Tập train:\n",
        "id_train_neg = id_neg[:10000] \n",
        "id_train_pos = id_pos[:500]\n",
        "# Lấy ngẫu nhiên 500 quan sát thuộc nhóm thiểu không trùng với test\n",
        "id_train_pos_add = id_pos[800:1300]\n",
        "id_train_add = np.concatenate((id_train_neg, id_train_pos, id_train_pos_add), axis = 0)\n",
        "\n",
        "# khởi tạo dataset\n",
        "data_train_add = dataset.iloc[id_train_add]\n",
        "print('data train shape: ', data_train_add.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data train shape:  (11000, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95ltwZL_7I6b",
        "colab_type": "code",
        "outputId": "21313f80-fac7-4fc0-99a7-b7ecc39249fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model_add = RandomForestClassifier(n_estimators=800, \n",
        "                                max_depth=10, \n",
        "                                min_samples_split=200, \n",
        "                                random_state=12, \n",
        "                                class_weight=\"balanced\",\n",
        "                                max_features=\"sqrt\")\n",
        "\n",
        "model_add.fit(data_train_add[model_features], data_train_add['default_payment_next_month'])\n",
        "model_add_predictions = model_add.predict_proba(data_test[model_features])\n",
        "model_add_pred_label = model_add.predict(data_test[model_features]) \n",
        "model_add_roc_score = roc_auc_score(data_test['default_payment_next_month'], model_add_predictions[:,1])\n",
        "model_add_f1_score = f1_score(data_test['default_payment_next_month'], model_add_pred_label)\n",
        "print('random forest roc score on test: ', model_add_roc_score)\n",
        "print('random forest f1 score on test: ', model_add_f1_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random forest roc score on test:  0.79414\n",
            "random forest f1 score on test:  0.2629310344827586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ByCBTaL8qZC",
        "colab_type": "text"
      },
      "source": [
        "Như vậy ta nhận thấy thu thập thêm dữ liệu cho nhóm thiểu số cũng là một phương án cải thiện khả năng dự báo so với model baseline, chỉ số `auc` và `f1 score` đều tăng.\n",
        "\n",
        "## Thu thập thêm biến\n",
        "\n",
        "Mô hình có kết quả kém có thể là do dữ liệu đang thiếu những biến quan trọng có ảnh hưởng lớn tới hành vi của nhóm thiểu số. Chẳng hạn đối với bài toán dự báo khả năng vỡ nợ, chúng ta có thể thu thập thêm dữ liệu về lịch sử tín dụng của khách hàng trên toàn bộ hệ thống ngân hàng để kiểm tra xem liệu khách hàng có đang vay vốn tại các ngân hàng khác không và khách hàng đã từng phát sinh nợ quá hạn chưa?\n",
        "\n",
        "Có nhiều biến đầu vào quan trọng không dễ dàng nhận biết nếu data scientist không có hiểu biết về lĩnh vực đó. Do đó hiểu biết lĩnh vực (knownledge domain) rất quan trọng đối với mọi data scientist trước khi xây dựng mô hình. Để bổ sung thêm biến, chúng ta có thể xin ý kiến chuyên gia trong lĩnh vực mà ta đang phân loại. Các chuyên gia là người có kinh nghiệm lâu năm và có hiểu biết sâu sắc về đặc tính của các nhóm. Do đó họ sẽ đưa ra nhiều rules nhận diện và các biến quan trọng giúp ích cho phân loại."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpUg7rTtpszi",
        "colab_type": "text"
      },
      "source": [
        "## Phạt mô hình\n",
        "\n",
        "Việc dự báo sai một quan sát thuộc mẫu đa số sẽ ít nghiêm trọng hơn so với dự báo sai một quan sát thuộc mẫu thiểu số. Xuất phát từ ý tưởng đó chúng ta sẽ phạt nặng hơn đối với sai số dự báo thuộc nhóm thiểu bằng cách gán cho nó một trọng số lớn hơn trong công thức của hàm loss function. Chẳng hạn như bên dưới trong argument `class_weight` chúng ta sẽ gán cho các trọng số của class thiểu số nhãn `1` là giá trị 0.9 và class đa số nhãn `0` là 0.1. Khi đó kết quả mô hình thu được trên tập test sẽ là:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtIz3BfTo_bT",
        "colab_type": "code",
        "outputId": "3911e4af-4d83-4969-a21e-ac02546c0c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model_pen = RandomForestClassifier(n_estimators=500, \n",
        "                                max_depth=10, \n",
        "                                min_samples_split=400, \n",
        "                                random_state=12, \n",
        "                                class_weight={0: 0.1,\n",
        "                                              1: 0.9},\n",
        "                                max_features=\"auto\")\n",
        "\n",
        "model_pen.fit(data_train[model_features], data_train['default_payment_next_month'])\n",
        "model_pen_predictions = model_pen.predict_proba(data_test[model_features])\n",
        "model_pen_pred_label = model_pen.predict(data_test[model_features]) \n",
        "model_pen_roc_score = roc_auc_score(data_test['default_payment_next_month'], model_pen_predictions[:,1])\n",
        "model_pen_f1_score = f1_score(data_test['default_payment_next_month'], model_pen_pred_label)\n",
        "print('random forest roc score on test: ', model_pen_roc_score)\n",
        "print('random forest f1 score on test: ', model_pen_f1_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random forest roc score on test:  0.784845\n",
            "random forest f1 score on test:  0.3092105263157895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOEYzUxdtmRg",
        "colab_type": "text"
      },
      "source": [
        "Ta thấy cả `auc` và `f1 score` đều cao hơn so với baseline model. Trong đó `f1` đã tăng gần 6% từ `0.2454` lên tới `0.3`. Đây là kết quả khả quan nhất trong các mô hình từ trước đến nay."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxE0N_8TuLML",
        "colab_type": "text"
      },
      "source": [
        "## Thử nghiệm nhiều phương pháp khác nhau.\n",
        "\n",
        "Quá trình thực nghiệm cho thấy mỗi một thuật toán sẽ có kết quả tốt đối với mỗi một bộ dữ liệu khác nhau. Có thuật toán cho kết quả tốt trên các bộ dữ liệu mất cân bằng nghiêm trọng nhưng kém hiệu quả trên các bộ dữ liệu không bị mất cân bằng. Do đó điều chúng ta không nên tin tưởng vào một thuật toán mà phải mở rộng và thử nghiệm mô hình trên nhiều thuật toán khác nhau.\n",
        "\n",
        "Bên dưới chúng ta cùng lần lượt hồi qui mô hình với các thuật toán và kiểm tra mức độ dự báo chính xác trên tập test.\n",
        "\n",
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7gDvhO-vI45",
        "colab_type": "code",
        "outputId": "62867335-4f09-42d7-85c3-069a6e541b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(C = 0.0001)\n",
        "\n",
        "def _train_and_test(model, algo):\n",
        "  model.fit(data_train[model_features], data_train['default_payment_next_month'])\n",
        "  predictions = model.predict_proba(data_test[model_features])\n",
        "  pred_label = model.predict(data_test[model_features]) \n",
        "  roc_score = roc_auc_score(data_test['default_payment_next_month'], predictions[:,1])\n",
        "  model_f1_score = f1_score(data_test['default_payment_next_month'], pred_label)\n",
        "  print('{} roc score on test: {}'.format(algo , roc_score))\n",
        "  print('{} f1 score on test: {}'.format(algo, model_f1_score))\n",
        "  return model\n",
        "\n",
        "log_reg = _train_and_test(log_reg, algo = 'Logistic')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic roc score on test: 0.6628700000000001\n",
            "Logistic f1 score on test: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIGF9ukgvWrm",
        "colab_type": "text"
      },
      "source": [
        "**kNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-YkFKgDvaoL",
        "colab_type": "code",
        "outputId": "7f578541-0f9b-4557-bd59-ac0499cf9e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors = 5, \n",
        "                                      weights = 'distance',\n",
        "                                      algorithm = 'kd_tree',\n",
        "                                      metric = 'minkowski'\n",
        "                                      )\n",
        "\n",
        "knn_classifier = _train_and_test(knn_classifier, algo = 'kNN')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kNN roc score on test: 0.5585575\n",
            "kNN f1 score on test: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpKxs2TfvQju",
        "colab_type": "text"
      },
      "source": [
        "**SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZk5AF_8vTe3",
        "colab_type": "code",
        "outputId": "c8b692da-f532-4f25-f146-ab2da7275585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "svm_classifier = LinearSVC(penalty='l2', \n",
        "                           loss='squared_hinge',\n",
        "                           tol=0.0001,\n",
        "                           C=0.9,\n",
        "                           dual=False,\n",
        "                           class_weight='balanced',\n",
        "                           max_iter=1000\n",
        "                          )\n",
        "svm_classifier = CalibratedClassifierCV(svm_classifier) \n",
        "svm_classifier = _train_and_test(svm_classifier, algo = 'SVM')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM roc score on test: 0.71934\n",
            "SVM f1 score on test: 0.03773584905660377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYWUUB0-vcg9",
        "colab_type": "text"
      },
      "source": [
        "**MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYjfUXpC2mYq",
        "colab_type": "code",
        "outputId": "281d5ed9-e204-4f65-f64a-fcf9e68dc9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10500, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxHbGIdgveMo",
        "colab_type": "code",
        "outputId": "35e8fc2c-2aee-4428-cc7b-1ff073fffb49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# # concate nate all layers\n",
        "# encode_els = concatenate(encode_els) \n",
        "inputlayer = Input(shape=(23,))\n",
        "hidden1 = Dense(units = 128, kernel_initializer = 'normal', activation = 'relu')(inputlayer)\n",
        "droplayer1 = Dropout(0.8)(hidden1)\n",
        "hidden2 = Dense(64, kernel_initializer = 'normal', activation = 'relu')(droplayer1)\n",
        "droplayer2 = Dropout(0.2)(hidden2)\n",
        "outputlayer = Dense(1, kernel_initializer = 'normal', activation = 'sigmoid')(droplayer2)\n",
        "mlp_classifier = Model(inputs = inputlayer, outputs = [outputlayer])\n",
        "mlp_classifier.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 23)]              0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 128)               3072      \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 11,393\n",
            "Trainable params: 11,393\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVEGZ_k_3AvN",
        "colab_type": "code",
        "outputId": "910eb76d-bb14-44b0-fe0e-4bd0846d97e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "optimizer = Adam()\n",
        "mlp_classifier.compile(optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "mlp_classifier.fit(data_train[model_features], data_train['default_payment_next_month'],\n",
        "                   validation_data = (data_val[model_features], data_val['default_payment_next_month']),\n",
        "                   epochs = 10,\n",
        "                   batch_size = 64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10500 samples, validate on 2100 samples\n",
            "Epoch 1/10\n",
            "10500/10500 [==============================] - 1s 90us/sample - loss: 0.4324 - acc: 0.9504 - val_loss: 0.1956 - val_acc: 0.9524\n",
            "Epoch 2/10\n",
            "10500/10500 [==============================] - 0s 44us/sample - loss: 0.6002 - acc: 0.9515 - val_loss: 0.1946 - val_acc: 0.9524\n",
            "Epoch 3/10\n",
            "10500/10500 [==============================] - 0s 42us/sample - loss: 0.3891 - acc: 0.9515 - val_loss: 0.1997 - val_acc: 0.9524\n",
            "Epoch 4/10\n",
            "10500/10500 [==============================] - 0s 43us/sample - loss: 0.3764 - acc: 0.9516 - val_loss: 0.1916 - val_acc: 0.9524\n",
            "Epoch 5/10\n",
            "10500/10500 [==============================] - 0s 42us/sample - loss: 0.2243 - acc: 0.9517 - val_loss: 0.1958 - val_acc: 0.9524\n",
            "Epoch 6/10\n",
            "10500/10500 [==============================] - 0s 43us/sample - loss: 0.3493 - acc: 0.9514 - val_loss: 0.1917 - val_acc: 0.9524\n",
            "Epoch 7/10\n",
            "10500/10500 [==============================] - 0s 42us/sample - loss: 0.3474 - acc: 0.9520 - val_loss: 0.1908 - val_acc: 0.9524\n",
            "Epoch 8/10\n",
            "10500/10500 [==============================] - 0s 42us/sample - loss: 0.4276 - acc: 0.9513 - val_loss: 0.1916 - val_acc: 0.9524\n",
            "Epoch 9/10\n",
            "10500/10500 [==============================] - 0s 43us/sample - loss: 0.2603 - acc: 0.9522 - val_loss: 0.1916 - val_acc: 0.9524\n",
            "Epoch 10/10\n",
            "10500/10500 [==============================] - 0s 44us/sample - loss: 0.2829 - acc: 0.9522 - val_loss: 0.1915 - val_acc: 0.9524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd201605cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9v2EqoM7uq4",
        "colab_type": "code",
        "outputId": "6b9055ab-1f68-45ac-d44f-2b3445e82132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "predictions = mlp_classifier.predict(data_test[model_features])\n",
        "pred_label = [0 if prob <= 0.5 else 1 for prob in predictions]\n",
        "roc_score = roc_auc_score(data_test['default_payment_next_month'], predictions)\n",
        "model_f1_score = f1_score(data_test['default_payment_next_month'], pred_label)\n",
        "print('{} roc score on test: {}'.format('MLP' , roc_score))\n",
        "print('{} f1 score on test: {}'.format('MLP', model_f1_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP roc score on test: 0.515965\n",
            "MLP f1 score on test: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdi2yTB3vJeK",
        "colab_type": "text"
      },
      "source": [
        "**Light Gradient Boosting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ00Z5Kcwh80",
        "colab_type": "code",
        "outputId": "3bf4989c-fc5d-45bc-88f9-3d2088e1e673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "lgb_classifier = lgb.LGBMClassifier(n_estimator = 800, \n",
        "                                    objective = 'binary', \n",
        "                                    class_weight = 'balanced',\n",
        "                                    learning_rate = 0.05,\n",
        "                                    reg_alpha = 0.1,\n",
        "                                    reg_lambda = 0.1,\n",
        "                                    subsample = 0.8,\n",
        "                                    n_job = -1,\n",
        "                                    random_state = 12\n",
        "                                   )\n",
        "\n",
        "lgb_classifier = _train_and_test(lgb_classifier, algo = 'Light Gradient Boosting')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Light Gradient Boosting roc score on test: 0.7818150000000001\n",
            "Light Gradient Boosting f1 score on test: 0.25654450261780104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwPkKPojvVNS",
        "colab_type": "text"
      },
      "source": [
        "Ta thấy hầu hết các mô hình đều không hoạt động tốt trên dữ liệu imbalance. Một số mô hình dự báo trên tập test chỉ rơi vào 1 nhóm dẫn tới `f1` = 0 như mô hình kNN, MLP, Logistic.\n",
        "\n",
        "Tuy nhiên, mô hình `Light Gradient Boosting` lại cho kết quả dự báo khá tốt khi cải thiện được cả 2 chỉ số `auc` và `f1` so với baseline model. Thực tế tôi từng xây dựng nhiều mô hình có hiện tượng mất cân bằng dữ liệu nghiêm trọng, và kết quả cho thấy `Light Gradient Boosting` là mô hình có hiệu quả cao trong nhiều bài toán của tôi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VsTPGLC8T8g",
        "colab_type": "text"
      },
      "source": [
        "## Calibration\n",
        "\n",
        "Đường curve ở trên cho thấy đầu ra của xác suất từ mô hình Random Forest có thể được hưởng lợi từ calibration.\n",
        "\n",
        "**Làm thế nào để xác định một phương pháp calibration tốt**?\n",
        "\n",
        "Một thuật ngữ đơn giản, xác suất có thể được diễn tả như một khoảng tin cậy. Thêm vào đó, một thuật toán classifier được cho rằng đưa ra một calibrated xác suất tốt nếu các điểm dữ liệu nhận xác suất là 0.5, 50% của những điểm dữ liệu này thuộc về class positive.\n",
        "\n",
        "**Có 2 phương pháp phổ biến cho calibrate xác suất:**\n",
        "\n",
        "**1. Platt Scaling:** aka logistic calibration là cách tiếp cận tham số với hàm sigmoid map giả định rằng mỗi class sẽ phân phối chuẩn hóa. Theo nghĩa đơn giản, phương pháp này huấn luyện mô hình logistic để phù hợp với xác suất ở output và tạo ra một điều chỉnh xác suất hợp lý hơn.\n",
        "\n",
        "Ưu điểm: Làm việc tốt với tập dữ liệu nhỏ\n",
        "\n",
        "Nhược điểm: Có thể tạo ra một hiệu chỉnh xác suất nếu giả thuyết không được giữ vững.\n",
        "\n",
        "**2. Isotonic Regression:** Đây là cách tiếp cận phi tham số hướng tới biểu diễn khi nó fit tốt với các piece wise non-decrease function để dự báo xác suất đầu ra bởi một base model.\n",
        "\n",
        "Ưu điểm: Không tạo ra một giả thuyết về phân phối xác suất của input.\n",
        "\n",
        "Nhược điểm: Yêu cầu nhiều dữ liệu hơn để làm việc.\n",
        "\n",
        "Bên dưới ta sẽ sử dụng phương pháp _Platt Scaling_ để tinh chỉnh xác suất của chúng ta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMiahK3SNubP",
        "colab_type": "code",
        "outputId": "4c0885ed-940a-484b-ec12-057d17f31140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "calib_clf = CalibratedClassifierCV(rf_clf, method=\"sigmoid\", cv=\"prefit\")\n",
        "calib_clf.fit(x_valid, y_valid)\n",
        "calibrated_predictions = calib_clf.predict_proba(x_test)\n",
        "calib_roc_score = roc_auc_score(y_test, calibrated_predictions[:, 1])\n",
        "print(calib_roc_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7719709946699864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrcC9gGdPxj7",
        "colab_type": "code",
        "outputId": "293b2940-b936-41b9-bbf8-52c9fb9461f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "for outcomes, models, roc_scores in zip([rf_predictions,calibrated_predictions], \n",
        "    [\"Random Forest\", \"Calibrated Model\"],\n",
        "    [rf_roc_score, calib_roc_score]):\n",
        "    fraction_of_positives, mean_predicted_value =        calibration_curve(y_test, outcomes[:,1])\n",
        "    plt.plot(mean_predicted_value, fraction_of_positives, label=\"%s with roc - (%1.2f)\" % (models, roc_scores))\n",
        "    plt.legend()\n",
        "    plt.title(\"Reliability curve\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAGrCAYAAADkaBIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqPMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7REwNvJtuI7",
        "colab_type": "text"
      },
      "source": [
        "# Kết luận\n",
        "\n",
        "Mất cân bằng dữ liệu là hiện tượng thường xuyên xảy ra ở các bài toán phân loại. Hiện tượng này sẽ dẫn tới mô hình dự báo kém chính xác và đa phần kết quả dự báo bị thiên hẳn về một nhãn. Trong trường hợp đó, các thước đo như accuracy cũng không phải là một metric tốt để đánh giá mô hình. Qua bài viết này tôi đã trình bày với các bạn một số phương pháp chính có thể áp dụng để đối phó với các bài toán mất cân bằng mẫu. Hi vọng rằng những phương pháp kể trên sẽ mang lại hiệu quả khi tiến hành xây dựng mô hình."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBy2xBJwqltP",
        "colab_type": "text"
      },
      "source": [
        "# Tài liệu\n",
        "\n",
        "\n",
        "https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/over-sampling/plot_comparison_over_sampling\n",
        "\n",
        "https://towardsdatascience.com/probability-calibration-for-imbalanced-dataset-64af3730eaab\n",
        "\n",
        "https://www.kdnuggets.com/2016/12/best-metric-measure-accuracy-classification-models.html/2\n",
        "\n",
        "https://www.kaggle.com/residentmario/undersampling-and-oversampling-imbalanced-data\n",
        "\n",
        "https://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation\n",
        "\n",
        "https://arxiv.org/pdf/1106.1813.pdf\n",
        "\n"
      ]
    }
  ]
}