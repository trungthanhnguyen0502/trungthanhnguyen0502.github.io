{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransformerModelForCorrectDiacritic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHnDZJx06lIP",
        "colab_type": "text"
      },
      "source": [
        "# 1. Dữ liệu \n",
        "\n",
        "Ý tưởng lấy dữ liệu từ wikipedia cho Tiếng Việt được mình tham khảo từ bài viết của [Ứng dụng ML translation vào bài toán thêm dấu cho Tiếng Việt aivivn - QuangPham](https://viblo.asia/p/ung-dung-machine-translation-vao-bai-toan-them-dau-cho-tieng-viet-khong-dau-aivivn-challenge-3-3P0lP4a8lox)\n",
        "\n",
        "Đầu tiên các bạn cần tải file `viwiki-20200501-pages-articles.xml.bz2` tại [wikipedia](https://dumps.wikimedia.org/viwiki/20200501/).\n",
        "\n",
        "Chúng ta cũng có thể download file bằng lệnh wget bên dưới:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F8DO9TkMhn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "path = '/content/gdrive/My Drive/Colab Notebooks/BERT/themdau_tv'\n",
        "%cd {path}\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "713WWPB-MbVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://dumps.wikimedia.org/viwiki/20200501/viwiki-20200501-pages-articles.xml.bz2\n",
        "!bzip2 -d viwiki-20200501-pages-articles.xml.bz2\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS25bwT9R6_L",
        "colab_type": "text"
      },
      "source": [
        "Tiếp theo ta sử dụng wikiextractor để giải nén dữ liệu từ file `viwiki-20200501-pages-articles.xml.bz2` vừa mới download.\n",
        "\n",
        "Quá trình giải nén mất khá nhiều thời gian. Bạn đọc có thể download dữ liệu có sẵn tại [viwiki-20200501-pages-articles-output](https://drive.google.com/drive/folders/11mkQBCUNuKxyLZEyfGe61INU0WY-SrR0?usp=sharing). Để giải nén file chúng ta sẽ sử dụng package [wikiextractor](https://github.com/attardi/wikiextractor). Một package chuyên dùng cho khai thác dữ liệu trên wiki."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wrI29zKNb7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/attardi/wikiextractor.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgn41Y1RQ8B_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python wikiextractor/WikiExtractor.py viwiki-20200501-pages-articles.xml.bz2 --processes 4 -o ./output/ --json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4TulNB8S9hV",
        "colab_type": "text"
      },
      "source": [
        "Các bạn xem thêm cách sử dụng lệnh giải nén bằng file [WikiExtractor.py](https://github.com/attardi/wikiextractor) tại mục **Usage** của README.\n",
        "\n",
        "Câu lệnh trên sẽ giải nén file và lưu vào folder `/output/` dưới định dạng json. Mỗi file sẽ bao gồm các dòng đại diện cho một văn bản tiếng Việt được giải nén từ wikipedia có định dạng như sau:\n",
        "\n",
        "`{\"id\": \"\", \"revid\": \"\", \"url\":\"\", \"title\": \"\", \"text\": \"...\"}`\n",
        "\n",
        "Trong đó:\n",
        "\n",
        "* id: Mã của bài viết.\n",
        "* revid: Mã của bài viết.\n",
        "* url: Link url của bài viết.\n",
        "* title: Tiêu đề bài viết.\n",
        "* text: Nội dung của bài viết."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODoRvN8H1_fM",
        "colab_type": "text"
      },
      "source": [
        "Tiếp theo chúng ta sẽ duyệt qua toàn bộ các file trong folder output để thu tập dữ liệu huấn luyện từ nội dung của các bài viết. Với mỗi một bài viết ta sẽ tách nội dung thành các câu và lưu trữ vào file `train_tieng_viet.txt`. Đánh mã số cho từng câu để tiện cho việc quản lý sau này. Cấu trúc file `train_tieng_viet.txt` sẽ bao gồm 2 trường: `id sequence` sao cho id là mã index của câu và sequence là câu Tiếng Việt có dấu. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LAIodn-jCZY",
        "colab_type": "text"
      },
      "source": [
        "Trong tập hợp các câu sẽ có một số câu không đạt tiêu chuẩn vì chứa các ký tự Tiếng Trung, Hàn,.... Vì vậy chúng ta sẽ lọc bỏ những câu này bằng cách tạo ra một hàm kiểm tra tính hợp lệ của câu. Một câu được coi là hợp lệ nếu chỉ chứa các ký tự tiếng việt được list trong `accept_strings` bên dưới."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUB_CNxrjDP-",
        "colab_type": "code",
        "outputId": "6a6b7dc5-d792-4ac3-9bf7-35fd4266d6d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import string\n",
        "import re\n",
        "# https://realpython.com/python-encodings-guide/\n",
        "# List các ký tự hợp lệ trong tiếng Việt\n",
        "intab_l = \"ạảãàáâậầấẩẫăắằặẳẵóòọõỏôộổỗồốơờớợởỡéèẻẹẽêếềệểễúùụủũưựữửừứíìịỉĩýỳỷỵỹđ\"\n",
        "ascii_lowercase = 'abcdefghijklmnopqrstuvwxyz'\n",
        "digits = '0123456789'\n",
        "punctuation = r\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"\n",
        "whitespace = ' '\n",
        "accept_strings =  intab_l + ascii_lowercase + digits + punctuation + whitespace\n",
        "r = re.compile('^[' + accept_strings + ']+$')\n",
        "# Một câu sẽ được coi là hợp lệ nếu có các ký tự nằm trong accept_strings\n",
        "def _check_tieng_viet(seq):\n",
        "  if re.match(r, seq.lower()):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "_check_tieng_viet('tiếng việt là ngôn ngữ của tôi')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqlfLzJG3qQu",
        "colab_type": "text"
      },
      "source": [
        "Tiếp theo ta sẽ tạo vòng lặp đi qua toàn bộ các file trong `/output` folder. Kiểm tra câu có thỏa mãn tiêu chuẩn Tiếng Việt không, đánh index cho câu và lưu đồng thời index và câu có dấu vào file `train_tieng_viet.txt`. Thời gian trích suất sẽ mất vài tiếng trên máy của mình. Vì vậy các bạn có thể download dữ liệu tại [train_tieng_viet.txt](https://drive.google.com/file/d/1-7lERkqCoID1691yCXLAOyZoJqYPqhGq/view?usp=sharing) và bỏ qua đoạn code bên dưới."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nROGDheUOgW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import glob2\n",
        "idx = 0\n",
        "\n",
        "for path in tqdm(glob2.glob('output/*/*')):\n",
        "  # Đọc nội dung của các văn bản từ folder output. Content sẽ chứa nhiều row, mỗi row là một json data\n",
        "  with open(path, 'r', encoding='utf8') as f:\n",
        "    content = f.readlines()\n",
        "    for row in content:\n",
        "      # Convert row sang json\n",
        "      art_json = json.loads(row)\n",
        "      # Lấy nội dung văn bản\n",
        "      art_cont = art_json['text']\n",
        "      art_cont = re.sub(\"(\\s)+\", r\"\\1\", art_cont)\n",
        "      # Chia văn bản thành các câu tại vị trí xuống dòng\n",
        "      art_seqs = art_cont.split(\"\\n\")\n",
        "      # Lưu các dòng là tiếng việt vào file 'train_tieng_viet.txt'.\n",
        "      # Mỗi dòng có định dạng: index{10digits} sequence\n",
        "      for seq in art_seqs:\n",
        "        if _check_tieng_viet(seq):\n",
        "          idx_str = str(idx).zfill(10)\n",
        "          with open('train_tieng_viet.txt', 'a') as f:\n",
        "            f.writelines([idx_str+'\\t', seq+'\\n'])\n",
        "          idx += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_RikA4Z4b9v",
        "colab_type": "text"
      },
      "source": [
        "Tiếp theo chúng ta sẽ load dữ liệu từ file `train_tieng_viet.txt`, loại bỏ dấu ở từng câu để tạo dữ liệu input. Dữ liệu output sẽ chính là câu Tiếng Việt có dấu.\n",
        "\n",
        "**Đọc file train_tieng_viet.txt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q95GhQnP48BO",
        "colab_type": "code",
        "outputId": "89720e2f-58e9-459d-a306-e6c43bcf4fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "with open('train_tieng_viet.txt', 'r', encoding='utf-8') as f:\n",
        "  train_output = f.readlines()\n",
        "\n",
        "print('Number of sequences: ', len(train_output))\n",
        "print('First sequence: ', train_output[0])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences:  3624432\n",
            "First sequence:  0000000000\tTrang Chính\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOR474bX6Nz5",
        "colab_type": "text"
      },
      "source": [
        "Ta thấy tổng số câu của chúng ta lên tới 3.6 triệu câu. Đối với cấu hình máy của google colab thì đay có thể coi là một lượng dữ liệu siêu to khổng lồ. Do đó mình sẽ chỉ lọc ra 100 nghìn câu đầu tiên làm tập huấn luyện (train dataset), 50 nghìn câu tiếp theo làm tập thẩm định (validation dataset) và 50 nghìn câu tiếp theo làm tập kiểm tra (test dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZlLAQdTitMe",
        "colab_type": "text"
      },
      "source": [
        "**Tạo cặp dữ liệu input-output**\n",
        "\n",
        "Mục tiêu mô hình là từ câu không dấu dự báo câu có dấu gốc tương ứng. Chúng ta đã có sẵn câu có dấu. Do đó việc tiếp theo là tạo câu không dấu. Hàm `remove_tone_line()` sẽ giúp bạn thực hiện điều này. Đây là hàm tiện ích được lấy từ cuộc thi thêm từ không dấu Tiếng Việt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCNgttL0S2P5",
        "colab_type": "code",
        "outputId": "fa560b72-5d12-4913-f3b4-bd8995ee4167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# encoding=utf8\n",
        "import codecs\n",
        "import csv\n",
        "import re\n",
        "import sys\n",
        "\n",
        "def remove_tone_line(utf8_str):\n",
        "    intab_l = \"ạảãàáâậầấẩẫăắằặẳẵóòọõỏôộổỗồốơờớợởỡéèẻẹẽêếềệểễúùụủũưựữửừứíìịỉĩýỳỷỵỹđ\"\n",
        "    intab_u = \"ẠẢÃÀÁÂẬẦẤẨẪĂẮẰẶẲẴÓÒỌÕỎÔỘỔỖỒỐƠỜỚỢỞỠÉÈẺẸẼÊẾỀỆỂỄÚÙỤỦŨƯỰỮỬỪỨÍÌỊỈĨÝỲỶỴỸĐ\"\n",
        "    intab = list(intab_l+intab_u)\n",
        "\n",
        "    outtab_l = \"a\"*17 + \"o\"*17 + \"e\"*11 + \"u\"*11 + \"i\"*5 + \"y\"*5 + \"d\"\n",
        "    outtab_u = \"A\"*17 + \"O\"*17 + \"E\"*11 + \"U\"*11 + \"I\"*5 + \"Y\"*5 + \"D\"\n",
        "    outtab = outtab_l + outtab_u\n",
        "    # Khởi tạo regex tìm kiếm các vị trí nguyên âm có dấu 'ạ|ả|ã|...'\n",
        "    r = re.compile(\"|\".join(intab))\n",
        "\n",
        "    # Dictionary có key-value là từ có dấu-từ không dấu. VD: {'â' : 'a'}\n",
        "    replaces_dict = dict(zip(intab, outtab))\n",
        "    # Thay thế các từ có dấu xuất hiện trong tìm kiếm của regex bằng từ không dấu tương ứng\n",
        "    non_dia_str = r.sub(lambda m: replaces_dict[m.group(0)], utf8_str)\n",
        "    return non_dia_str\n",
        "  \n",
        "remove_tone_line('Đi một ngày đàng học 1 sàng khôn')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Di mot ngay dang hoc 1 sang khon'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBzb0B44esj6",
        "colab_type": "code",
        "outputId": "c022ffb6-ef9b-437b-9183-b3b7c569284d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "train_idx_500k = []\n",
        "train_opt_500k = []\n",
        "train_ipt_500k = []\n",
        "val_idx_50k = []\n",
        "val_opt_50k = []\n",
        "val_ipt_50k = []\n",
        "test_idx_50k = []\n",
        "test_opt_50k = []\n",
        "test_ipt_50k = []\n",
        "\n",
        "for i in tqdm(range(600000)):\n",
        "  [idx, origin_seq] = train_output[i].split('\\t')\n",
        "  try:\n",
        "    non_acc_seq = remove_tone_line(origin_seq)\n",
        "  except:\n",
        "    print('error remove tone line at sequence {}', str(i))\n",
        "    next\n",
        "  if i < 500000:\n",
        "    train_idx_500k.append(idx)\n",
        "    train_opt_500k.append(origin_seq)\n",
        "    train_ipt_500k.append(non_acc_seq)\n",
        "  elif i < 550000:\n",
        "    val_idx_50k.append(idx)\n",
        "    val_opt_50k.append(origin_seq)\n",
        "    val_ipt_50k.append(non_acc_seq)\n",
        "  else:\n",
        "    test_idx_50k.append(idx)\n",
        "    test_opt_50k.append(origin_seq)\n",
        "    test_ipt_50k.append(non_acc_seq)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 600000/600000 [00:31<00:00, 19184.82it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1gyxMatgTdp",
        "colab_type": "code",
        "outputId": "eae0a740-37ef-4394-b8af-daa6b944db16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(train_ipt_500k[10])\n",
        "print(train_opt_500k[10])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tieng Viet la ngon ngu co nguon goc ban dia, xuat than tu nen van minh nong nghiep, tai noi ma ngay nay la khu vuc phia bac luu vuc song Hong va song Ma cua Viet Nam.\n",
            "\n",
            "Tiếng Việt là ngôn ngữ có nguồn gốc bản địa, xuất thân từ nền văn minh nông nghiệp, tại nơi mà ngày nay là khu vực phía bắc lưu vực sông Hồng và sông Mã của Việt Nam.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh9zOJ_sJMCZ",
        "colab_type": "text"
      },
      "source": [
        "Sau khi đã có dữ liệu huấn luyện, thẩm định và kiểm tra. Chúng ta nên lưu lại để tái sử dụng cho những lượt cải thiện mô hình sau. Nếu bạn không lưu lại dữ liệu, bạn sẽ không có căn cứ để đánh giá và so sánh giữa các mô hình. Để không tốn dung lượng thì mình chỉ lưu lại index. Từ index có thể truy suất ra câu cần lấy. Mình sử dụng google drive nên tài nguyên chỉ có 15GB thôi. Đó là lý do tại sao mình đánh index để tiết kiệm tài nguyên."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUzyXVZua6v2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "def _save_pickle(filename, obj):\n",
        "  with open(filename, 'wb') as f:\n",
        "    pickle.dump(obj, f)\n",
        "\n",
        "_save_pickle('train_tv_idx_500k.pkl', train_idx_500k)\n",
        "_save_pickle('val_tv_idx_50k.pkl', val_idx_50k)\n",
        "_save_pickle('test_tv_idx_50k.pkl', test_idx_50k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07JYJGiiLyzy",
        "colab_type": "text"
      },
      "source": [
        "# 2. Xây dựng model Transformer\n",
        "\n",
        "Hướng dẫn này sẽ huấn luyện model transformer để tiến hành dịch câu Tiếng Việt không dấu sang có dấu. Mã nguồn tham khảo tại [Transformer model for language understanding](https://www.tensorflow.org/tutorials/text/transformer) ứng dụng trên thuật toán dịch máy. Có rất nhiều mã nguồn khác nhau về transformer. Nhưng mình chọn mã nguồn này là bởi tác giả giải thích các step rất chi tiết, dễ hiểu ở từng bước xử lý khác nhau. Bạn đọc sẽ hiểu được các bước xử lý trong transformer gồm những gì thông qua bài viết này. Trước khi bắt tay vào xây dựng mô hình, tôi khuyên bạn đọc qua trước [Bài 4 - Attention is all you need](https://phamdinhkhanh.github.io/2019/06/18/AttentionLayer.html) để hiểu về kiến trúc transformer và bài [Bài 36 - BERT model](https://phamdinhkhanh.github.io/2020/05/23/BERTModel.html) mô hình BERT áp dụng kiến trúc transformer trong các tác vụ NLP.\n",
        "\n",
        "Điểm cải tiến của transformer so với RNN đó là kỹ thuật attention giúp cho học được từ toàn bộ các vị trí khác nhau trong câu input để tính toán ra biểu diễn output của câu. transformer tạo ra một chuỗi stack các block sub-layer và áp dụng các biến đổi `Scale dot Product attention` và `Multi-head attention` sẽ được giải thích ở bên dưới.\n",
        "\n",
        "Một mô hình transformer sẽ kiểm soát kích thước biến của input sử dụng stacks của các self-attention layers thay vì RNNs, CNNs. Kiến trúc tổng quát này có những điểm lợi thế sau:\n",
        "\n",
        "* Không phụ thuộc vào giả thiết quan hệ thời gian trong toàn bộ dữ liệu.\n",
        "\n",
        "* Output có thể được tính toán song song thay vì theo chuỗi như RNN.\n",
        "\n",
        "* Các từ ở xa có thể ảnh hưởng tới những output của những từ khác mà không truyền qua nhiều RNN steps.\n",
        "\n",
        "* Nó có thể học được sự phụ thuộc dài hạn. Sự phụ thuộc dài hạn là một thách thức của rất nhiều các tác vụ seq2seq.\n",
        "\n",
        "Hạn chế của transformer:\n",
        "\n",
        "* Output của tranformer được tính toán từ toàn bộ lịch sử thay vì chỉ input và hidden-state hiên tại. Đây có thể là một nhược điểm vì khoảng cách xa có thể không liên quan.\n",
        "\n",
        "* Input không có sự phụ thuộc thời gian, do đó position encoding cần được thêm vào để mã hóa sự tương quan về mặt thời gian.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKvVYh3LL2aN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m3ai1fxtGDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_examples = tf.data.Dataset.from_tensor_slices((train_ipt_100k, train_opt_100k))\n",
        "train_examples = tf.data.Dataset.from_tensor_slices((train_ipt_500k, train_opt_500k))\n",
        "val_examples = tf.data.Dataset.from_tensor_slices((val_ipt_50k, val_opt_50k))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMiZnryIL-sH",
        "colab_type": "text"
      },
      "source": [
        "Khởi tạo tokenize cho tập train input và output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OPH42XjL8Ux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_ipt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (ipt.numpy() for (ipt, opt) in train_examples), target_vocab_size=2**13)\n",
        "\n",
        "tokenizer_opt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (opt.numpy() for (ipt, opt) in train_examples), target_vocab_size=2**13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I28hgxdNQGND",
        "colab_type": "code",
        "outputId": "9a16a59d-3742-49fd-d100-811892ac8f3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sample_string = 'Tiếng Việt là ngôn ngữ trong sáng nhất thế giới'\n",
        "\n",
        "tokenized_string = tokenizer_opt.encode(sample_string)\n",
        "print ('Tokenized string is {}'.format(tokenized_string))\n",
        "\n",
        "original_string = tokenizer_opt.decode(tokenized_string)\n",
        "print ('The original string: {}'.format(original_string))\n",
        "\n",
        "assert original_string == sample_string"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized string is [2270, 65, 5, 695, 527, 10, 451, 60, 56, 573]\n",
            "The original string: Tiếng Việt là ngôn ngữ trong sáng nhất thế giới\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plvxAXN8Jp0y",
        "colab_type": "text"
      },
      "source": [
        "Lưu lại Tokenizer và kích thước vocabulary size của nó:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hRKkDI2Jr-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "def _save_pickle(path, obj):\n",
        "  with open(path, 'wb') as f:\n",
        "    pickle.dump(obj, f)\n",
        "\n",
        "def _load_pickle(path):\n",
        "  with open(path, 'rb') as f:\n",
        "    obj = pickle.load(f)\n",
        "  return obj\n",
        "\n",
        "_save_pickle('tokenizer/tokenizer_ipt.pkl', tokenizer_ipt)\n",
        "_save_pickle('tokenizer/tokenizer_opt.pkl', tokenizer_opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ber3d-ZMU__2",
        "colab_type": "text"
      },
      "source": [
        "Tokenizer sẽ encoding chuỗi string bằng cách chi nhỏ nó thành những subwords nếu từ không xuất hiện trong từ điển của nó.\n",
        "\n",
        "**Khái niệm subwords**: Thuật toán transfomer sẽ hiệu quả hơn nếu ta chia các từ theo subwords. subword là một chuỗi các ký tự xuất hiện trong token mà thường được lặp đi lặp lại. Chẳng hạn như từ `chính tả` thì cụm ký tự như `ính` sẽ dễ dàng được sử dụng lặp lại ở những từ khác. Do đó nó có thể là một subword. Bạn đọc có thể tham khảo thêm về subwords tại [How subword helps on your nlp model](https://medium.com/@makcedward/how-subword-helps-on-your-nlp-model-83dd1b836f46)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV4ZhgV4Uu_h",
        "colab_type": "code",
        "outputId": "2449dfa5-51a0-4838-c765-60aa437fdc9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for ts in tokenized_string:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer_opt.decode([ts])))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2270 ----> Tiếng \n",
            "65 ----> Việt \n",
            "5 ----> là \n",
            "695 ----> ngôn \n",
            "527 ----> ngữ \n",
            "10 ----> trong \n",
            "451 ----> sáng \n",
            "60 ----> nhất \n",
            "56 ----> thế \n",
            "573 ----> giới\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqh4oxn_U1B2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpexkCiTVS1j",
        "colab_type": "text"
      },
      "source": [
        "Tiếp theo chúng ta sẽ thêm token `start` và `end` vào câu input và câu target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFbSgjE9VQkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(ipt, opt):\n",
        "  ipt = [tokenizer_ipt.vocab_size] + tokenizer_ipt.encode(\n",
        "      ipt.numpy()) + [tokenizer_ipt.vocab_size+1]\n",
        "\n",
        "  opt = [tokenizer_opt.vocab_size] + tokenizer_opt.encode(\n",
        "      opt.numpy()) + [tokenizer_opt.vocab_size+1]\n",
        "  \n",
        "  return ipt, opt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "recZkkk2vfxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode(ipt = 'tieng viet la ngon ngu trong sang', opt = 'tiếng việt là ngôn ngữ trong sáng')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK_8fBKyXjwi",
        "colab_type": "text"
      },
      "source": [
        "Nếu bạn muốn sử dụng `Dataset.map` để áp dụng hàm số này cho mỗi phần tử của dataset. `Dataset.map` sẽ chạy trên graph mode.\n",
        "\n",
        "* Graph tensors không có dữ liệu.\n",
        "* Trong graph model bạn chỉ có thể sử dụng Tensorflow Ops và functions.\n",
        "\n",
        "Do đó bạn không thể `.map` các hàm số này trực tiếp: Bạn cần wrap nó trong một hàm số gọi là `tf.py_function`. Hàm số này sẽ truyền các tensors thông thường (với một giá trị và một phương thức `.numpy()` để truy cập nó), để wrapped hàm số trong python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyh8cyhjXf1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_encode(ipt, opt):\n",
        "  result_ipt, result_opt = tf.py_function(encode, [ipt, opt], [tf.int64, tf.int64])\n",
        "  result_ipt.set_shape([None])\n",
        "  result_opt.set_shape([None])\n",
        "  return result_ipt, result_opt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRKP3pZCWxp0",
        "colab_type": "text"
      },
      "source": [
        "Note: Để dữ cho bộ dữ liệu nhỏ và huấn luyện nhanh hơn, chúng ta sẽ loại bỏ những mẫu kích thước lớn hơn 40 tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kJ7Sf0XZyqA",
        "colab_type": "text"
      },
      "source": [
        "Khởi tạo tensorflow Dataset cho train và validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i4xVuipysG_",
        "colab_type": "code",
        "outputId": "f0e5cbff-4c6c-43b5-b624-a0d2b6db1165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "next(iter(train_examples))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=string, numpy=b'Trang Chinh\\n'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'Trang Ch\\xc3\\xadnh\\n'>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC081xq8XHE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 40\n",
        "\n",
        "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
        "  return tf.logical_and(tf.size(x) <= max_length,\n",
        "                        tf.size(y) <= max_length)\n",
        "  \n",
        "train_dataset = train_examples.map(tf_encode)\n",
        "train_dataset = train_dataset.filter(filter_max_length)\n",
        "# cache the dataset to memory to get a speedup while reading from it.\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "val_dataset = val_examples.map(tf_encode)\n",
        "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xP5f6FCtzUg",
        "colab_type": "code",
        "outputId": "342dee2e-6c18-4ace-9dd1-eddec3a0e469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print('tokenizer_ipt.vocab_size: ', tokenizer_ipt.vocab_size)\n",
        "x, y = next(iter(train_dataset))\n",
        "print('input shape: ', x.shape)\n",
        "print('output shape: ', y.shape)\n",
        "print('first row of input index: ', x[0, :])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenizer_ipt.vocab_size:  8185\n",
            "input shape:  (64, 37)\n",
            "output shape:  (64, 40)\n",
            "first row of input index:  tf.Tensor(\n",
            "[8185 7759 7961 1302 7939 8186    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0], shape=(37,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JUKtVUet09T",
        "colab_type": "text"
      },
      "source": [
        "# 3. Position Encoding\n",
        "\n",
        "\n",
        "**Chức năng của position Encoding**: Tranformer sẽ không dự báo tuân theo time step như RNN. Toàn bộ các input sẽ được truyền vào mô hình **cùng một thời điểm**. Sẽ rất khó để nhận viết vị trí của các từ input trong câu ở những lớp mô hình không tuân theo time step. Do đó thêm position encoding sẽ cho mô hình thêm các thông tin về vị trí của từ.\n",
        "\n",
        "Position encoding véc tơ sẽ được cộng trực tiếp vào embedding véc tơ. Embeddings biểu diễn một token trong một không gian d chiều nơi mà các token có cùng ý nghĩa sẽ gần nhau hơn. Nhưng embedding vector không chứa thông tin vị trí của từ trong câu. Do đó sau khi thêm position encoding véc tơ, một từ sẽ gần với những từ khác hơn dựa trên ý nghĩa của chúng và khoảng cách vị trí của chúng trong câu trong không gian `d` chiều.\n",
        "\n",
        "Theo dõi note book về [position encoding](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) để hiểu rõ hơn về chức năng và tính chất của nó.\n",
        "\n",
        "**Công thức position Encoding:**\n",
        "\n",
        "$$PE(pos, 2i) = sin(\\frac{pos}{10000^\\frac{2i}{d_{model}}})$$\n",
        "\n",
        "$$PE(pos, 2i+1) = cos(\\frac{pos}{10000^\\frac{2i}{d_{model}}})$$\n",
        "\n",
        "Trong đó $pos$ là vị trí hiện tại của từ, $i$ chỉ số của phần tử nằm trong véc tơ encoding và $d_{model}$ là kích thước các véc tơ positional embedding.\n",
        "\n",
        "Gỉa sử $PE(pos)$ là véc tơ encoding tại vị trí `pos`. Véc tơ này có kích thước phải bằng với các véc tơ embedding từ để phép cộng thực hiện được và kích thước đó bằng $d_{model}$.\n",
        "\n",
        "Công thức $PE(pos, 2i), PE(pos, 2i+1)$ tính giá trị các phần tử véc tơ positional encoding tại lần lượt vị trí $2i$ và $2i+1$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbI_bQKvt2xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVO3kt_Tt4eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model) # shape (position, d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32) # shape: (position, d_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Voqn6K3zRdmN",
        "colab_type": "text"
      },
      "source": [
        "Hàm `positional_encoding()` sẽ tạo ra ma trận mà gồm các véc tơ dòng là những `positional encoding` véc tơ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M0ivjeQt8ML",
        "colab_type": "code",
        "outputId": "6df13bd2-4ac9-40a5-c29e-3bfb2c3310f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "pos_encoding = positional_encoding(50, 512)\n",
        "print (pos_encoding.shape)\n",
        "\n",
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 50, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XtPYN9qt9vH",
        "colab_type": "text"
      },
      "source": [
        "# 4. Masking\n",
        "\n",
        "Masking nhằm mục đích không đưa các vị trí padding trong câu vào như một input. Mask là ma trận có kích thước bằng với kích thước ma trận input và đánh dấu các vị trị padding (tương ứng với 0) bằng giá trị 1. Các giá trị còn lại bằng 0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD7GGn6muKUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq0BVOrguMWh",
        "colab_type": "code",
        "outputId": "5ad4129d-dfdd-4221-83f3-7d1b0800a251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
        "create_padding_mask(x)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 1., 1., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAOC_8CtLK4Y",
        "colab_type": "text"
      },
      "source": [
        "Tiếp theo để ngăn cản ảnh hưởng của các từ tương lai vào dự đoán từ hiện tại. Chúng ta sẽ tiếp tục mask các vị trí tương lai bằng 1.\n",
        "\n",
        "Như vậy tại vị trí cần dự báo từ thứ 3 thì chỉ từ thứ 1 và thứ 2 được đưa vào dự báo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esft047_uPAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zN8JQ9FuRAQ",
        "colab_type": "code",
        "outputId": "55d22731-aed1-4961-f852-16bf503594e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "x = tf.random.uniform((1, 3))\n",
        "temp = create_look_ahead_mask(x.shape[1])\n",
        "temp"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[0., 1., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVC5JQI-uS59",
        "colab_type": "text"
      },
      "source": [
        "# 5. Scale dot Product attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSN5nz86L7ZF",
        "colab_type": "text"
      },
      "source": [
        "Một attention sẽ sử dụng input là 3 ma trận: $\\mathbf{Q}$ (query), $\\mathbf{K}$ (key) và $\\mathbf{V}$ (value). Theo sơ đồ như sau:\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
        "\n",
        "Output thu được là ma trận attention của các từ lẫn nhau trong câu.\n",
        "\n",
        "Diễn giải quá trình tính attention như sau:\n",
        "\n",
        "* Sau khi thực hiện `MatMul` giữa $\\mathbf{Q}$ và $\\mathbf{K}$ --> thu được ma trận attention.\n",
        "\n",
        "* Scale ma trận attention với nghịch đảo số độ sâu (chính là kích thước véc tơ dòng) của ma trận $\\mathbf{K}$ là $\\frac{1}{\\mathbf{\\sqrt{d_k}}}$ để tránh cho giá trị phần tử của ma trận attention quá lớn trong khi gradient thì quá nhỏ --> huấn luyện lâu.\n",
        "\n",
        "* Thực hiện Masking. Ma trận mask là ma trận để ngăn cho những vị trí padding tham gia vào quá trình attention. Ma trận masking được nhân với -1E9 (là một giá trị gần với âm vô cùng). Sở dĩ ta thực hiện như vậy vì sau đó ma trận attention sẽ cộng với ma trận mask. Tại những vị trí padding sẽ có giá trị gần như âm vô cùng và khi tính phân phối softmax theo dòng sẽ thu được output là 0. Một lát nữa chúng ta sẽ thực nghiệm điều này.\n",
        "\n",
        "* Sau khi tính phân phối softmax cho ma trận attention, chúng ta sẽ nhân ma trận attention với ma trận $\\mathbf{V}$.\n",
        "\n",
        "Toàn bộ quá trình phức tạp trên được tổng hợp trong công thức Attention:\n",
        "\n",
        "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqVlRGCmuW0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32) # depth\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QmQkMqP702p",
        "colab_type": "text"
      },
      "source": [
        "Mask sẽ ngăn cản các vị trí được padding. Bên dưới ta sẽ thực nghiệm quá trình masking và xem hệ số attention sau khi đi qua phân phối softmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RGs7-YN2_42",
        "colab_type": "code",
        "outputId": "4ff5ed60-6ebc-41bc-b13a-1772f056e737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# with tf.Session() as sess:\n",
        "mask = tf.constant([[0, 1, 1],\n",
        "                    [0, 0, 1],\n",
        "                    [0, 0, 0]], dtype = tf.float64)\n",
        "\n",
        "scaled_attention_logit = tf.constant([[1, 3, 10],\n",
        "                [1, 2, 5],\n",
        "                [1, 1, 5]], dtype = tf.float64)\n",
        "\n",
        "scaled_attention_logit += (mask * -1e9)\n",
        "attention_weights = tf.nn.softmax(scaled_attention_logit, axis=-1)\n",
        "print('scaled_attention_logit: ', scaled_attention_logit)\n",
        "print('attention_weights: ', attention_weights)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scaled_attention_logit:  tf.Tensor(\n",
            "[[ 1.00000000e+00 -9.99999997e+08 -9.99999990e+08]\n",
            " [ 1.00000000e+00  2.00000000e+00 -9.99999995e+08]\n",
            " [ 1.00000000e+00  1.00000000e+00  5.00000000e+00]], shape=(3, 3), dtype=float64)\n",
            "attention_weights:  tf.Tensor(\n",
            "[[1.         0.         0.        ]\n",
            " [0.26894142 0.73105858 0.        ]\n",
            " [0.01766842 0.01766842 0.96466316]], shape=(3, 3), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQNzEhxdAsBu",
        "colab_type": "text"
      },
      "source": [
        "Ta có thể thấy tại các vị trí padding được mask với giá trị bằng 1 thì attention_weights bằng 0.\n",
        "\n",
        "Kết quả sau cùng sẽ thu được là tích giữa ma trận attention_weights với ma trận $\\mathbf{V}$. Kết quả này sẽ đảm bảo:\n",
        "\n",
        "* Phân bố attention giữa các véc tơ trong $\\mathbf{V}$\n",
        "* Loại bỏ những từ không liên quan ra khỏi attention.\n",
        "\n",
        "Tiếp theo ta sẽ test hàm `scaled_dot_product_attention()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AH_lT2FuZXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print ('Attention weights are:')\n",
        "  print (temp_attn)\n",
        "  print ('Output is:')\n",
        "  print (temp_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3vT17K9uchz",
        "colab_type": "code",
        "outputId": "5de1357b-a4b7-4663-b481-34dce795efe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "temp_k = tf.constant([[10,0,0],\n",
        "                      [0,10,0],\n",
        "                      [0,0,10],\n",
        "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
        "\n",
        "temp_v = tf.constant([[   1,0],\n",
        "                      [  10,0],\n",
        "                      [ 100,5],\n",
        "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
        "\n",
        "# This `query` aligns with the second `key`,\n",
        "# so the second `value` is returned.\n",
        "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD_kwWBBZUO_",
        "colab_type": "text"
      },
      "source": [
        "Véc tơ attention là [0, 1, 0, 0] chỉ tập trung vào vị trí thứ 2. Do đó kết quả trả về là dòng thứ 2 của ma trận $\\mathbf{V}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEkyXBwfupMg",
        "colab_type": "text"
      },
      "source": [
        "# 6. Multi-head Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3o-36EwZkM9",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n",
        "\n",
        "\n",
        "Multi-head attention sẽ bao gồm 4 phần:\n",
        "\n",
        "* Các linear layers và phân chi thành các nhiều heads.\n",
        "* Scaled dot-product attention\n",
        "* Concatenate các heads\n",
        "* Linear layer cuối cùng."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19mrDxXBasQ2",
        "colab_type": "text"
      },
      "source": [
        "Mỗi một multi-head attention block nhận 3 đầu vào: là các ma trận $\\mathbf{Q}$, $\\mathbf{K}$, $\\mathbf{V}$. Sau đó `scale_dot_product_attention()` sẽ được sử dụng để tính toán trên từng head. Attention output của mỗi layer sau đó được concatenate và truyền qua một Dens layer.\n",
        "\n",
        "Thay vì sử dụng một single head attention, chúng ta sử dụng nhiều multi-head attention là để mô hình có thể học được attention từ các vị trí trên những biểu diễn không gian khác nhau."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_AwaSTNFcny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    \n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLRbInlMFmJe",
        "colab_type": "code",
        "outputId": "95648a36-3a19-48fc-cf24-c97a577d531a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSYmqvMQaj3v",
        "colab_type": "text"
      },
      "source": [
        "Như vậy shape của attention sẽ là `(batch_size, num_head, seq_len_q, seq_len_k)` và shape của output  sẽ là `(batch_size, seq_len_q, d_model)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J47Rx-86FoR2",
        "colab_type": "text"
      },
      "source": [
        "# 7. Point wise feed forward network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdzrfEPCc76a",
        "colab_type": "text"
      },
      "source": [
        "Point wise feed forward bao gồm 2 fully-connected layers với hàm ReLU activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "870jgMeTFsJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83P5BnbCteGz",
        "colab_type": "text"
      },
      "source": [
        "# 8. Encoder and Decoder\n",
        "\n",
        "\n",
        "Toàn bộ kiến trúc của transformer sẽ bao gồm 2 nhánh Encoder và Decoder như bên dưới:\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">\n",
        "\n",
        "* Câu input sẽ được embedding và truyền qua $N$ sub-layers block của encoder để sinh ra output cho mỗi từ trong câu.\n",
        "\n",
        "* Decoder áp dụng encoder-decoder attention giữa output của encoder và input của decoder để dự báo next word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hhfm3heOHmC7",
        "colab_type": "text"
      },
      "source": [
        "## 8.1. Encoder layer\n",
        "\n",
        "Mỗi một Encoder layer sẽ gồm 2 sublayers:\n",
        "\n",
        "* Multi-head Attention (với padding mask)\n",
        "* Point wise feed forward network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA8wQkWcHUjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S91bVVYBHdWq",
        "colab_type": "code",
        "outputId": "5ac22a5e-1b45-4b2f-cabc-5fdbe81b8c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 43, 512)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 43, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZCWNUqNehSj",
        "colab_type": "text"
      },
      "source": [
        "Nếu bạn chạy ra shape của output Encoder là `(batch_size, input_seq_length, d_model)` là đúng."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC3WwW7IHhu0",
        "colab_type": "text"
      },
      "source": [
        "## 8.2. Decoder layer\n",
        "\n",
        "Mỗi một layer của Decoder layer sẽ bao gồm 3 sublayers:\n",
        "\n",
        "* Masked multi-head attention (với look ahead mask và padding mask).\n",
        "* Multi-head attention (với padding mask). Ma trận $\\mathbf{V}$, $\\mathbf{K}$ cùng lấy output từ Encoder và ma trận $\\mathbf{Q}$ nhận output từ _masked multi-head attention_.\n",
        "* Point wise feed forward network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2MSdz2KHe3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6lVI5ADHtDT",
        "colab_type": "code",
        "outputId": "6e7f3460-22c9-42cb-f060-edc4da79b537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
        "    False, None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sXQYgengStV",
        "colab_type": "text"
      },
      "source": [
        "Output shape của Decoder sẽ là `(batch_size, target_seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7TwwsI1HyAE",
        "colab_type": "text"
      },
      "source": [
        "## 8.3. Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_7eNpkBgiLQ",
        "colab_type": "text"
      },
      "source": [
        "Toàn bộ Encoder sẽ bao gồm:\n",
        "\n",
        "* Input Embedding\n",
        "* Positional Encoding\n",
        "* N encoder layers\n",
        "\n",
        "Input sau khi được Embedding sẽ được cộng với Positional Encoding. Kết quả tổng thu được tiếp tục được truyền qua N encoder layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxfBddGyHvd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                            self.d_model)\n",
        "    \n",
        "    \n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxLYoNKCH4JP",
        "colab_type": "code",
        "outputId": "80212069-33c9-4549-fa3f-f780dc9c02b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
        "                         dff=2048, input_vocab_size=8500,\n",
        "                         maximum_position_encoding=10000)\n",
        "\n",
        "# Init sample tensorflow with shape 64 x 62 and data type int.\n",
        "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
        "\n",
        "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 62, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MErTEan7Hzm0",
        "colab_type": "text"
      },
      "source": [
        "## 8.4. Decoder\n",
        "\n",
        "Decoder sẽ bao gồm:\n",
        "\n",
        "* Output Embedding\n",
        "* Positional Embedding\n",
        "* N encoder layers\n",
        "\n",
        "Giá trị target được truyền qua Output Embedding và cộng với Positional Encoding. Tổng sau đó tiếp tục được truyền qua N encoder layers (Đã tính attention với output của Encoder). Output của decoder là input của linear layer cuối cùng.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMQcUNWeH08k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    \n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    \n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "      \n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-lQpvB3H8pG",
        "colab_type": "code",
        "outputId": "cd5e8162-3d84-4a10-968d-a2ca85085ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
        "                         dff=2048, target_vocab_size=8000,\n",
        "                         maximum_position_encoding=5000)\n",
        "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output, attn = sample_decoder(temp_input, \n",
        "                              enc_output=sample_encoder_output, \n",
        "                              training=False,\n",
        "                              look_ahead_mask=None, \n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSS_00COH-6l",
        "colab_type": "text"
      },
      "source": [
        "# 9. Create transformer\n",
        "\n",
        "MÔ hình transformer sẽ hình thành từ Encoder, Decoder và linear layer cuối cùng. Kết quả sau cùng là output của linear layer cuối cùng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd69LFkdIBKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "    # print('enc_padding_mask: ', enc_padding_mask)\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    \n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    \n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return final_output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFfUxxvHIGqe",
        "colab_type": "code",
        "outputId": "f3bdeefe-a60f-4306-8f5f-f983239fc393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_transformer = Transformer(\n",
        "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
        "    input_vocab_size=8500, target_vocab_size=8000, \n",
        "    pe_input=10000, pe_target=6000)\n",
        "\n",
        "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
        "                               enc_padding_mask=None, \n",
        "                               look_ahead_mask=None,\n",
        "                               dec_padding_mask=None)\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 36, 8000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwlz7OafIJX-",
        "colab_type": "text"
      },
      "source": [
        "# 10. Set hyperparameters\n",
        "\n",
        "Chúng ta sẽ cần thiết lập các tham số cho mô hình bao gồm:\n",
        "\n",
        "1. Các tham số kiến trúc mô hình:\n",
        "\n",
        "* num_layers: Số lượng Attention sub-layer blocks của encoder và decoder.\n",
        "* d_model: Kích thước của véc tơ embedding.\n",
        "* num_heads: Số lượng các head trong một attention layer.\n",
        "* dff: Số lượng token tối đa cho phép của văn bản đầu vào.\n",
        "\n",
        "2. Các tham số huấn luyện:\n",
        "\n",
        "* dropout_rate: Tỷ lệ drop out ở output.\n",
        "* input_vocab_size: Số lượng từ vựng của input.\n",
        "* target_vocab_size: Số lượng từ vựng của target.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzQwkCnrIKLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = tokenizer_ipt.vocab_size + 2\n",
        "target_vocab_size = tokenizer_opt.vocab_size + 2\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGXnDPd6P3I2",
        "colab_type": "code",
        "outputId": "9c46f93a-ec8e-4a06-ea9f-165b7d92782d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('input_vocab_size: ',  input_vocab_size)\n",
        "print('target_vocab_size: ', target_vocab_size)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_vocab_size:  8197\n",
            "target_vocab_size:  8135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrFDeRlgITgc",
        "colab_type": "text"
      },
      "source": [
        "# 11. Optimizer\n",
        "\n",
        "Sử dụng Adam optimizer với Learning rate đã được scheduler theo công thức tại [paper](https://arxiv.org/abs/1706.03762).\n",
        "\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICFn84w3IXY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFJ0FaNrIaaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3frPLmKHIcQK",
        "colab_type": "code",
        "outputId": "38200827-2a18-4e4e-81b4-b9b818aa0f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgM8bh7VIfZb",
        "colab_type": "text"
      },
      "source": [
        "# 12. Loss and Metrics\n",
        "\n",
        "Bởi vì câu mục tiêu và được padded, do đó chúng ta cũng phải áp dụng padding mask khi tính toán loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99VNjCjgIj70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKQhFlUWIlsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBcaGzgXIojP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsYBPEFHIswC",
        "colab_type": "text"
      },
      "source": [
        "# 13. Training and checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLDHZV-LIwn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer = Transformer(num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff,\n",
        "                          input_vocab_size=input_vocab_size, target_vocab_size=target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-f74iJQIyk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by \n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXjnL6M84QgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.constant([[7, 6, 0, 0, 0], [1, 2, 3, 0, 0], [6, 0, 0, 0, 0]])\n",
        "y = tf.constant([[1, 4, 5, 0, 0], [1, 4, 3, 0, 0], [1, 2, 0, 0, 0]])\n",
        "enc_padding_mask, combined_mask, dec_padding_mask = create_masks(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zerHWzUm9Exd",
        "colab_type": "code",
        "outputId": "57756ec4-b09a-4a7f-dbe3-ba78dce51900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "combined_mask"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1, 5, 5), dtype=float32, numpy=\n",
              "array([[[[0., 1., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1.],\n",
              "         [0., 0., 0., 1., 1.],\n",
              "         [0., 0., 0., 1., 1.],\n",
              "         [0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[0., 1., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1.],\n",
              "         [0., 0., 0., 1., 1.],\n",
              "         [0., 0., 0., 1., 1.],\n",
              "         [0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[0., 1., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1.]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqZTCNs0I6As",
        "colab_type": "text"
      },
      "source": [
        "Chúng ta sẽ tạo ra một checkpoint path và checkpoint manager để lưu checkpoints (là trạng thái của model, có thể load lại để huấn luyện lại) sau mỗi `n=5` epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os5cyElOI2MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train_500k\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE_wzlQIHjVg",
        "colab_type": "text"
      },
      "source": [
        "**Note:** Layer embedding của Encoder sẽ lưu `input_vocabulary_size` và `target_vocabulary_size` theo bộ dữ liệu. Do đó nếu huấn luyện trên bộ dữ liệu mới thì sẽ không thể load lại model từ checkpoints cũ. Chúng ta cần chuyển sang một bộ checkpoints mới."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT82mPAF1s-I",
        "colab_type": "text"
      },
      "source": [
        "Target sẽ được phân thành `tar_inp` và `tar_real`. `tar_inp` được truyền vào như là một input cho decoder. `tar_real` tương tự như `tar_inp` nhưng được dịch chuyển 1 đơn vị: Tại mỗi vị trí trong `tar_inp` ta sẽ có 1 vị trí tương ứng trong `tar_real` là token tiếp theo nên được dự báo.\n",
        "\n",
        "Chẳng hạn trong câu sentence = `SOS một con sư tử đang ngủ say trong rừng SOS`\n",
        "\n",
        "`tar_inp` = `SOS một con sư tử đang ngủ say trong rừng`\n",
        "\n",
        "`tar_real` = `một con sư tử đang ngủ say trong rừng SOS`\n",
        "\n",
        "transformer là một mô hình tự hồi qui (auto-regressive model, một dạng model trong chuỗi thời gian sử dụng chính giá trị quá khử của chuỗi để dự báo giá trị hiện tại của chuỗi): và tạo ra một dự báo tại mỗi một time step. Nó sử dụng output của nó từ trước đến hiện tại để quyết định xem từ tiếp theo là gì.\n",
        "\n",
        "Trong quá trình huấn luyện ví dụ này sử dụng kỹ thuật teacher-forcing. Teacher-forcing sẽ bỏ qua giá trị đúng ở output để tới time step tiếp theo mà không quan tâm tới mô hình dự báo ra là gì tại time step hiện tại.\n",
        "\n",
        "Khi transformer dự báo mỗi từ, `self-attention` cho phép nó nhìn vào các từ liền trước trong chuỗi input để dự báo tốt hơn từ tiếp theo.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3yqqByQJL86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfzBNDzkJNgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "    \n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzqyxtmoJQ5v",
        "colab_type": "code",
        "outputId": "0ef7300d-6d0c-4f74-f9f0-940b9e899d5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  # inp -> non_diacritic, tar -> diacritic\n",
        "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "    train_step(inp, tar)\n",
        "    \n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "      \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "    \n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.2649 Accuracy 0.4796\n",
            "Epoch 1 Batch 50 Loss 0.2963 Accuracy 0.4298\n",
            "Epoch 1 Batch 100 Loss 0.2766 Accuracy 0.4315\n",
            "Epoch 1 Batch 150 Loss 0.2642 Accuracy 0.4315\n",
            "Epoch 1 Batch 200 Loss 0.2577 Accuracy 0.4350\n",
            "Epoch 1 Batch 250 Loss 0.2498 Accuracy 0.4351\n",
            "Epoch 1 Batch 300 Loss 0.2453 Accuracy 0.4347\n",
            "Epoch 1 Batch 350 Loss 0.2435 Accuracy 0.4345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-b21c3715fca0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# inp -> non_diacritic, tar -> diacritic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lLVyH4IJTD-",
        "colab_type": "text"
      },
      "source": [
        "# 14. Evaluate\n",
        "\n",
        "Các bước sau đây được sử dụng để đánh giá:\n",
        "\n",
        "* Mã hóa câu đầu vào bằng cách sử dụng tokenizer input (tokenizer_pt). Ngoài ra , thêm mã bắt đầu và kết thúc để đầu vào tương đương với những gì mô hình đã huấn luyện. Đây sẽ là đầu vào cho encoder.\n",
        "\n",
        "* Đầu vào cho decoder là start token có index bằng với tokenizer_en.vocab_size.\n",
        "\n",
        "* Tính toán các padding masks và look ahead masks.\n",
        "\n",
        "* decoder sau đó đưa ra các dự đoán dựa trên đầu ra của encoder và đầu ra của chính nó (self-attention).\n",
        "\n",
        "* Chọn từ cuối cùng và tính argmax của từ đó.\n",
        "\n",
        "* Nối từ dự đoán với đầu vào decoder input khi chuyển từ đó đến decoder.\n",
        "\n",
        "* Trong phương pháp này, decoder dự đoán từ tiếp theo dựa trên các từ trước đó mà nó dự đoán."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMThE6dBJU8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 40\n",
        "\n",
        "def evaluate(inp_sentence):\n",
        "  start_token = [tokenizer_ipt.vocab_size]\n",
        "  end_token = [tokenizer_ipt.vocab_size + 1]\n",
        "  \n",
        "  # inp sentence is non_diacritic, hence adding the start and end token\n",
        "  inp_sentence = start_token + tokenizer_ipt.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "  \n",
        "  # as the target is exist diacritic, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  decoder_input = [tokenizer_opt.vocab_size]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "  \n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == tokenizer_opt.vocab_size+1:\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0), attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cInZU7mRts4",
        "colab_type": "text"
      },
      "source": [
        "Tiếp theo ta sẽ xây dựng biểu đồ heatmap visualize attention weight giữa 2 từ bất kỳ được lấy từ câu input và câu target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh2okU5pJY5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_attention_weights(attention, sentence, result, layer):\n",
        "  fig = plt.figure(figsize=(16, 8))\n",
        "  \n",
        "  sentence = tokenizer_ipt.encode(sentence)\n",
        "  \n",
        "  attention = tf.squeeze(attention[layer], axis=0)\n",
        "  \n",
        "  for head in range(attention.shape[0]):\n",
        "    ax = fig.add_subplot(2, 4, head+1)\n",
        "    \n",
        "    # plot the attention weights\n",
        "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 10}\n",
        "    \n",
        "    ax.set_xticks(range(len(sentence)+2))\n",
        "    ax.set_yticks(range(len(result)))\n",
        "    \n",
        "    ax.set_ylim(len(result)-1.5, -0.5)\n",
        "        \n",
        "    ax.set_xticklabels(\n",
        "        ['<start>']+[tokenizer_ipt.decode([i]) for i in sentence]+['<end>'], \n",
        "        fontdict=fontdict, rotation=90)\n",
        "    \n",
        "    ax.set_yticklabels([tokenizer_opt.decode([i]) for i in result \n",
        "                        if i < tokenizer_opt.vocab_size], \n",
        "                       fontdict=fontdict)\n",
        "    \n",
        "    ax.set_xlabel('Head {}'.format(head+1))\n",
        "  \n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S9Bva_lSItR",
        "colab_type": "text"
      },
      "source": [
        "Hàm translate sẽ có tác dụng chuyển đánh giá câu input và trả ra câu dự báo bằng cách giải mã chuỗi indices token được dự báo từ mô hình."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66o0xlJJJebR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence, plot=''):\n",
        "  result, attention_weights = evaluate(sentence)\n",
        "  \n",
        "  predicted_sentence = tokenizer_opt.decode([i for i in result \n",
        "                                            if i < tokenizer_opt.vocab_size])  \n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Predicted translation: {}'.format(predicted_sentence))\n",
        "  \n",
        "  if plot:\n",
        "    plot_attention_weights(attention_weights, sentence, result, plot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wVbXwWnJgcP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6676e4e3-94f3-44d6-f864-097fdefb19b3"
      },
      "source": [
        "translate(\"tieng Viet la ngon ngu trong sang nhat the gioi\")"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tieng Viet la ngon ngu trong sang nhat the gioi\n",
            "Predicted translation: tiếng Việt là ngôn ngữ trong sáng nhất thế giới\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhQBXkDBJqJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "0dfeddad-6e3e-4987-825e-987ad75da71a"
      },
      "source": [
        "translate(\"hom nay thoi tiet tai Ha Noi rat nong\", plot='decoder_layer4_block2')\n",
        "print (\"Real translation: hôm nay thời tiết tại Hà Nội rất nóng\")"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: hom nay thoi tiet tai Ha Noi rat nong\n",
            "Predicted translation: hôm nay thời tiết tại Hà Nội rất nóng\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Real translation: this is the first book i've ever done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NxaNF-hRaGH",
        "colab_type": "text"
      },
      "source": [
        "Ta có thể thấy khi visualize `encoder-decoder attention` từ một block layer trong decoder cho từng head trong multi-heads thì các vị trí từ ở encoder cùng mà vị trí với từ ở decoder sẽ có attention weight cao hơn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx7ptmkZLGTq",
        "colab_type": "text"
      },
      "source": [
        "# 15. Pretrain model\n",
        "\n",
        "Nếu bạn không muốn huấn luyện model từ đầu, bạn có thể sử dụng pretrained model đã được tôi huấn luyện bằng cách download các thư mục:\n",
        "\n",
        "* tokenizer: là tokenizer cho các subwords dùng để chuyển sequence sang indice.\n",
        "\n",
        "* checkpoint: Là checkpint, nơi lưu trữ last pretrain model để bạn có thể load lại cho dự báo.\n",
        "\n",
        "Cả 2 đều được đặt trong folder [themdau_tv](https://drive.google.com/drive/folders/11KSVIIDWlNknVZmoL1ugW8fxHJyrNBCr?usp=sharing).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7OXMynGfSlq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8186e0a1-6026-4d05-cc34-8e2fce6579a2"
      },
      "source": [
        "!ls tokenizer"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_vocab.txt   tokenizer_ipt.pkl\t  tokenizer_opt.pkl\n",
            "output_vocab.txt  tokenizer_ipt.subwords  tokenizer_opt.subwords\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxmexB51LJBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load tokenizer\n",
        "import pickle\n",
        "\n",
        "def _save_pickle(path, obj):\n",
        "  with open(path, 'wb') as f:\n",
        "    pickle.dump(obj, f)\n",
        "\n",
        "def _load_pickle(path):\n",
        "  with open(path, 'rb') as f:\n",
        "    obj = pickle.load(f)\n",
        "  return obj\n",
        "\n",
        "tokenizer_ipt = _load_pickle('tokenizer/tokenizer_ipt.pkl')\n",
        "tokenizer_opt = _load_pickle('tokenizer/tokenizer_opt.pkl')\n",
        "\n",
        "# Khai báo tham số\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = tokenizer_ipt.vocab_size + 2\n",
        "target_vocab_size = tokenizer_opt.vocab_size + 2\n",
        "dropout_rate = 0.1\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdCXS6SDT9pH",
        "colab_type": "text"
      },
      "source": [
        "Nếu các bạn bắt đầu từ mục 15 này ngay từ đầu. Trước khi load model thì các bạn cần chạy lại toàn bộ code cho layers và mô hình ở mục 8 và 9. Đây là hạn chế của notebook so với python file. Trên python file chúng ta có thể import class giữa các files với nhau khá dễ dàng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1vP_hu1hRPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load model\n",
        "transformer = Transformer(num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff,\n",
        "                          input_vocab_size=input_vocab_size, target_vocab_size=target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)\n",
        "\n",
        "checkpoint_path = \"./checkpoints/train_500k\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV0700vGBjIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(inp_sentence):\n",
        "  start_token = [ipt_vocab_size]\n",
        "  end_token = [ipt_vocab_size+1]\n",
        "  \n",
        "  # inp sentence is non_diacritic, hence adding the start and end token\n",
        "  inp_sentence = start_token + tokenizer_ipt.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "  \n",
        "  # as the target is exist diacritic, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  decoder_input = [opt_vocab_size]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "  \n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == opt_vocab_size+1:\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0), attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS2CXsgupovK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_diacritic(sentence, plot=''):\n",
        "  result, attention_weights = evaluate(sentence)\n",
        "  predicted_sentence = tokenizer_opt.decode([i for i in result \n",
        "                                            if i < opt_vocab_size])  \n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Predicted translation: {}'.format(predicted_sentence))\n",
        "  if plot:\n",
        "    plot_attention_weights(attention_weights, sentence, result, plot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6fxveGUQWQM",
        "colab_type": "text"
      },
      "source": [
        "Bên dưới là kết quả của một vài câu thử nghiệm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePzW7Tj9Oi5A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d2841f95-6112-41f9-c559-92f07112810d"
      },
      "source": [
        "add_diacritic(\"hom nay thoi tiet tai Ha Noi rat nong\")"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: hom nay thoi tiet tai Ha Noi rat nong\n",
            "Predicted translation: hôm nay thời tiết tại Hà Nội rất nóng\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjjVBFk9Ojle",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6ae3f4d0-dfc2-4bee-a9bf-c826a1a13d22"
      },
      "source": [
        "add_diacritic(\"toi la mot nguoi rat yeu thich AI\")"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: toi la mot nguoi rat yeu thich AI\n",
            "Predicted translation: tôi là một người rất yêu thích AI\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7rzkkidOkLz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fae64756-6b33-4462-cb4b-d1cd4e435f0e"
      },
      "source": [
        "add_diacritic(\"toi muon tro thanh mot AI researcher noi tieng tren the gioi\")"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: toi muon tro thanh mot AI researcher noi tieng tren the gioi\n",
            "Predicted translation: tôi muốn trở thành một AI researcher nổi tiếng trên thế giới\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEjDzyc57D1y",
        "colab_type": "text"
      },
      "source": [
        "# 16. Tổng kết\n",
        "\n",
        "Như vậy qua bài viết này chúng ta đã được hướng dẫn từ bước thu thập dữ liệu, xây dựng các layers của kiến trúc transformer, huấn luyện mô hình và dự báo từ pretrained model.\n",
        "\n",
        "Thông qua việc thực hành chúng ta sẽ hiểu rõ hơn cấu trúc từng layer và các xử lý attention, mask trong tác vụ seq2seq. Bản thân tôi cũng phải bỏ ra rất nhiều thời gian để nghiên cứu bài viết này và viết lại như một tài liệu tham khảo khi cần. Bài viết được lấy từ nhiều nguồn liệt kê bên dưới."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5g4XOctDU7B",
        "colab_type": "text"
      },
      "source": [
        "# 17. Tài liệu tham khảo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDLGRNGVk-GF",
        "colab_type": "text"
      },
      "source": [
        "1. [Transformer model for language understanding](https://www.tensorflow.org/tutorials/text/transformer)\n",
        "\n",
        "2. [Bài 4 - Attention is all you need - Khanh Blog](https://phamdinhkhanh.github.io/2019/06/18/AttentionLayer.html)\n",
        "\n",
        "3. [Bài 7 - Pytorch Seq2seq model correct spelling - Khanh Blog](https://phamdinhkhanh.github.io/2019/08/19/CorrectSpellingVietnamseTonePrediction.html)\n",
        "\n",
        "4. [Bài 36 - BERT model - Khanh Blog](https://phamdinhkhanh.github.io/2020/05/23/BERTModel.html)"
      ]
    }
  ]
}